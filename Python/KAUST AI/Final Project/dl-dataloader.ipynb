{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87e6ba57",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-29T05:41:55.034683Z",
     "iopub.status.busy": "2022-06-29T05:41:55.034169Z",
     "iopub.status.idle": "2022-06-29T05:41:55.054117Z",
     "shell.execute_reply": "2022-06-29T05:41:55.052401Z"
    },
    "papermill": {
     "duration": 0.028721,
     "end_time": "2022-06-29T05:41:55.057094",
     "exception": false,
     "start_time": "2022-06-29T05:41:55.028373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input/sample-submission.csv\n",
      "input/test.csv\n",
      "input/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('input/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7b9496",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T05:41:55.068728Z",
     "iopub.status.busy": "2022-06-29T05:41:55.068269Z",
     "iopub.status.idle": "2022-06-29T05:42:07.698659Z",
     "shell.execute_reply": "2022-06-29T05:42:07.697494Z"
    },
    "papermill": {
     "duration": 12.639312,
     "end_time": "2022-06-29T05:42:07.701503",
     "exception": false,
     "start_time": "2022-06-29T05:41:55.062191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37cf567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T05:42:07.712748Z",
     "iopub.status.busy": "2022-06-29T05:42:07.711984Z",
     "iopub.status.idle": "2022-06-29T05:42:09.750830Z",
     "shell.execute_reply": "2022-06-29T05:42:09.749623Z"
    },
    "papermill": {
     "duration": 2.047293,
     "end_time": "2022-06-29T05:42:09.753474",
     "exception": false,
     "start_time": "2022-06-29T05:42:07.706181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(\"input/\")\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(DATA_DIR / \"train.csv\", dtype=\"uint8\")\n",
    "test_df = pd.read_csv(DATA_DIR / \"test.csv\", dtype=\"uint8\")\n",
    "\n",
    "\n",
    "train_features = train_df.drop(\"labels\", axis=1)\n",
    "train_target = train_df.loc[:, \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dcdcc72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T05:42:09.764620Z",
     "iopub.status.busy": "2022-06-29T05:42:09.764267Z",
     "iopub.status.idle": "2022-06-29T05:42:09.775004Z",
     "shell.execute_reply": "2022-06-29T05:42:09.773882Z"
    },
    "papermill": {
     "duration": 0.019258,
     "end_time": "2022-06-29T05:42:09.777460",
     "exception": false,
     "start_time": "2022-06-29T05:42:09.758202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataSetWithTransforms(Dataset):\n",
    "    \n",
    "    def __init__(self, features, target, feature_transforms=None):\n",
    "        super().__init__()\n",
    "        self._features = features\n",
    "        self._target = torch.from_numpy(target).long()\n",
    "        self._feature_transforms = feature_transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self._feature_transforms is None:\n",
    "            features = self._features[index]\n",
    "            #feature = torch.rashape(feature, (32,32,3))\n",
    "        else: \n",
    "            features = self._feature_transforms(self._features[index])\n",
    "        target = self._target[index]\n",
    "        return (features, target) \n",
    "    \n",
    "    def __len__(self):\n",
    "        n_samples, _ = self._features.shape\n",
    "        return n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52517dd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T05:42:09.788346Z",
     "iopub.status.busy": "2022-06-29T05:42:09.787967Z",
     "iopub.status.idle": "2022-06-29T05:42:09.797615Z",
     "shell.execute_reply": "2022-06-29T05:42:09.796849Z"
    },
    "papermill": {
     "duration": 0.017615,
     "end_time": "2022-06-29T05:42:09.799740",
     "exception": false,
     "start_time": "2022-06-29T05:42:09.782125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataSetTest(Dataset):\n",
    "    \n",
    "    def __init__(self, features, feature_transforms=None):\n",
    "        super().__init__()\n",
    "        self._features = features\n",
    "        self._feature_transforms = feature_transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self._feature_transforms is None:\n",
    "            features = self._features[index]\n",
    "            #feature = torch.rashape(feature, (32,32,3))\n",
    "        else: \n",
    "            features = self._feature_transforms(self._features[index])\n",
    "        return (features) \n",
    "    \n",
    "    def __len__(self):\n",
    "        n_samples, _ = self._features.shape\n",
    "        return n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6697d1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T05:42:09.810569Z",
     "iopub.status.busy": "2022-06-29T05:42:09.810189Z",
     "iopub.status.idle": "2022-06-29T05:42:09.818580Z",
     "shell.execute_reply": "2022-06-29T05:42:09.816982Z"
    },
    "papermill": {
     "duration": 0.017051,
     "end_time": "2022-06-29T05:42:09.821486",
     "exception": false,
     "start_time": "2022-06-29T05:42:09.804435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data augmentation should only apply to training data\n",
    "_feature_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda array: array.reshape((32, 32))),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), shear=15, scale=(1.0, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffa1d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conveting test data only to tensor images should only apply to training data\n",
    "_feature_transforms_test = transforms.Compose([\n",
    "    transforms.Lambda(lambda array: array.reshape((32, 32))),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c6a237e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "def mnist(batch_sz, valid_size=0.2, shuffle=True, random_seed=2000):\n",
    "    \n",
    "\n",
    "    train_df = pd.read_csv(DATA_DIR / \"train.csv\", dtype=\"uint8\")\n",
    "    test_df = pd.read_csv(DATA_DIR / \"test.csv\", dtype=\"uint8\")\n",
    "\n",
    "    train_features = train_df.drop(\"labels\", axis=1)\n",
    "    train_target = train_df.loc[:, \"labels\"]\n",
    "\n",
    "    # Training dataset\n",
    "    train_data = DataSetWithTransforms(train_features.values, train_target.values, _feature_transforms)\n",
    "    valid_data = DataSetWithTransforms(train_features.values, train_target.values, _feature_transforms_test)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    if shuffle == True:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_sz, sampler=train_sampler, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=batch_sz, sampler=valid_sampler, pin_memory=True)\n",
    "\n",
    "    # Test dataset\n",
    "    test_data = DataSetTest(test_df.values, _feature_transforms_test)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_sz, shuffle=False, pin_memory=True)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e0f62536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T05:42:09.832382Z",
     "iopub.status.busy": "2022-06-29T05:42:09.832004Z",
     "iopub.status.idle": "2022-06-29T05:42:09.837793Z",
     "shell.execute_reply": "2022-06-29T05:42:09.836898Z"
    },
    "papermill": {
     "duration": 0.013628,
     "end_time": "2022-06-29T05:42:09.839745",
     "exception": false,
     "start_time": "2022-06-29T05:42:09.826117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "batch_sz=64 # this is batch size i.e. the number of rows in a batch of data\n",
    "train_loader, valid_loader, test_loader=mnist(batch_sz) \n",
    "for batch in test_loader:\n",
    "    print(batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dfe5fc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13440"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*(len(train_loader)+len(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "780d27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,20,5,1)\n",
    "        self.norm1 = nn.BatchNorm2d(20)\n",
    "        self.conv2 = nn.Conv2d(20,50,5,1)\n",
    "        self.norm2 = nn.BatchNorm2d(50)\n",
    "        self.l1 = nn.Linear(5*5*50,100)\n",
    "        self.l2 = nn.Linear(100,200)\n",
    "        self.l3 = nn.Linear(200, 500)\n",
    "        self.l4 = nn.Linear(500, 200)\n",
    "        self.l5 = nn.Linear(200, 29)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (32,32)\n",
    "        x = F.leaky_relu(self.norm1(self.conv1(x)))\n",
    "        # (28,28)\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # (14,14)\n",
    "        x = F.leaky_relu(self.norm2(self.conv2(x)))\n",
    "        # (10,10)\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # (5,5)\n",
    "        x = x.view(-1,5*5*50)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.l3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.l4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.l5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "ee47ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "net = ConvNet()\n",
    "net = net.to(device)\n",
    "\n",
    "ls=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "24786929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "\n",
    "net = models.resnet18(num_classes=29)\n",
    "\n",
    "net.conv1 = nn.Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "af563517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-01.\n"
     ]
    }
   ],
   "source": [
    "net.conv1 = nn.Conv2d(1, 64, kernel_size=(5, 5), padding=(3, 3), bias=False)\n",
    "#net.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
    "net = net.to(device)\n",
    "lr = 0.1\n",
    "momentum = 0.2\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=lr, momentum=momentum)\n",
    "lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "b056eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "826a39e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9825148809523809\n"
     ]
    }
   ],
   "source": [
    "print(highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "d685772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9000e-02.\n",
      "Iterataion 0: Training Loss: 2.023458252409975, Validation Loss: 1.952951992430338\n",
      "Iteataion 0: Training Accuracy: 0.2615327380952381, Validation Accuracy  0.2931547619047619\n",
      "Adjusting learning rate of group 0 to 9.8010e-02.\n",
      "Iterataion 1: Training Loss: 1.6326002674902271, Validation Loss: 1.4440708770984556\n",
      "Iteataion 1: Training Accuracy: 0.34402901785714285, Validation Accuracy  0.39955357142857145\n",
      "Adjusting learning rate of group 0 to 9.7030e-02.\n",
      "Iterataion 2: Training Loss: 1.4910598672078754, Validation Loss: 1.6139707274553252\n",
      "Iteataion 2: Training Accuracy: 0.4226190476190476, Validation Accuracy  0.39211309523809523\n",
      "Adjusting learning rate of group 0 to 9.6060e-02.\n",
      "Iterataion 3: Training Loss: 1.3126487203700814, Validation Loss: 1.0927190417196693\n",
      "Iteataion 3: Training Accuracy: 0.4816778273809524, Validation Accuracy  0.5308779761904762\n",
      "Adjusting learning rate of group 0 to 9.5099e-02.\n",
      "Iterataion 4: Training Loss: 1.1473228849336772, Validation Loss: 1.076343595981598\n",
      "Iteataion 4: Training Accuracy: 0.5580357142857143, Validation Accuracy  0.59375\n",
      "Adjusting learning rate of group 0 to 9.4148e-02.\n",
      "Iterataion 5: Training Loss: 0.9986977591486035, Validation Loss: 0.7908395281652125\n",
      "Iteataion 5: Training Accuracy: 0.615234375, Validation Accuracy  0.6848958333333334\n",
      "Adjusting learning rate of group 0 to 9.3207e-02.\n",
      "Iterataion 6: Training Loss: 0.8931534843530483, Validation Loss: 0.6274223494820479\n",
      "Iteataion 6: Training Accuracy: 0.6686197916666666, Validation Accuracy  0.7697172619047619\n",
      "Adjusting learning rate of group 0 to 9.2274e-02.\n",
      "Iterataion 7: Training Loss: 0.7576766756480325, Validation Loss: 1.104226259196677\n",
      "Iteataion 7: Training Accuracy: 0.7488839285714286, Validation Accuracy  0.6372767857142857\n",
      "Adjusting learning rate of group 0 to 9.1352e-02.\n",
      "Iterataion 8: Training Loss: 0.6439691626740073, Validation Loss: 0.4733974017748019\n",
      "Iteataion 8: Training Accuracy: 0.7881324404761905, Validation Accuracy  0.8560267857142857\n",
      "Adjusting learning rate of group 0 to 9.0438e-02.\n",
      "Iterataion 9: Training Loss: 0.6027774856297555, Validation Loss: 0.44040211998834844\n",
      "Iteataion 9: Training Accuracy: 0.8095238095238095, Validation Accuracy  0.8560267857142857\n",
      "Adjusting learning rate of group 0 to 8.9534e-02.\n",
      "Iterataion 10: Training Loss: 0.49973676358154434, Validation Loss: 0.47698725214818627\n",
      "Iteataion 10: Training Accuracy: 0.8450520833333334, Validation Accuracy  0.8467261904761905\n",
      "Adjusting learning rate of group 0 to 8.8638e-02.\n",
      "Iterataion 11: Training Loss: 0.4885037776952732, Validation Loss: 0.49997129963665476\n",
      "Iteataion 11: Training Accuracy: 0.8497953869047619, Validation Accuracy  0.8727678571428571\n",
      "Adjusting learning rate of group 0 to 8.7752e-02.\n",
      "Iterataion 12: Training Loss: 0.4124493313406756, Validation Loss: 0.2806231592123101\n",
      "Iteataion 12: Training Accuracy: 0.8812313988095238, Validation Accuracy  0.9233630952380952\n",
      "Adjusting learning rate of group 0 to 8.6875e-02.\n",
      "Iterataion 13: Training Loss: 0.4236549708300722, Validation Loss: 0.3777959157780903\n",
      "Iteataion 13: Training Accuracy: 0.8795572916666666, Validation Accuracy  0.8828125\n",
      "Adjusting learning rate of group 0 to 8.6006e-02.\n",
      "Iterataion 14: Training Loss: 0.4080397046790152, Validation Loss: 0.3209142437795313\n",
      "Iteataion 14: Training Accuracy: 0.8864397321428571, Validation Accuracy  0.9162946428571429\n",
      "Adjusting learning rate of group 0 to 8.5146e-02.\n",
      "Iterataion 15: Training Loss: 0.35740371838122786, Validation Loss: 0.34267625612456626\n",
      "Iteataion 15: Training Accuracy: 0.8990885416666666, Validation Accuracy  0.9055059523809523\n",
      "Adjusting learning rate of group 0 to 8.4294e-02.\n",
      "Iterataion 16: Training Loss: 0.37079178791738554, Validation Loss: 0.2566651903638026\n",
      "Iteataion 16: Training Accuracy: 0.8959263392857143, Validation Accuracy  0.9296875\n",
      "Adjusting learning rate of group 0 to 8.3451e-02.\n",
      "Iterataion 17: Training Loss: 0.36473334402202845, Validation Loss: 0.26760702598385694\n",
      "Iteataion 17: Training Accuracy: 0.8994605654761905, Validation Accuracy  0.9233630952380952\n",
      "Adjusting learning rate of group 0 to 8.2617e-02.\n",
      "Iterataion 18: Training Loss: 0.31987371755217364, Validation Loss: 0.25132154782370825\n",
      "Iteataion 18: Training Accuracy: 0.9104352678571429, Validation Accuracy  0.9356398809523809\n",
      "Adjusting learning rate of group 0 to 8.1791e-02.\n",
      "Iterataion 19: Training Loss: 0.30807702243328094, Validation Loss: 0.31992276303651856\n",
      "Iteataion 19: Training Accuracy: 0.9166666666666666, Validation Accuracy  0.9043898809523809\n",
      "Adjusting learning rate of group 0 to 8.0973e-02.\n",
      "Iterataion 20: Training Loss: 0.319157186561002, Validation Loss: 0.6107938969280662\n",
      "Iteataion 20: Training Accuracy: 0.9143415178571429, Validation Accuracy  0.8671875\n",
      "Adjusting learning rate of group 0 to 8.0163e-02.\n",
      "Iterataion 21: Training Loss: 0.34002295814588396, Validation Loss: 0.3033649414414313\n",
      "Iteataion 21: Training Accuracy: 0.9136904761904762, Validation Accuracy  0.9304315476190477\n",
      "Adjusting learning rate of group 0 to 7.9361e-02.\n",
      "Iterataion 22: Training Loss: 0.27623668018572345, Validation Loss: 0.16407577902442072\n",
      "Iteataion 22: Training Accuracy: 0.9268043154761905, Validation Accuracy  0.9575892857142857\n",
      "Adjusting learning rate of group 0 to 7.8568e-02.\n",
      "Iterataion 23: Training Loss: 0.24436101143410105, Validation Loss: 0.24874366592706704\n",
      "Iteataion 23: Training Accuracy: 0.9325706845238095, Validation Accuracy  0.9378720238095238\n",
      "Adjusting learning rate of group 0 to 7.7782e-02.\n",
      "Iterataion 24: Training Loss: 0.2651968622457481, Validation Loss: 0.21145744967024502\n",
      "Iteataion 24: Training Accuracy: 0.9273623511904762, Validation Accuracy  0.9419642857142857\n",
      "Adjusting learning rate of group 0 to 7.7004e-02.\n",
      "Iterataion 25: Training Loss: 0.2511788171208547, Validation Loss: 0.16161432235342701\n",
      "Iteataion 25: Training Accuracy: 0.9326636904761905, Validation Accuracy  0.9587053571428571\n",
      "Adjusting learning rate of group 0 to 7.6234e-02.\n",
      "Iterataion 26: Training Loss: 0.2293949185865011, Validation Loss: 0.2376868258707407\n",
      "Iteataion 26: Training Accuracy: 0.9385230654761905, Validation Accuracy  0.9441964285714286\n",
      "Adjusting learning rate of group 0 to 7.5472e-02.\n",
      "Iterataion 27: Training Loss: 0.24400787138028773, Validation Loss: 0.19022274662445232\n",
      "Iteataion 27: Training Accuracy: 0.9361049107142857, Validation Accuracy  0.9468005952380952\n",
      "Adjusting learning rate of group 0 to 7.4717e-02.\n",
      "Iterataion 28: Training Loss: 0.24849260245968482, Validation Loss: 0.2671991734788185\n",
      "Iteataion 28: Training Accuracy: 0.9373139880952381, Validation Accuracy  0.9456845238095238\n",
      "Adjusting learning rate of group 0 to 7.3970e-02.\n",
      "Iterataion 29: Training Loss: 0.2227579979839439, Validation Loss: 0.17123270089306483\n",
      "Iteataion 29: Training Accuracy: 0.9401041666666666, Validation Accuracy  0.9598214285714286\n",
      "Adjusting learning rate of group 0 to 7.3230e-02.\n",
      "Iterataion 30: Training Loss: 0.22006612639138085, Validation Loss: 0.21450941110166108\n",
      "Iteataion 30: Training Accuracy: 0.9406622023809523, Validation Accuracy  0.9587053571428571\n",
      "Adjusting learning rate of group 0 to 7.2498e-02.\n",
      "Iterataion 31: Training Loss: 0.1921699543645282, Validation Loss: 0.14257149557333168\n",
      "Iteataion 31: Training Accuracy: 0.9477306547619048, Validation Accuracy  0.9672619047619048\n",
      "Adjusting learning rate of group 0 to 7.1773e-02.\n",
      "Iterataion 32: Training Loss: 0.2155494735894089, Validation Loss: 0.21093648744792473\n",
      "Iteataion 32: Training Accuracy: 0.9428943452380952, Validation Accuracy  0.9557291666666666\n",
      "Adjusting learning rate of group 0 to 7.1055e-02.\n",
      "Iterataion 33: Training Loss: 0.2540205341211693, Validation Loss: 0.24278037159181223\n",
      "Iteataion 33: Training Accuracy: 0.9385230654761905, Validation Accuracy  0.9393601190476191\n",
      "Adjusting learning rate of group 0 to 7.0345e-02.\n",
      "Iterataion 34: Training Loss: 0.23274589097963835, Validation Loss: 0.600454428573934\n",
      "Iteataion 34: Training Accuracy: 0.9407552083333334, Validation Accuracy  0.9118303571428571\n",
      "Adjusting learning rate of group 0 to 6.9641e-02.\n",
      "Iterataion 35: Training Loss: 0.21796390251395945, Validation Loss: 0.16149153442281047\n",
      "Iteataion 35: Training Accuracy: 0.9419642857142857, Validation Accuracy  0.9609375\n",
      "Adjusting learning rate of group 0 to 6.8945e-02.\n",
      "Iterataion 36: Training Loss: 0.18475713512810046, Validation Loss: 0.1675772397983365\n",
      "Iteataion 36: Training Accuracy: 0.9515438988095238, Validation Accuracy  0.9676339285714286\n",
      "Adjusting learning rate of group 0 to 6.8255e-02.\n",
      "Iterataion 37: Training Loss: 0.18087280867342465, Validation Loss: 0.15438386920566965\n",
      "Iteataion 37: Training Accuracy: 0.9506138392857143, Validation Accuracy  0.9650297619047619\n",
      "Adjusting learning rate of group 0 to 6.7573e-02.\n",
      "Iterataion 38: Training Loss: 0.17560721592542655, Validation Loss: 0.16306795338850197\n",
      "Iteataion 38: Training Accuracy: 0.9543340773809523, Validation Accuracy  0.9609375\n",
      "Adjusting learning rate of group 0 to 6.6897e-02.\n",
      "Iterataion 39: Training Loss: 0.1827898222596167, Validation Loss: 0.13255512355486068\n",
      "Iteataion 39: Training Accuracy: 0.9510788690476191, Validation Accuracy  0.9702380952380952\n",
      "Adjusting learning rate of group 0 to 6.6228e-02.\n",
      "Iterataion 40: Training Loss: 0.1928355785499433, Validation Loss: 0.19394483226465015\n",
      "Iteataion 40: Training Accuracy: 0.9518229166666666, Validation Accuracy  0.9546130952380952\n",
      "Adjusting learning rate of group 0 to 6.5566e-02.\n",
      "Iterataion 41: Training Loss: 0.18086533838448055, Validation Loss: 0.14123212318958306\n",
      "Iteataion 41: Training Accuracy: 0.9512648809523809, Validation Accuracy  0.9654017857142857\n",
      "Adjusting learning rate of group 0 to 6.4910e-02.\n",
      "Iterataion 42: Training Loss: 0.18910946643459584, Validation Loss: 0.2401711377428799\n",
      "Iteataion 42: Training Accuracy: 0.9484747023809523, Validation Accuracy  0.9505208333333334\n",
      "Adjusting learning rate of group 0 to 6.4261e-02.\n",
      "Iterataion 43: Training Loss: 0.18139551743909627, Validation Loss: 0.23640087292325207\n",
      "Iteataion 43: Training Accuracy: 0.9539620535714286, Validation Accuracy  0.9527529761904762\n",
      "Adjusting learning rate of group 0 to 6.3619e-02.\n",
      "Iterataion 44: Training Loss: 0.19006621576622576, Validation Loss: 0.1797609192023917\n",
      "Iteataion 44: Training Accuracy: 0.9527529761904762, Validation Accuracy  0.9639136904761905\n",
      "Adjusting learning rate of group 0 to 6.2982e-02.\n",
      "Iterataion 45: Training Loss: 0.16275948568241683, Validation Loss: 0.12606020694280543\n",
      "Iteataion 45: Training Accuracy: 0.9540550595238095, Validation Accuracy  0.9668898809523809\n",
      "Adjusting learning rate of group 0 to 6.2353e-02.\n",
      "Iterataion 46: Training Loss: 0.1625128247200729, Validation Loss: 0.16637742473948292\n",
      "Iteataion 46: Training Accuracy: 0.9571242559523809, Validation Accuracy  0.9627976190476191\n",
      "Adjusting learning rate of group 0 to 6.1729e-02.\n",
      "Iterataion 47: Training Loss: 0.1707971974158894, Validation Loss: 0.1800322483134706\n",
      "Iteataion 47: Training Accuracy: 0.9543340773809523, Validation Accuracy  0.9616815476190477\n",
      "Adjusting learning rate of group 0 to 6.1112e-02.\n",
      "Iterataion 48: Training Loss: 0.15622056596828793, Validation Loss: 0.23196441843742277\n",
      "Iteataion 48: Training Accuracy: 0.9594494047619048, Validation Accuracy  0.953125\n",
      "Adjusting learning rate of group 0 to 6.0501e-02.\n",
      "Iterataion 49: Training Loss: 0.14497444106120908, Validation Loss: 0.18443174042352817\n",
      "Iteataion 49: Training Accuracy: 0.9616815476190477, Validation Accuracy  0.9654017857142857\n",
      "Adjusting learning rate of group 0 to 5.9896e-02.\n",
      "Iterataion 50: Training Loss: 0.13928088106348843, Validation Loss: 0.14616560554359018\n",
      "Iteataion 50: Training Accuracy: 0.9627976190476191, Validation Accuracy  0.9672619047619048\n",
      "Adjusting learning rate of group 0 to 5.9297e-02.\n",
      "Iterataion 51: Training Loss: 0.15262205209471508, Validation Loss: 0.17201798781752586\n",
      "Iteataion 51: Training Accuracy: 0.9592633928571429, Validation Accuracy  0.9654017857142857\n",
      "Adjusting learning rate of group 0 to 5.8704e-02.\n",
      "Iterataion 52: Training Loss: 0.1599509547503587, Validation Loss: 0.15535405941489266\n",
      "Iteataion 52: Training Accuracy: 0.9599144345238095, Validation Accuracy  0.9631696428571429\n",
      "Adjusting learning rate of group 0 to 5.8117e-02.\n",
      "Iterataion 53: Training Loss: 0.1415888635542043, Validation Loss: 0.15980996791182495\n",
      "Iteataion 53: Training Accuracy: 0.9591703869047619, Validation Accuracy  0.9646577380952381\n",
      "Adjusting learning rate of group 0 to 5.7535e-02.\n",
      "Iterataion 54: Training Loss: 0.1406776046904618, Validation Loss: 0.13983833440011595\n",
      "Iteataion 54: Training Accuracy: 0.9626116071428571, Validation Accuracy  0.9631696428571429\n",
      "Adjusting learning rate of group 0 to 5.6960e-02.\n",
      "Iterataion 55: Training Loss: 0.14071954412017754, Validation Loss: 0.17871615140721564\n",
      "Iteataion 55: Training Accuracy: 0.9619605654761905, Validation Accuracy  0.9620535714285714\n",
      "Adjusting learning rate of group 0 to 5.6391e-02.\n",
      "Iterataion 56: Training Loss: 0.13446796009551265, Validation Loss: 0.13161675282186125\n",
      "Iteataion 56: Training Accuracy: 0.9651227678571429, Validation Accuracy  0.9654017857142857\n",
      "Adjusting learning rate of group 0 to 5.5827e-02.\n",
      "Iterataion 57: Training Loss: 0.1410685195671227, Validation Loss: 0.23341744915559526\n",
      "Iteataion 57: Training Accuracy: 0.9635416666666666, Validation Accuracy  0.9520089285714286\n",
      "Adjusting learning rate of group 0 to 5.5268e-02.\n",
      "Iterataion 58: Training Loss: 0.1339197026587978, Validation Loss: 0.14262698245484653\n",
      "Iteataion 58: Training Accuracy: 0.9653087797619048, Validation Accuracy  0.9635416666666666\n",
      "Adjusting learning rate of group 0 to 5.4716e-02.\n",
      "Iterataion 59: Training Loss: 0.12987757847270745, Validation Loss: 0.1279941041976577\n",
      "Iteataion 59: Training Accuracy: 0.9657738095238095, Validation Accuracy  0.9698660714285714\n",
      "Adjusting learning rate of group 0 to 5.4169e-02.\n",
      "Iterataion 60: Training Loss: 0.1289224160422465, Validation Loss: 0.1238653598262406\n",
      "Iteataion 60: Training Accuracy: 0.9657738095238095, Validation Accuracy  0.9691220238095238\n",
      "Adjusting learning rate of group 0 to 5.3627e-02.\n",
      "Iterataion 61: Training Loss: 0.14017167462114088, Validation Loss: 0.1438647015474555\n",
      "Iteataion 61: Training Accuracy: 0.9642857142857143, Validation Accuracy  0.9709821428571429\n",
      "Adjusting learning rate of group 0 to 5.3091e-02.\n",
      "Iterataion 62: Training Loss: 0.11670739455762023, Validation Loss: 0.17315371961491863\n",
      "Iteataion 62: Training Accuracy: 0.9689360119047619, Validation Accuracy  0.9639136904761905\n",
      "Adjusting learning rate of group 0 to 5.2560e-02.\n",
      "Iterataion 63: Training Loss: 0.14076362697485678, Validation Loss: 0.13921795667308132\n",
      "Iteataion 63: Training Accuracy: 0.9622395833333334, Validation Accuracy  0.9668898809523809\n",
      "Adjusting learning rate of group 0 to 5.2034e-02.\n",
      "Iterataion 64: Training Loss: 0.12512982340005344, Validation Loss: 0.14351860515591575\n",
      "Iteataion 64: Training Accuracy: 0.9653087797619048, Validation Accuracy  0.9665178571428571\n",
      "Adjusting learning rate of group 0 to 5.1514e-02.\n",
      "Iterataion 65: Training Loss: 0.11242807909712463, Validation Loss: 0.11033832086477338\n",
      "Iteataion 65: Training Accuracy: 0.96875, Validation Accuracy  0.9735863095238095\n",
      "Adjusting learning rate of group 0 to 5.0999e-02.\n",
      "Iterataion 66: Training Loss: 0.11772863584163482, Validation Loss: 0.1342690981833673\n",
      "Iteataion 66: Training Accuracy: 0.96875, Validation Accuracy  0.9654017857142857\n",
      "Adjusting learning rate of group 0 to 5.0489e-02.\n",
      "Iterataion 67: Training Loss: 0.10768584680079879, Validation Loss: 0.22409284319274309\n",
      "Iteataion 67: Training Accuracy: 0.9677269345238095, Validation Accuracy  0.9627976190476191\n",
      "Adjusting learning rate of group 0 to 4.9984e-02.\n",
      "Iterataion 68: Training Loss: 0.1289302745755918, Validation Loss: 0.14117264453457987\n",
      "Iteataion 68: Training Accuracy: 0.9666108630952381, Validation Accuracy  0.9694940476190477\n",
      "Adjusting learning rate of group 0 to 4.9484e-02.\n",
      "Iterataion 69: Training Loss: 0.11969679797034778, Validation Loss: 0.12299547492094882\n",
      "Iteataion 69: Training Accuracy: 0.9669828869047619, Validation Accuracy  0.9709821428571429\n",
      "Adjusting learning rate of group 0 to 4.8989e-02.\n",
      "Iterataion 70: Training Loss: 0.11396226434672843, Validation Loss: 0.12457112779431953\n",
      "Iteataion 70: Training Accuracy: 0.9695870535714286, Validation Accuracy  0.96875\n",
      "Adjusting learning rate of group 0 to 4.8499e-02.\n",
      "Iterataion 71: Training Loss: 0.10217881000818249, Validation Loss: 0.12724813805302468\n",
      "Iteataion 71: Training Accuracy: 0.9701450892857143, Validation Accuracy  0.9668898809523809\n",
      "Adjusting learning rate of group 0 to 4.8014e-02.\n",
      "Iterataion 72: Training Loss: 0.09942518890707079, Validation Loss: 0.12031407096627646\n",
      "Iteataion 72: Training Accuracy: 0.9728422619047619, Validation Accuracy  0.9694940476190477\n",
      "Adjusting learning rate of group 0 to 4.7534e-02.\n",
      "Iterataion 73: Training Loss: 0.11862489293346148, Validation Loss: 0.13564281492698482\n",
      "Iteataion 73: Training Accuracy: 0.9692150297619048, Validation Accuracy  0.9683779761904762\n",
      "Adjusting learning rate of group 0 to 4.7059e-02.\n",
      "Iterataion 74: Training Loss: 0.10461599769037284, Validation Loss: 0.12025740143002533\n",
      "Iteataion 74: Training Accuracy: 0.9725632440476191, Validation Accuracy  0.9754464285714286\n",
      "Adjusting learning rate of group 0 to 4.6588e-02.\n",
      "Iterataion 75: Training Loss: 0.11276954003682214, Validation Loss: 0.11999356587667291\n",
      "Iteataion 75: Training Accuracy: 0.970703125, Validation Accuracy  0.9720982142857143\n",
      "Adjusting learning rate of group 0 to 4.6122e-02.\n",
      "Iterataion 76: Training Loss: 0.10339649995331636, Validation Loss: 0.17625948791278573\n",
      "Iteataion 76: Training Accuracy: 0.9724702380952381, Validation Accuracy  0.9676339285714286\n",
      "Adjusting learning rate of group 0 to 4.5661e-02.\n",
      "Iterataion 77: Training Loss: 0.10189512197463634, Validation Loss: 0.15068540567668473\n",
      "Iteataion 77: Training Accuracy: 0.9713541666666666, Validation Accuracy  0.9694940476190477\n",
      "Adjusting learning rate of group 0 to 4.5204e-02.\n",
      "Iterataion 78: Training Loss: 0.09811433176314849, Validation Loss: 0.10562054201869703\n",
      "Iteataion 78: Training Accuracy: 0.9719122023809523, Validation Accuracy  0.9758184523809523\n",
      "Adjusting learning rate of group 0 to 4.4752e-02.\n",
      "Iterataion 79: Training Loss: 0.1291224367381213, Validation Loss: 0.12055461413068015\n",
      "Iteataion 79: Training Accuracy: 0.9670758928571429, Validation Accuracy  0.9728422619047619\n",
      "Adjusting learning rate of group 0 to 4.4305e-02.\n",
      "Iterataion 80: Training Loss: 0.09026287469321383, Validation Loss: 0.12406284973116183\n",
      "Iteataion 80: Training Accuracy: 0.9748883928571429, Validation Accuracy  0.9717261904761905\n",
      "Adjusting learning rate of group 0 to 4.3862e-02.\n",
      "Iterataion 81: Training Loss: 0.10182661726000067, Validation Loss: 0.16978280498396334\n",
      "Iteataion 81: Training Accuracy: 0.9749813988095238, Validation Accuracy  0.9706101190476191\n",
      "Adjusting learning rate of group 0 to 4.3423e-02.\n",
      "Iterataion 82: Training Loss: 0.09875754240766435, Validation Loss: 0.12566563521125695\n",
      "Iteataion 82: Training Accuracy: 0.9721912202380952, Validation Accuracy  0.9735863095238095\n",
      "Adjusting learning rate of group 0 to 4.2989e-02.\n",
      "Iterataion 83: Training Loss: 0.09279759769735044, Validation Loss: 0.12300306224695794\n",
      "Iteataion 83: Training Accuracy: 0.9762834821428571, Validation Accuracy  0.9717261904761905\n",
      "Adjusting learning rate of group 0 to 4.2559e-02.\n",
      "Iterataion 84: Training Loss: 0.09009463672699061, Validation Loss: 0.12090104329967644\n",
      "Iteataion 84: Training Accuracy: 0.9748883928571429, Validation Accuracy  0.9717261904761905\n",
      "Adjusting learning rate of group 0 to 4.2133e-02.\n",
      "Iterataion 85: Training Loss: 0.09131490840147177, Validation Loss: 0.16466028084297005\n",
      "Iteataion 85: Training Accuracy: 0.9745163690476191, Validation Accuracy  0.9639136904761905\n",
      "Adjusting learning rate of group 0 to 4.1712e-02.\n",
      "Iterataion 86: Training Loss: 0.09645642436661585, Validation Loss: 0.10852473101964812\n",
      "Iteataion 86: Training Accuracy: 0.9727492559523809, Validation Accuracy  0.9747023809523809\n",
      "Adjusting learning rate of group 0 to 4.1295e-02.\n",
      "Iterataion 87: Training Loss: 0.0841223736165348, Validation Loss: 0.12287928563792531\n",
      "Iteataion 87: Training Accuracy: 0.9783296130952381, Validation Accuracy  0.9732142857142857\n",
      "Adjusting learning rate of group 0 to 4.0882e-02.\n",
      "Iterataion 88: Training Loss: 0.08438563736679847, Validation Loss: 0.1340924585465251\n",
      "Iteataion 88: Training Accuracy: 0.9780505952380952, Validation Accuracy  0.9724702380952381\n",
      "Adjusting learning rate of group 0 to 4.0473e-02.\n",
      "Iterataion 89: Training Loss: 0.10734134099674886, Validation Loss: 0.10672751032724613\n",
      "Iteataion 89: Training Accuracy: 0.9714471726190477, Validation Accuracy  0.9739583333333334\n",
      "Adjusting learning rate of group 0 to 4.0068e-02.\n",
      "Iterataion 90: Training Loss: 0.08792101336966553, Validation Loss: 0.10994289899472057\n",
      "Iteataion 90: Training Accuracy: 0.9760044642857143, Validation Accuracy  0.9739583333333334\n",
      "Adjusting learning rate of group 0 to 3.9668e-02.\n",
      "Iterataion 91: Training Loss: 0.0899334482982487, Validation Loss: 0.11982345504958819\n",
      "Iteataion 91: Training Accuracy: 0.9769345238095238, Validation Accuracy  0.9735863095238095\n",
      "Adjusting learning rate of group 0 to 3.9271e-02.\n",
      "Iterataion 92: Training Loss: 0.12401577999848805, Validation Loss: 0.11614073113333888\n",
      "Iteataion 92: Training Accuracy: 0.9696800595238095, Validation Accuracy  0.9717261904761905\n",
      "Adjusting learning rate of group 0 to 3.8878e-02.\n",
      "Iterataion 93: Training Loss: 0.08355285915194782, Validation Loss: 0.11873809259566592\n",
      "Iteataion 93: Training Accuracy: 0.9769345238095238, Validation Accuracy  0.9720982142857143\n",
      "Adjusting learning rate of group 0 to 3.8490e-02.\n",
      "Iterataion 94: Training Loss: 0.09414056687431778, Validation Loss: 0.13373187714733364\n",
      "Iteataion 94: Training Accuracy: 0.9733072916666666, Validation Accuracy  0.9720982142857143\n",
      "Adjusting learning rate of group 0 to 3.8105e-02.\n",
      "Iterataion 95: Training Loss: 0.07490963519489516, Validation Loss: 0.1375001452454343\n",
      "Iteataion 95: Training Accuracy: 0.9782366071428571, Validation Accuracy  0.9709821428571429\n",
      "Adjusting learning rate of group 0 to 3.7724e-02.\n",
      "Iterataion 96: Training Loss: 0.07824024227364156, Validation Loss: 0.11656056854465022\n",
      "Iteataion 96: Training Accuracy: 0.9768415178571429, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 3.7346e-02.\n",
      "Iterataion 97: Training Loss: 0.08039123682907509, Validation Loss: 0.12683645164503193\n",
      "Iteataion 97: Training Accuracy: 0.9778645833333334, Validation Accuracy  0.9713541666666666\n",
      "Adjusting learning rate of group 0 to 3.6973e-02.\n",
      "Iterataion 98: Training Loss: 0.08937364704572334, Validation Loss: 0.12832042075148442\n",
      "Iteataion 98: Training Accuracy: 0.9744233630952381, Validation Accuracy  0.9754464285714286\n",
      "Adjusting learning rate of group 0 to 3.6603e-02.\n",
      "Iterataion 99: Training Loss: 0.07464113931902154, Validation Loss: 0.15771501000243715\n",
      "Iteataion 99: Training Accuracy: 0.9789806547619048, Validation Accuracy  0.9713541666666666\n",
      "Adjusting learning rate of group 0 to 3.6237e-02.\n",
      "Iterataion 100: Training Loss: 0.08164624130063339, Validation Loss: 0.13201577627531638\n",
      "Iteataion 100: Training Accuracy: 0.9771205357142857, Validation Accuracy  0.9735863095238095\n",
      "Adjusting learning rate of group 0 to 3.5875e-02.\n",
      "Iterataion 101: Training Loss: 0.07284286489966743, Validation Loss: 0.12810833576112624\n",
      "Iteataion 101: Training Accuracy: 0.9793526785714286, Validation Accuracy  0.9713541666666666\n",
      "Adjusting learning rate of group 0 to 3.5516e-02.\n",
      "Iterataion 102: Training Loss: 0.07691074971076169, Validation Loss: 0.1203722539471417\n",
      "Iteataion 102: Training Accuracy: 0.9799107142857143, Validation Accuracy  0.9735863095238095\n",
      "Adjusting learning rate of group 0 to 3.5161e-02.\n",
      "Iterataion 103: Training Loss: 0.08033133777761887, Validation Loss: 0.10039519016608232\n",
      "Iteataion 103: Training Accuracy: 0.9781436011904762, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 3.4809e-02.\n",
      "Iterataion 104: Training Loss: 0.08327536289942657, Validation Loss: 0.1220428731019904\n",
      "Iteataion 104: Training Accuracy: 0.9767485119047619, Validation Accuracy  0.9747023809523809\n",
      "Adjusting learning rate of group 0 to 3.4461e-02.\n",
      "Iterataion 105: Training Loss: 0.06860593597622153, Validation Loss: 0.11544424603216169\n",
      "Iteataion 105: Training Accuracy: 0.9789806547619048, Validation Accuracy  0.9743303571428571\n",
      "Adjusting learning rate of group 0 to 3.4117e-02.\n",
      "Iterataion 106: Training Loss: 0.07486429274316408, Validation Loss: 0.12387365755829506\n",
      "Iteataion 106: Training Accuracy: 0.9800967261904762, Validation Accuracy  0.9732142857142857\n",
      "Adjusting learning rate of group 0 to 3.3775e-02.\n",
      "Iterataion 107: Training Loss: 0.07578047659961942, Validation Loss: 0.11843751021092985\n",
      "Iteataion 107: Training Accuracy: 0.9794456845238095, Validation Accuracy  0.9735863095238095\n",
      "Adjusting learning rate of group 0 to 3.3438e-02.\n",
      "Iterataion 108: Training Loss: 0.08317041288905158, Validation Loss: 0.1521993004376205\n",
      "Iteataion 108: Training Accuracy: 0.9782366071428571, Validation Accuracy  0.9706101190476191\n",
      "Adjusting learning rate of group 0 to 3.3103e-02.\n",
      "Iterataion 109: Training Loss: 0.08128495157757651, Validation Loss: 0.11381546892907198\n",
      "Iteataion 109: Training Accuracy: 0.9773995535714286, Validation Accuracy  0.9724702380952381\n",
      "Adjusting learning rate of group 0 to 3.2772e-02.\n",
      "Iterataion 110: Training Loss: 0.06970026434404765, Validation Loss: 0.09604518561873858\n",
      "Iteataion 110: Training Accuracy: 0.9789806547619048, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 3.2445e-02.\n",
      "Iterataion 111: Training Loss: 0.06840544847303076, Validation Loss: 0.12403255039485307\n",
      "Iteataion 111: Training Accuracy: 0.9813988095238095, Validation Accuracy  0.9747023809523809\n",
      "Adjusting learning rate of group 0 to 3.2120e-02.\n",
      "Iterataion 112: Training Loss: 0.07515787208051293, Validation Loss: 0.12268493513054238\n",
      "Iteataion 112: Training Accuracy: 0.9783296130952381, Validation Accuracy  0.9735863095238095\n",
      "Adjusting learning rate of group 0 to 3.1799e-02.\n",
      "Iterataion 113: Training Loss: 0.07512547071287018, Validation Loss: 0.11127913266238643\n",
      "Iteataion 113: Training Accuracy: 0.9805617559523809, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 3.1481e-02.\n",
      "Iterataion 114: Training Loss: 0.06426816567789741, Validation Loss: 0.12065454081791203\n",
      "Iteataion 114: Training Accuracy: 0.9806547619047619, Validation Accuracy  0.9747023809523809\n",
      "Adjusting learning rate of group 0 to 3.1166e-02.\n",
      "Iterataion 115: Training Loss: 0.06936484406573955, Validation Loss: 0.1095103146621912\n",
      "Iteataion 115: Training Accuracy: 0.9801897321428571, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 3.0854e-02.\n",
      "Iterataion 116: Training Loss: 0.08120340135361175, Validation Loss: 0.12087453954012656\n",
      "Iteataion 116: Training Accuracy: 0.9797247023809523, Validation Accuracy  0.9743303571428571\n",
      "Adjusting learning rate of group 0 to 3.0546e-02.\n",
      "Iterataion 117: Training Loss: 0.07036633803481292, Validation Loss: 0.11053084039197462\n",
      "Iteataion 117: Training Accuracy: 0.9801897321428571, Validation Accuracy  0.9747023809523809\n",
      "Adjusting learning rate of group 0 to 3.0240e-02.\n",
      "Iterataion 118: Training Loss: 0.05627151735930029, Validation Loss: 0.13134385365992785\n",
      "Iteataion 118: Training Accuracy: 0.9828869047619048, Validation Accuracy  0.9680059523809523\n",
      "Adjusting learning rate of group 0 to 2.9938e-02.\n",
      "Iterataion 119: Training Loss: 0.06398149141428357, Validation Loss: 0.12142945391057831\n",
      "Iteataion 119: Training Accuracy: 0.9800967261904762, Validation Accuracy  0.9750744047619048\n",
      "Adjusting learning rate of group 0 to 2.9639e-02.\n",
      "Iterataion 120: Training Loss: 0.058013494352358363, Validation Loss: 0.13785113402210722\n",
      "Iteataion 120: Training Accuracy: 0.982421875, Validation Accuracy  0.9739583333333334\n",
      "Adjusting learning rate of group 0 to 2.9342e-02.\n",
      "Iterataion 121: Training Loss: 0.067579292399463, Validation Loss: 0.10977681782437353\n",
      "Iteataion 121: Training Accuracy: 0.9807477678571429, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 2.9049e-02.\n",
      "Iterataion 122: Training Loss: 0.0569563817837928, Validation Loss: 0.14178614011715826\n",
      "Iteataion 122: Training Accuracy: 0.9827008928571429, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 2.8758e-02.\n",
      "Iterataion 123: Training Loss: 0.05315433445659851, Validation Loss: 0.1214126362351746\n",
      "Iteataion 123: Training Accuracy: 0.9834449404761905, Validation Accuracy  0.9758184523809523\n",
      "Adjusting learning rate of group 0 to 2.8471e-02.\n",
      "Iterataion 124: Training Loss: 0.05925296041222211, Validation Loss: 0.14307187112593434\n",
      "Iteataion 124: Training Accuracy: 0.9820498511904762, Validation Accuracy  0.9739583333333334\n",
      "Adjusting learning rate of group 0 to 2.8186e-02.\n",
      "Iterataion 125: Training Loss: 0.06068794033629541, Validation Loss: 0.10888094713956845\n",
      "Iteataion 125: Training Accuracy: 0.9835379464285714, Validation Accuracy  0.9750744047619048\n",
      "Adjusting learning rate of group 0 to 2.7904e-02.\n",
      "Iterataion 126: Training Loss: 0.08425673419849468, Validation Loss: 0.14491431926172682\n",
      "Iteataion 126: Training Accuracy: 0.9813988095238095, Validation Accuracy  0.9720982142857143\n",
      "Adjusting learning rate of group 0 to 2.7625e-02.\n",
      "Iterataion 127: Training Loss: 0.057294379281225855, Validation Loss: 0.12540513269671397\n",
      "Iteataion 127: Training Accuracy: 0.9830729166666666, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 2.7349e-02.\n",
      "Iterataion 128: Training Loss: 0.05839694081247968, Validation Loss: 0.12100575592868575\n",
      "Iteataion 128: Training Accuracy: 0.9826078869047619, Validation Accuracy  0.9747023809523809\n",
      "Adjusting learning rate of group 0 to 2.7075e-02.\n",
      "Iterataion 129: Training Loss: 0.056487815900744795, Validation Loss: 0.13712634024687292\n",
      "Iteataion 129: Training Accuracy: 0.9838169642857143, Validation Accuracy  0.9743303571428571\n",
      "Adjusting learning rate of group 0 to 2.6805e-02.\n",
      "Iterataion 130: Training Loss: 0.06297489735827654, Validation Loss: 0.13906741046869173\n",
      "Iteataion 130: Training Accuracy: 0.982421875, Validation Accuracy  0.9743303571428571\n",
      "Adjusting learning rate of group 0 to 2.6537e-02.\n",
      "Iterataion 131: Training Loss: 0.06354559430278124, Validation Loss: 0.10891234076286598\n",
      "Iteataion 131: Training Accuracy: 0.9818638392857143, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 2.6271e-02.\n",
      "Iterataion 132: Training Loss: 0.04647206885650933, Validation Loss: 0.12025472987727148\n",
      "Iteataion 132: Training Accuracy: 0.9867931547619048, Validation Accuracy  0.9743303571428571\n",
      "Adjusting learning rate of group 0 to 2.6009e-02.\n",
      "Iterataion 133: Training Loss: 0.057467177674776604, Validation Loss: 0.1410681221452428\n",
      "Iteataion 133: Training Accuracy: 0.9833519345238095, Validation Accuracy  0.9747023809523809\n",
      "Adjusting learning rate of group 0 to 2.5748e-02.\n",
      "Iterataion 134: Training Loss: 0.05721431646585286, Validation Loss: 0.15602508687028072\n",
      "Iteataion 134: Training Accuracy: 0.9841889880952381, Validation Accuracy  0.9709821428571429\n",
      "Adjusting learning rate of group 0 to 2.5491e-02.\n",
      "Iterataion 135: Training Loss: 0.06105982997276246, Validation Loss: 0.18300536545220672\n",
      "Iteataion 135: Training Accuracy: 0.9827008928571429, Validation Accuracy  0.9702380952380952\n",
      "Adjusting learning rate of group 0 to 2.5236e-02.\n",
      "Iterataion 136: Training Loss: 0.059643487408366835, Validation Loss: 0.12376523941255561\n",
      "Iteataion 136: Training Accuracy: 0.9831659226190477, Validation Accuracy  0.9743303571428571\n",
      "Adjusting learning rate of group 0 to 2.4984e-02.\n",
      "Iterataion 137: Training Loss: 0.058475803792989715, Validation Loss: 0.11957789939351199\n",
      "Iteataion 137: Training Accuracy: 0.9835379464285714, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 2.4734e-02.\n",
      "Iterataion 138: Training Loss: 0.052446622223018886, Validation Loss: 0.1180728250239953\n",
      "Iteataion 138: Training Accuracy: 0.9862351190476191, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 2.4487e-02.\n",
      "Iterataion 139: Training Loss: 0.05410424807711231, Validation Loss: 0.12787860684187674\n",
      "Iteataion 139: Training Accuracy: 0.984375, Validation Accuracy  0.9754464285714286\n",
      "Adjusting learning rate of group 0 to 2.4242e-02.\n",
      "Iterataion 140: Training Loss: 0.05333609000952569, Validation Loss: 0.12098147218660792\n",
      "Iteataion 140: Training Accuracy: 0.9839099702380952, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 2.3999e-02.\n",
      "Iterataion 141: Training Loss: 0.04574107407441664, Validation Loss: 0.18142446609804544\n",
      "Iteataion 141: Training Accuracy: 0.9852120535714286, Validation Accuracy  0.9754464285714286\n",
      "Adjusting learning rate of group 0 to 2.3759e-02.\n",
      "Iterataion 142: Training Loss: 0.05138199924474616, Validation Loss: 0.11634994386808901\n",
      "Iteataion 142: Training Accuracy: 0.9850260416666666, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 2.3522e-02.\n",
      "Iterataion 143: Training Loss: 0.052052549942547155, Validation Loss: 0.12685436561203947\n",
      "Iteataion 143: Training Accuracy: 0.9851190476190477, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 2.3286e-02.\n",
      "Iterataion 144: Training Loss: 0.06801779174474543, Validation Loss: 0.1239000349532722\n",
      "Iteataion 144: Training Accuracy: 0.9837239583333334, Validation Accuracy  0.9758184523809523\n",
      "Adjusting learning rate of group 0 to 2.3054e-02.\n",
      "Iterataion 145: Training Loss: 0.055211924324592876, Validation Loss: 0.13919792576443132\n",
      "Iteataion 145: Training Accuracy: 0.9846540178571429, Validation Accuracy  0.9735863095238095\n",
      "Adjusting learning rate of group 0 to 2.2823e-02.\n",
      "Iterataion 146: Training Loss: 0.05183291417674836, Validation Loss: 0.1355685984783965\n",
      "Iteataion 146: Training Accuracy: 0.9866071428571429, Validation Accuracy  0.9747023809523809\n",
      "Adjusting learning rate of group 0 to 2.2595e-02.\n",
      "Iterataion 147: Training Loss: 0.054107241209841776, Validation Loss: 0.13857403941588795\n",
      "Iteataion 147: Training Accuracy: 0.9856770833333334, Validation Accuracy  0.9735863095238095\n",
      "Adjusting learning rate of group 0 to 2.2369e-02.\n",
      "Iterataion 148: Training Loss: 0.04993551893962804, Validation Loss: 0.1351817352924405\n",
      "Iteataion 148: Training Accuracy: 0.9869791666666666, Validation Accuracy  0.9754464285714286\n",
      "Adjusting learning rate of group 0 to 2.2145e-02.\n",
      "Iterataion 149: Training Loss: 0.045763034388857954, Validation Loss: 0.12968697432405885\n",
      "Iteataion 149: Training Accuracy: 0.9871651785714286, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 2.1924e-02.\n",
      "Iterataion 150: Training Loss: 0.05201568060922632, Validation Loss: 0.1570884168784066\n",
      "Iteataion 150: Training Accuracy: 0.9842819940476191, Validation Accuracy  0.9739583333333334\n",
      "Adjusting learning rate of group 0 to 2.1704e-02.\n",
      "Iterataion 151: Training Loss: 0.049899746978956605, Validation Loss: 0.11878064016970556\n",
      "Iteataion 151: Training Accuracy: 0.9871651785714286, Validation Accuracy  0.9743303571428571\n",
      "Adjusting learning rate of group 0 to 2.1487e-02.\n",
      "Iterataion 152: Training Loss: 0.04781205270684765, Validation Loss: 0.1418148119331951\n",
      "Iteataion 152: Training Accuracy: 0.9851190476190477, Validation Accuracy  0.9750744047619048\n",
      "Adjusting learning rate of group 0 to 2.1273e-02.\n",
      "Iterataion 153: Training Loss: 0.046549917805192624, Validation Loss: 0.13077529033691418\n",
      "Iteataion 153: Training Accuracy: 0.9867001488095238, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 2.1060e-02.\n",
      "Iterataion 154: Training Loss: 0.05112317456545944, Validation Loss: 0.12426959966286653\n",
      "Iteataion 154: Training Accuracy: 0.9844680059523809, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 2.0849e-02.\n",
      "Iterataion 155: Training Loss: 0.05314821156416601, Validation Loss: 0.13338937759172262\n",
      "Iteataion 155: Training Accuracy: 0.9851190476190477, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 2.0641e-02.\n",
      "Iterataion 156: Training Loss: 0.049862953081370114, Validation Loss: 0.13650310157639226\n",
      "Iteataion 156: Training Accuracy: 0.9862351190476191, Validation Accuracy  0.9747023809523809\n",
      "Adjusting learning rate of group 0 to 2.0434e-02.\n",
      "Iterataion 157: Training Loss: 0.042541471576251225, Validation Loss: 0.1106041372134691\n",
      "Iteataion 157: Training Accuracy: 0.9867001488095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.0230e-02.\n",
      "Iterataion 158: Training Loss: 0.047616601223126054, Validation Loss: 0.2048489377016156\n",
      "Iteataion 158: Training Accuracy: 0.9873511904761905, Validation Accuracy  0.9720982142857143\n",
      "Adjusting learning rate of group 0 to 2.0028e-02.\n",
      "Iterataion 159: Training Loss: 0.0509266444066439, Validation Loss: 0.11994983868605298\n",
      "Iteataion 159: Training Accuracy: 0.9853980654761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.9827e-02.\n",
      "Iterataion 160: Training Loss: 0.04231693813002886, Validation Loss: 0.14644564890370862\n",
      "Iteataion 160: Training Accuracy: 0.9864211309523809, Validation Accuracy  0.9743303571428571\n",
      "Adjusting learning rate of group 0 to 1.9629e-02.\n",
      "Iterataion 161: Training Loss: 0.045320026517962804, Validation Loss: 0.10282355009737175\n",
      "Iteataion 161: Training Accuracy: 0.9867001488095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.9433e-02.\n",
      "Iterataion 162: Training Loss: 0.03723940464757204, Validation Loss: 0.09908486436484609\n",
      "Iteataion 162: Training Accuracy: 0.9884672619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.9239e-02.\n",
      "Iterataion 163: Training Loss: 0.04173427120319562, Validation Loss: 0.09894047930791247\n",
      "Iteataion 163: Training Accuracy: 0.9878162202380952, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.9046e-02.\n",
      "Iterataion 164: Training Loss: 0.04968307377327189, Validation Loss: 0.11519368191635827\n",
      "Iteataion 164: Training Accuracy: 0.9860491071428571, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.8856e-02.\n",
      "Iterataion 165: Training Loss: 0.046587603604476786, Validation Loss: 0.10418900080229633\n",
      "Iteataion 165: Training Accuracy: 0.9859561011904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.8667e-02.\n",
      "Iterataion 166: Training Loss: 0.03850071247971009, Validation Loss: 0.11356009634370666\n",
      "Iteataion 166: Training Accuracy: 0.9893973214285714, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 1.8480e-02.\n",
      "Iterataion 167: Training Loss: 0.04205736674892599, Validation Loss: 0.10013301121979588\n",
      "Iteataion 167: Training Accuracy: 0.9884672619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.8296e-02.\n",
      "Iterataion 168: Training Loss: 0.04543140144882066, Validation Loss: 0.1274262982045823\n",
      "Iteataion 168: Training Accuracy: 0.9854910714285714, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.8113e-02.\n",
      "Iterataion 169: Training Loss: 0.04123289084262744, Validation Loss: 0.12359475350098276\n",
      "Iteataion 169: Training Accuracy: 0.9877232142857143, Validation Accuracy  0.9754464285714286\n",
      "Adjusting learning rate of group 0 to 1.7932e-02.\n",
      "Iterataion 170: Training Loss: 0.03890581670479325, Validation Loss: 0.09292017676435955\n",
      "Iteataion 170: Training Accuracy: 0.9873511904761905, Validation Accuracy  0.9802827380952381\n",
      "Adjusting learning rate of group 0 to 1.7752e-02.\n",
      "Iterataion 171: Training Loss: 0.040861640405746365, Validation Loss: 0.115186261325484\n",
      "Iteataion 171: Training Accuracy: 0.9889322916666666, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.7575e-02.\n",
      "Iterataion 172: Training Loss: 0.039772227180642106, Validation Loss: 0.1361116301381915\n",
      "Iteataion 172: Training Accuracy: 0.9884672619047619, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 1.7399e-02.\n",
      "Iterataion 173: Training Loss: 0.04327237247461509, Validation Loss: 0.11202140107591886\n",
      "Iteataion 173: Training Accuracy: 0.9880022321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.7225e-02.\n",
      "Iterataion 174: Training Loss: 0.04049479834105217, Validation Loss: 0.12043060192543013\n",
      "Iteataion 174: Training Accuracy: 0.9872581845238095, Validation Accuracy  0.9802827380952381\n",
      "Adjusting learning rate of group 0 to 1.7053e-02.\n",
      "Iterataion 175: Training Loss: 0.0391816010790693, Validation Loss: 0.13705338862520167\n",
      "Iteataion 175: Training Accuracy: 0.9877232142857143, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.6882e-02.\n",
      "Iterataion 176: Training Loss: 0.03945444801942206, Validation Loss: 0.12174052495236803\n",
      "Iteataion 176: Training Accuracy: 0.9894903273809523, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.6713e-02.\n",
      "Iterataion 177: Training Loss: 0.05124722293460976, Validation Loss: 0.11438406338324635\n",
      "Iteataion 177: Training Accuracy: 0.9866071428571429, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.6546e-02.\n",
      "Iterataion 178: Training Loss: 0.04655698219503828, Validation Loss: 0.12584004950391628\n",
      "Iteataion 178: Training Accuracy: 0.9853050595238095, Validation Accuracy  0.9732142857142857\n",
      "Adjusting learning rate of group 0 to 1.6381e-02.\n",
      "Iterataion 179: Training Loss: 0.03865611456853232, Validation Loss: 0.11196832754081343\n",
      "Iteataion 179: Training Accuracy: 0.9883742559523809, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.6217e-02.\n",
      "Iterataion 180: Training Loss: 0.03443871311492058, Validation Loss: 0.11409339325207217\n",
      "Iteataion 180: Training Accuracy: 0.9889322916666666, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 1.6055e-02.\n",
      "Iterataion 181: Training Loss: 0.04254487174713683, Validation Loss: 0.10415836361168725\n",
      "Iteataion 181: Training Accuracy: 0.9873511904761905, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.5894e-02.\n",
      "Iterataion 182: Training Loss: 0.03948673442100917, Validation Loss: 0.09844869643268062\n",
      "Iteataion 182: Training Accuracy: 0.9887462797619048, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.5735e-02.\n",
      "Iterataion 183: Training Loss: 0.03854736857517751, Validation Loss: 0.09907173202373087\n",
      "Iteataion 183: Training Accuracy: 0.9894903273809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.5578e-02.\n",
      "Iterataion 184: Training Loss: 0.03991508000658568, Validation Loss: 0.11072601598301311\n",
      "Iteataion 184: Training Accuracy: 0.9880022321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.5422e-02.\n",
      "Iterataion 185: Training Loss: 0.04514268093218213, Validation Loss: 0.1180451704507194\n",
      "Iteataion 185: Training Accuracy: 0.98828125, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 1.5268e-02.\n",
      "Iterataion 186: Training Loss: 0.03909561393815957, Validation Loss: 0.11556494611928739\n",
      "Iteataion 186: Training Accuracy: 0.9880952380952381, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.5115e-02.\n",
      "Iterataion 187: Training Loss: 0.035786630946886305, Validation Loss: 0.1372734185921528\n",
      "Iteataion 187: Training Accuracy: 0.9893043154761905, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.4964e-02.\n",
      "Iterataion 188: Training Loss: 0.039978895307111434, Validation Loss: 0.11368049979891355\n",
      "Iteataion 188: Training Accuracy: 0.9884672619047619, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.4814e-02.\n",
      "Iterataion 189: Training Loss: 0.035018930809773106, Validation Loss: 0.10208116027117684\n",
      "Iteataion 189: Training Accuracy: 0.9890252976190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4666e-02.\n",
      "Iterataion 190: Training Loss: 0.040190709601463134, Validation Loss: 0.10812385412069356\n",
      "Iteataion 190: Training Accuracy: 0.9880952380952381, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.4520e-02.\n",
      "Iterataion 191: Training Loss: 0.03431401288549522, Validation Loss: 0.10380392404636596\n",
      "Iteataion 191: Training Accuracy: 0.9894903273809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4374e-02.\n",
      "Iterataion 192: Training Loss: 0.03437845013801477, Validation Loss: 0.11840726338644944\n",
      "Iteataion 192: Training Accuracy: 0.9897693452380952, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.4231e-02.\n",
      "Iterataion 193: Training Loss: 0.029267317512278963, Validation Loss: 0.1194170391096211\n",
      "Iteataion 193: Training Accuracy: 0.9906994047619048, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.4088e-02.\n",
      "Iterataion 194: Training Loss: 0.033079472889783544, Validation Loss: 0.09863045430605913\n",
      "Iteataion 194: Training Accuracy: 0.9889322916666666, Validation Accuracy  0.9806547619047619\n",
      "Adjusting learning rate of group 0 to 1.3948e-02.\n",
      "Iterataion 195: Training Loss: 0.03613530508239759, Validation Loss: 0.13380512195389446\n",
      "Iteataion 195: Training Accuracy: 0.9878162202380952, Validation Accuracy  0.9758184523809523\n",
      "Adjusting learning rate of group 0 to 1.3808e-02.\n",
      "Iterataion 196: Training Loss: 0.03239198242771456, Validation Loss: 0.09846974115977745\n",
      "Iteataion 196: Training Accuracy: 0.9899553571428571, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.3670e-02.\n",
      "Iterataion 197: Training Loss: 0.03671002980951822, Validation Loss: 0.09874105387049295\n",
      "Iteataion 197: Training Accuracy: 0.9890252976190477, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.3533e-02.\n",
      "Iterataion 198: Training Loss: 0.040573538649091107, Validation Loss: 0.14118974388395322\n",
      "Iteataion 198: Training Accuracy: 0.9891183035714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.3398e-02.\n",
      "Iterataion 199: Training Loss: 0.038407800965914556, Validation Loss: 0.14542570497795212\n",
      "Iteataion 199: Training Accuracy: 0.9896763392857143, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.3264e-02.\n",
      "Iterataion 200: Training Loss: 0.030778114368837928, Validation Loss: 0.10788432587926253\n",
      "Iteataion 200: Training Accuracy: 0.9904203869047619, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.3131e-02.\n",
      "Iterataion 201: Training Loss: 0.03349913042707893, Validation Loss: 0.11982382945829957\n",
      "Iteataion 201: Training Accuracy: 0.990234375, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.3000e-02.\n",
      "Iterataion 202: Training Loss: 0.033417594745967116, Validation Loss: 0.14501631220450578\n",
      "Iteataion 202: Training Accuracy: 0.9906063988095238, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.2870e-02.\n",
      "Iterataion 203: Training Loss: 0.03357091873624881, Validation Loss: 0.1252856301882009\n",
      "Iteataion 203: Training Accuracy: 0.9910714285714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.2741e-02.\n",
      "Iterataion 204: Training Loss: 0.03074887780121299, Validation Loss: 0.12753190525534858\n",
      "Iteataion 204: Training Accuracy: 0.9900483630952381, Validation Accuracy  0.9802827380952381\n",
      "Adjusting learning rate of group 0 to 1.2614e-02.\n",
      "Iterataion 205: Training Loss: 0.030727389063630366, Validation Loss: 0.13086963861487896\n",
      "Iteataion 205: Training Accuracy: 0.9905133928571429, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 1.2488e-02.\n",
      "Iterataion 206: Training Loss: 0.03432651506430152, Validation Loss: 0.1386189857475096\n",
      "Iteataion 206: Training Accuracy: 0.9894903273809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.2363e-02.\n",
      "Iterataion 207: Training Loss: 0.03551485740808313, Validation Loss: 0.12519291249137918\n",
      "Iteataion 207: Training Accuracy: 0.9903273809523809, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 1.2239e-02.\n",
      "Iterataion 208: Training Loss: 0.02740320513543567, Validation Loss: 0.12324417668690042\n",
      "Iteataion 208: Training Accuracy: 0.9909784226190477, Validation Accuracy  0.9813988095238095\n",
      "Adjusting learning rate of group 0 to 1.2117e-02.\n",
      "Iterataion 209: Training Loss: 0.028265570592927093, Validation Loss: 0.10445934301810111\n",
      "Iteataion 209: Training Accuracy: 0.9906063988095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1996e-02.\n",
      "Iterataion 210: Training Loss: 0.030216348089813116, Validation Loss: 0.13991886632880424\n",
      "Iteataion 210: Training Accuracy: 0.9906994047619048, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.1876e-02.\n",
      "Iterataion 211: Training Loss: 0.02800907786729227, Validation Loss: 0.08738394337706268\n",
      "Iteataion 211: Training Accuracy: 0.9918154761904762, Validation Accuracy  0.9810267857142857\n",
      "Adjusting learning rate of group 0 to 1.1757e-02.\n",
      "Iterataion 212: Training Loss: 0.03425710197694287, Validation Loss: 0.10484831251783251\n",
      "Iteataion 212: Training Accuracy: 0.9901413690476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1639e-02.\n",
      "Iterataion 213: Training Loss: 0.027039086312323272, Validation Loss: 0.109633774090581\n",
      "Iteataion 213: Training Accuracy: 0.9910714285714286, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1523e-02.\n",
      "Iterataion 214: Training Loss: 0.03873664647909606, Validation Loss: 0.13050569497934747\n",
      "Iteataion 214: Training Accuracy: 0.9890252976190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1408e-02.\n",
      "Iterataion 215: Training Loss: 0.03405916709578345, Validation Loss: 0.12128249554122549\n",
      "Iteataion 215: Training Accuracy: 0.9895833333333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.1294e-02.\n",
      "Iterataion 216: Training Loss: 0.03060901037509369, Validation Loss: 0.16093908592195408\n",
      "Iteataion 216: Training Accuracy: 0.9904203869047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1181e-02.\n",
      "Iterataion 217: Training Loss: 0.02848553450493711, Validation Loss: 0.1289426162384632\n",
      "Iteataion 217: Training Accuracy: 0.9915364583333334, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.1069e-02.\n",
      "Iterataion 218: Training Loss: 0.029773873976197563, Validation Loss: 0.14433993704662454\n",
      "Iteataion 218: Training Accuracy: 0.9910714285714286, Validation Accuracy  0.9750744047619048\n",
      "Adjusting learning rate of group 0 to 1.0958e-02.\n",
      "Iterataion 219: Training Loss: 0.029268048951837294, Validation Loss: 0.12841241756772123\n",
      "Iteataion 219: Training Accuracy: 0.9918154761904762, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.0849e-02.\n",
      "Iterataion 220: Training Loss: 0.027616195941154293, Validation Loss: 0.11904917186603131\n",
      "Iteataion 220: Training Accuracy: 0.9920014880952381, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 1.0740e-02.\n",
      "Iterataion 221: Training Loss: 0.026047303267436737, Validation Loss: 0.1125919559470764\n",
      "Iteataion 221: Training Accuracy: 0.9911644345238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0633e-02.\n",
      "Iterataion 222: Training Loss: 0.026526915829651013, Validation Loss: 0.11847583175545967\n",
      "Iteataion 222: Training Accuracy: 0.9920014880952381, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0526e-02.\n",
      "Iterataion 223: Training Loss: 0.02938360062324648, Validation Loss: 0.09738659307292503\n",
      "Iteataion 223: Training Accuracy: 0.9906994047619048, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0421e-02.\n",
      "Iterataion 224: Training Loss: 0.032179748680593145, Validation Loss: 0.12679964036499036\n",
      "Iteataion 224: Training Accuracy: 0.9893973214285714, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.0317e-02.\n",
      "Iterataion 225: Training Loss: 0.029297650034656515, Validation Loss: 0.12808303751346722\n",
      "Iteataion 225: Training Accuracy: 0.9909784226190477, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.0214e-02.\n",
      "Iterataion 226: Training Loss: 0.030160578411117106, Validation Loss: 0.1471218761828978\n",
      "Iteataion 226: Training Accuracy: 0.9906994047619048, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.0112e-02.\n",
      "Iterataion 227: Training Loss: 0.028862879657560212, Validation Loss: 0.11587321582511521\n",
      "Iteataion 227: Training Accuracy: 0.9909784226190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0011e-02.\n",
      "Iterataion 228: Training Loss: 0.024342165677808225, Validation Loss: 0.1087707629506817\n",
      "Iteataion 228: Training Accuracy: 0.9919084821428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.9105e-03.\n",
      "Iterataion 229: Training Loss: 0.029998242487004417, Validation Loss: 0.11304192989496742\n",
      "Iteataion 229: Training Accuracy: 0.9913504464285714, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 9.8114e-03.\n",
      "Iterataion 230: Training Loss: 0.02563906599966876, Validation Loss: 0.14248705378779006\n",
      "Iteataion 230: Training Accuracy: 0.9918154761904762, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 9.7133e-03.\n",
      "Iterataion 231: Training Loss: 0.026220149589245192, Validation Loss: 0.12696160179869523\n",
      "Iteataion 231: Training Accuracy: 0.9917224702380952, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 9.6161e-03.\n",
      "Iterataion 232: Training Loss: 0.02620174343109376, Validation Loss: 0.12208203783417802\n",
      "Iteataion 232: Training Accuracy: 0.9917224702380952, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 9.5200e-03.\n",
      "Iterataion 233: Training Loss: 0.03333080885025622, Validation Loss: 0.11838526767678559\n",
      "Iteataion 233: Training Accuracy: 0.9899553571428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 9.4248e-03.\n",
      "Iterataion 234: Training Loss: 0.02661313602427567, Validation Loss: 0.11142672271263308\n",
      "Iteataion 234: Training Accuracy: 0.9916294642857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.3305e-03.\n",
      "Iterataion 235: Training Loss: 0.026661010143280164, Validation Loss: 0.1311544433077116\n",
      "Iteataion 235: Training Accuracy: 0.9917224702380952, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 9.2372e-03.\n",
      "Iterataion 236: Training Loss: 0.02262425952393026, Validation Loss: 0.12592697061496083\n",
      "Iteataion 236: Training Accuracy: 0.9931175595238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.1448e-03.\n",
      "Iterataion 237: Training Loss: 0.027494448969770824, Validation Loss: 0.11570498935321755\n",
      "Iteataion 237: Training Accuracy: 0.9913504464285714, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 9.0534e-03.\n",
      "Iterataion 238: Training Loss: 0.030027982032255544, Validation Loss: 0.10588522814782109\n",
      "Iteataion 238: Training Accuracy: 0.9904203869047619, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 8.9629e-03.\n",
      "Iterataion 239: Training Loss: 0.026216915545115124, Validation Loss: 0.11498220284361528\n",
      "Iteataion 239: Training Accuracy: 0.990234375, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 8.8732e-03.\n",
      "Iterataion 240: Training Loss: 0.025985703294020435, Validation Loss: 0.10918882834475215\n",
      "Iteataion 240: Training Accuracy: 0.9923735119047619, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 8.7845e-03.\n",
      "Iterataion 241: Training Loss: 0.030118485409027514, Validation Loss: 0.11426017448737673\n",
      "Iteataion 241: Training Accuracy: 0.9908854166666666, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 8.6967e-03.\n",
      "Iterataion 242: Training Loss: 0.026479096692836213, Validation Loss: 0.10256921118920351\n",
      "Iteataion 242: Training Accuracy: 0.9914434523809523, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 8.6097e-03.\n",
      "Iterataion 243: Training Loss: 0.02716244086846263, Validation Loss: 0.11359608959883633\n",
      "Iteataion 243: Training Accuracy: 0.9919084821428571, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 8.5236e-03.\n",
      "Iterataion 244: Training Loss: 0.026459459129311032, Validation Loss: 0.12442044883103269\n",
      "Iteataion 244: Training Accuracy: 0.9912574404761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.4384e-03.\n",
      "Iterataion 245: Training Loss: 0.025881727262327594, Validation Loss: 0.13595721111121792\n",
      "Iteataion 245: Training Accuracy: 0.9911644345238095, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 8.3540e-03.\n",
      "Iterataion 246: Training Loss: 0.026594778248192574, Validation Loss: 0.13741565279367313\n",
      "Iteataion 246: Training Accuracy: 0.9920944940476191, Validation Accuracy  0.9758184523809523\n",
      "Adjusting learning rate of group 0 to 8.2704e-03.\n",
      "Iterataion 247: Training Loss: 0.027194020554456792, Validation Loss: 0.12426196959255854\n",
      "Iteataion 247: Training Accuracy: 0.9920014880952381, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 8.1877e-03.\n",
      "Iterataion 248: Training Loss: 0.0280993444371751, Validation Loss: 0.15510210128523771\n",
      "Iteataion 248: Training Accuracy: 0.9923735119047619, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 8.1059e-03.\n",
      "Iterataion 249: Training Loss: 0.02588424075347466, Validation Loss: 0.145198885098713\n",
      "Iteataion 249: Training Accuracy: 0.9925595238095238, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 8.0248e-03.\n",
      "Iterataion 250: Training Loss: 0.023862976889672528, Validation Loss: 0.12908786199646208\n",
      "Iteataion 250: Training Accuracy: 0.9920944940476191, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 7.9445e-03.\n",
      "Iterataion 251: Training Loss: 0.02655944541935993, Validation Loss: 0.13553917952018177\n",
      "Iteataion 251: Training Accuracy: 0.9910714285714286, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 7.8651e-03.\n",
      "Iterataion 252: Training Loss: 0.029036786253522233, Validation Loss: 0.10611771050522603\n",
      "Iteataion 252: Training Accuracy: 0.9910714285714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.7864e-03.\n",
      "Iterataion 253: Training Loss: 0.02387253585003852, Validation Loss: 0.12277975256509352\n",
      "Iteataion 253: Training Accuracy: 0.9922805059523809, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 7.7086e-03.\n",
      "Iterataion 254: Training Loss: 0.022544012829510796, Validation Loss: 0.11862822413648956\n",
      "Iteataion 254: Training Accuracy: 0.9921875, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 7.6315e-03.\n",
      "Iterataion 255: Training Loss: 0.024970810399613828, Validation Loss: 0.11720177178589128\n",
      "Iteataion 255: Training Accuracy: 0.9922805059523809, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 7.5552e-03.\n",
      "Iterataion 256: Training Loss: 0.024758915110870437, Validation Loss: 0.13515411743258193\n",
      "Iteataion 256: Training Accuracy: 0.9924665178571429, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 7.4796e-03.\n",
      "Iterataion 257: Training Loss: 0.026465642320697647, Validation Loss: 0.12891032056962481\n",
      "Iteataion 257: Training Accuracy: 0.9915364583333334, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 7.4048e-03.\n",
      "Iterataion 258: Training Loss: 0.025694003204597596, Validation Loss: 0.12114813214838051\n",
      "Iteataion 258: Training Accuracy: 0.9928385416666666, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.3308e-03.\n",
      "Iterataion 259: Training Loss: 0.023936975373005393, Validation Loss: 0.12897591145067452\n",
      "Iteataion 259: Training Accuracy: 0.9929315476190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.2575e-03.\n",
      "Iterataion 260: Training Loss: 0.02631992054789489, Validation Loss: 0.11673505645154453\n",
      "Iteataion 260: Training Accuracy: 0.9929315476190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.1849e-03.\n",
      "Iterataion 261: Training Loss: 0.02767709384931664, Validation Loss: 0.150134813190983\n",
      "Iteataion 261: Training Accuracy: 0.9912574404761905, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 7.1131e-03.\n",
      "Iterataion 262: Training Loss: 0.02981856822881089, Validation Loss: 0.1156591780585941\n",
      "Iteataion 262: Training Accuracy: 0.9924665178571429, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.0419e-03.\n",
      "Iterataion 263: Training Loss: 0.023613906161536177, Validation Loss: 0.13437322708891658\n",
      "Iteataion 263: Training Accuracy: 0.9921875, Validation Accuracy  0.9758184523809523\n",
      "Adjusting learning rate of group 0 to 6.9715e-03.\n",
      "Iterataion 264: Training Loss: 0.02517744834244831, Validation Loss: 0.1216842794120766\n",
      "Iteataion 264: Training Accuracy: 0.9925595238095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.9018e-03.\n",
      "Iterataion 265: Training Loss: 0.02631320763681876, Validation Loss: 0.11111150009603035\n",
      "Iteataion 265: Training Accuracy: 0.9924665178571429, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.8328e-03.\n",
      "Iterataion 266: Training Loss: 0.027268833743581203, Validation Loss: 0.11565058034413107\n",
      "Iteataion 266: Training Accuracy: 0.9911644345238095, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 6.7644e-03.\n",
      "Iterataion 267: Training Loss: 0.022762712268967426, Validation Loss: 0.11377146143875108\n",
      "Iteataion 267: Training Accuracy: 0.9931175595238095, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 6.6968e-03.\n",
      "Iterataion 268: Training Loss: 0.024225630842757126, Validation Loss: 0.10777404653362749\n",
      "Iteataion 268: Training Accuracy: 0.9926525297619048, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.6298e-03.\n",
      "Iterataion 269: Training Loss: 0.022058170700785956, Validation Loss: 0.11914839089859458\n",
      "Iteataion 269: Training Accuracy: 0.9931175595238095, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 6.5635e-03.\n",
      "Iterataion 270: Training Loss: 0.021237561145998136, Validation Loss: 0.11892377729698016\n",
      "Iteataion 270: Training Accuracy: 0.9928385416666666, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 6.4979e-03.\n",
      "Iterataion 271: Training Loss: 0.020347105613128913, Validation Loss: 0.12032452631009198\n",
      "Iteataion 271: Training Accuracy: 0.9932105654761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.4329e-03.\n",
      "Iterataion 272: Training Loss: 0.024966889376121904, Validation Loss: 0.1170909459356264\n",
      "Iteataion 272: Training Accuracy: 0.9917224702380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.3686e-03.\n",
      "Iterataion 273: Training Loss: 0.027329551206600522, Validation Loss: 0.11475027375854552\n",
      "Iteataion 273: Training Accuracy: 0.9930245535714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.3049e-03.\n",
      "Iterataion 274: Training Loss: 0.020296752572054055, Validation Loss: 0.12156515004590335\n",
      "Iteataion 274: Training Accuracy: 0.9936755952380952, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 6.2419e-03.\n",
      "Iterataion 275: Training Loss: 0.019593742855233392, Validation Loss: 0.11903295007239027\n",
      "Iteataion 275: Training Accuracy: 0.9938616071428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.1794e-03.\n",
      "Iterataion 276: Training Loss: 0.024711448401575183, Validation Loss: 0.10372992092743516\n",
      "Iteataion 276: Training Accuracy: 0.9922805059523809, Validation Accuracy  0.9802827380952381\n",
      "Adjusting learning rate of group 0 to 6.1176e-03.\n",
      "Iterataion 277: Training Loss: 0.02223434603513737, Validation Loss: 0.11374712855804985\n",
      "Iteataion 277: Training Accuracy: 0.9932105654761905, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 6.0565e-03.\n",
      "Iterataion 278: Training Loss: 0.025019256448969913, Validation Loss: 0.11271832412017918\n",
      "Iteataion 278: Training Accuracy: 0.9933035714285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.9959e-03.\n",
      "Iterataion 279: Training Loss: 0.021833336631513708, Validation Loss: 0.11908872159788521\n",
      "Iteataion 279: Training Accuracy: 0.9923735119047619, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.9359e-03.\n",
      "Iterataion 280: Training Loss: 0.022613791820682405, Validation Loss: 0.12175372010664787\n",
      "Iteataion 280: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.8766e-03.\n",
      "Iterataion 281: Training Loss: 0.019949446144042548, Validation Loss: 0.12611384713090956\n",
      "Iteataion 281: Training Accuracy: 0.9931175595238095, Validation Accuracy  0.9750744047619048\n",
      "Adjusting learning rate of group 0 to 5.8178e-03.\n",
      "Iterataion 282: Training Loss: 0.0246083886097018, Validation Loss: 0.11742641794972303\n",
      "Iteataion 282: Training Accuracy: 0.9933035714285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.7596e-03.\n",
      "Iterataion 283: Training Loss: 0.021271143232689735, Validation Loss: 0.12580848534920866\n",
      "Iteataion 283: Training Accuracy: 0.9928385416666666, Validation Accuracy  0.9754464285714286\n",
      "Adjusting learning rate of group 0 to 5.7020e-03.\n",
      "Iterataion 284: Training Loss: 0.018529692795448294, Validation Loss: 0.1284584485039842\n",
      "Iteataion 284: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 5.6450e-03.\n",
      "Iterataion 285: Training Loss: 0.021314384532161057, Validation Loss: 0.1263201233118818\n",
      "Iteataion 285: Training Accuracy: 0.9930245535714286, Validation Accuracy  0.9758184523809523\n",
      "Adjusting learning rate of group 0 to 5.5886e-03.\n",
      "Iterataion 286: Training Loss: 0.018107949515587154, Validation Loss: 0.12509709847920641\n",
      "Iteataion 286: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9758184523809523\n",
      "Adjusting learning rate of group 0 to 5.5327e-03.\n",
      "Iterataion 287: Training Loss: 0.02380759516991619, Validation Loss: 0.13160488637811618\n",
      "Iteataion 287: Training Accuracy: 0.9928385416666666, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 5.4774e-03.\n",
      "Iterataion 288: Training Loss: 0.019841406254228873, Validation Loss: 0.10882772312346255\n",
      "Iteataion 288: Training Accuracy: 0.9940476190476191, Validation Accuracy  0.9802827380952381\n",
      "Adjusting learning rate of group 0 to 5.4226e-03.\n",
      "Iterataion 289: Training Loss: 0.024623095459781565, Validation Loss: 0.11146898090373725\n",
      "Iteataion 289: Training Accuracy: 0.9925595238095238, Validation Accuracy  0.9810267857142857\n",
      "Adjusting learning rate of group 0 to 5.3684e-03.\n",
      "Iterataion 290: Training Loss: 0.01996049818005636, Validation Loss: 0.1184682427570451\n",
      "Iteataion 290: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.3147e-03.\n",
      "Iterataion 291: Training Loss: 0.021545437388373036, Validation Loss: 0.10593870852040355\n",
      "Iteataion 291: Training Accuracy: 0.994140625, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 5.2615e-03.\n",
      "Iterataion 292: Training Loss: 0.02187668641507737, Validation Loss: 0.1150225525432289\n",
      "Iteataion 292: Training Accuracy: 0.9930245535714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.2089e-03.\n",
      "Iterataion 293: Training Loss: 0.02125933650367988, Validation Loss: 0.11972822686203005\n",
      "Iteataion 293: Training Accuracy: 0.994140625, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 5.1568e-03.\n",
      "Iterataion 294: Training Loss: 0.019244095320328176, Validation Loss: 0.1148420086545052\n",
      "Iteataion 294: Training Accuracy: 0.9934895833333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.1053e-03.\n",
      "Iterataion 295: Training Loss: 0.02015891902686883, Validation Loss: 0.10881733559867049\n",
      "Iteataion 295: Training Accuracy: 0.9936755952380952, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.0542e-03.\n",
      "Iterataion 296: Training Loss: 0.023781039763916798, Validation Loss: 0.11217041227898401\n",
      "Iteataion 296: Training Accuracy: 0.9931175595238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.0037e-03.\n",
      "Iterataion 297: Training Loss: 0.02569600318113766, Validation Loss: 0.10542335280035509\n",
      "Iteataion 297: Training Accuracy: 0.9923735119047619, Validation Accuracy  0.9802827380952381\n",
      "Adjusting learning rate of group 0 to 4.9536e-03.\n",
      "Iterataion 298: Training Loss: 0.019912221340719096, Validation Loss: 0.10715652691631965\n",
      "Iteataion 298: Training Accuracy: 0.9934895833333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.9041e-03.\n",
      "Iterataion 299: Training Loss: 0.02037764311883833, Validation Loss: 0.11081407336154725\n",
      "Iteataion 299: Training Accuracy: 0.9933035714285714, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 4.8550e-03.\n",
      "Iterataion 300: Training Loss: 0.02094657509657415, Validation Loss: 0.11640329363687736\n",
      "Iteataion 300: Training Accuracy: 0.9934895833333334, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 4.8065e-03.\n",
      "Iterataion 301: Training Loss: 0.01879087309590067, Validation Loss: 0.11511240430636241\n",
      "Iteataion 301: Training Accuracy: 0.9935825892857143, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 4.7584e-03.\n",
      "Iterataion 302: Training Loss: 0.02129898091477013, Validation Loss: 0.11295725725216382\n",
      "Iteataion 302: Training Accuracy: 0.9920014880952381, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.7108e-03.\n",
      "Iterataion 303: Training Loss: 0.016912877297204566, Validation Loss: 0.11460766882533435\n",
      "Iteataion 303: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 4.6637e-03.\n",
      "Iterataion 304: Training Loss: 0.021808495677444348, Validation Loss: 0.1160325390945484\n",
      "Iteataion 304: Training Accuracy: 0.9933035714285714, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.6171e-03.\n",
      "Iterataion 305: Training Loss: 0.021426592642597542, Validation Loss: 0.11217628068733597\n",
      "Iteataion 305: Training Accuracy: 0.9931175595238095, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.5709e-03.\n",
      "Iterataion 306: Training Loss: 0.019452545638851442, Validation Loss: 0.11162166810514997\n",
      "Iteataion 306: Training Accuracy: 0.9933035714285714, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.5252e-03.\n",
      "Iterataion 307: Training Loss: 0.020390719432916357, Validation Loss: 0.11833318771805795\n",
      "Iteataion 307: Training Accuracy: 0.9936755952380952, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 4.4800e-03.\n",
      "Iterataion 308: Training Loss: 0.022356079262541885, Validation Loss: 0.11381292646103425\n",
      "Iteataion 308: Training Accuracy: 0.9931175595238095, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.4352e-03.\n",
      "Iterataion 309: Training Loss: 0.01807388562735583, Validation Loss: 0.11183797559848555\n",
      "Iteataion 309: Training Accuracy: 0.9938616071428571, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.3908e-03.\n",
      "Iterataion 310: Training Loss: 0.01807838253862319, Validation Loss: 0.11640587857805147\n",
      "Iteataion 310: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 4.3469e-03.\n",
      "Iterataion 311: Training Loss: 0.01781651338501025, Validation Loss: 0.11686831476484857\n",
      "Iteataion 311: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 4.3034e-03.\n",
      "Iterataion 312: Training Loss: 0.02100978724130089, Validation Loss: 0.11644325435456888\n",
      "Iteataion 312: Training Accuracy: 0.9937686011904762, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.2604e-03.\n",
      "Iterataion 313: Training Loss: 0.020694612705951812, Validation Loss: 0.11676367045317708\n",
      "Iteataion 313: Training Accuracy: 0.9938616071428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.2178e-03.\n",
      "Iterataion 314: Training Loss: 0.021451138887794208, Validation Loss: 0.11397116488163792\n",
      "Iteataion 314: Training Accuracy: 0.9937686011904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.1756e-03.\n",
      "Iterataion 315: Training Loss: 0.017591618452134715, Validation Loss: 0.12291561562579306\n",
      "Iteataion 315: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 4.1339e-03.\n",
      "Iterataion 316: Training Loss: 0.020532947547753304, Validation Loss: 0.1366529641502605\n",
      "Iteataion 316: Training Accuracy: 0.9928385416666666, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 4.0925e-03.\n",
      "Iterataion 317: Training Loss: 0.02419985478854052, Validation Loss: 0.13010664960573903\n",
      "Iteataion 317: Training Accuracy: 0.9918154761904762, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.0516e-03.\n",
      "Iterataion 318: Training Loss: 0.01701172918546945, Validation Loss: 0.12282850724508668\n",
      "Iteataion 318: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.0111e-03.\n",
      "Iterataion 319: Training Loss: 0.016700155842382863, Validation Loss: 0.12470457034196886\n",
      "Iteataion 319: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 3.9710e-03.\n",
      "Iterataion 320: Training Loss: 0.02195757211424399, Validation Loss: 0.12750057687006164\n",
      "Iteataion 320: Training Accuracy: 0.9936755952380952, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 3.9313e-03.\n",
      "Iterataion 321: Training Loss: 0.0178768987907515, Validation Loss: 0.13572324761303095\n",
      "Iteataion 321: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.8920e-03.\n",
      "Iterataion 322: Training Loss: 0.02151746230519204, Validation Loss: 0.139130369420788\n",
      "Iteataion 322: Training Accuracy: 0.9937686011904762, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 3.8530e-03.\n",
      "Iterataion 323: Training Loss: 0.01823256971958668, Validation Loss: 0.12219141821217973\n",
      "Iteataion 323: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 3.8145e-03.\n",
      "Iterataion 324: Training Loss: 0.024129137220098164, Validation Loss: 0.10940341518981746\n",
      "Iteataion 324: Training Accuracy: 0.9929315476190477, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 3.7764e-03.\n",
      "Iterataion 325: Training Loss: 0.020998900166495207, Validation Loss: 0.11122041120103038\n",
      "Iteataion 325: Training Accuracy: 0.9931175595238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.7386e-03.\n",
      "Iterataion 326: Training Loss: 0.018710370006842794, Validation Loss: 0.12397546078385104\n",
      "Iteataion 326: Training Accuracy: 0.9933035714285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.7012e-03.\n",
      "Iterataion 327: Training Loss: 0.0189864916913769, Validation Loss: 0.1216278275724773\n",
      "Iteataion 327: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9758184523809523\n",
      "Adjusting learning rate of group 0 to 3.6642e-03.\n",
      "Iterataion 328: Training Loss: 0.02021969936880099, Validation Loss: 0.11156562053905118\n",
      "Iteataion 328: Training Accuracy: 0.9938616071428571, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 3.6276e-03.\n",
      "Iterataion 329: Training Loss: 0.020059191831666417, Validation Loss: 0.11165138988233195\n",
      "Iteataion 329: Training Accuracy: 0.9937686011904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.5913e-03.\n",
      "Iterataion 330: Training Loss: 0.017810716546101574, Validation Loss: 0.10946113797097762\n",
      "Iteataion 330: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.5554e-03.\n",
      "Iterataion 331: Training Loss: 0.01778728443492081, Validation Loss: 0.11782554074803867\n",
      "Iteataion 331: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.5198e-03.\n",
      "Iterataion 332: Training Loss: 0.02007905991425916, Validation Loss: 0.11708180728459322\n",
      "Iteataion 332: Training Accuracy: 0.9939546130952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.4846e-03.\n",
      "Iterataion 333: Training Loss: 0.02003714825831142, Validation Loss: 0.12324871455046643\n",
      "Iteataion 333: Training Accuracy: 0.9933965773809523, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.4498e-03.\n",
      "Iterataion 334: Training Loss: 0.01934594868453677, Validation Loss: 0.1147778201110025\n",
      "Iteataion 334: Training Accuracy: 0.9940476190476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.4153e-03.\n",
      "Iterataion 335: Training Loss: 0.017536470855789785, Validation Loss: 0.10828788691234388\n",
      "Iteataion 335: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.3811e-03.\n",
      "Iterataion 336: Training Loss: 0.017653076713249467, Validation Loss: 0.11053134447741662\n",
      "Iteataion 336: Training Accuracy: 0.9940476190476191, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 3.3473e-03.\n",
      "Iterataion 337: Training Loss: 0.016985826478353675, Validation Loss: 0.11192105617374182\n",
      "Iteataion 337: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.3138e-03.\n",
      "Iterataion 338: Training Loss: 0.016194872356132844, Validation Loss: 0.11096482823046333\n",
      "Iteataion 338: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.2807e-03.\n",
      "Iterataion 339: Training Loss: 0.019778883076638182, Validation Loss: 0.11432779906317592\n",
      "Iteataion 339: Training Accuracy: 0.9936755952380952, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 3.2479e-03.\n",
      "Iterataion 340: Training Loss: 0.0163502438306881, Validation Loss: 0.11034281328661232\n",
      "Iteataion 340: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 3.2154e-03.\n",
      "Iterataion 341: Training Loss: 0.016598897472004444, Validation Loss: 0.10961689305684824\n",
      "Iteataion 341: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 3.1833e-03.\n",
      "Iterataion 342: Training Loss: 0.01908766296880409, Validation Loss: 0.10338973368393121\n",
      "Iteataion 342: Training Accuracy: 0.9936755952380952, Validation Accuracy  0.9810267857142857\n",
      "Adjusting learning rate of group 0 to 3.1514e-03.\n",
      "Iterataion 343: Training Loss: 0.016707357513428313, Validation Loss: 0.10655078364581597\n",
      "Iteataion 343: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 3.1199e-03.\n",
      "Iterataion 344: Training Loss: 0.01731232674527512, Validation Loss: 0.11189356353559826\n",
      "Iteataion 344: Training Accuracy: 0.9938616071428571, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 3.0887e-03.\n",
      "Iterataion 345: Training Loss: 0.02224447431104135, Validation Loss: 0.11641294267823601\n",
      "Iteataion 345: Training Accuracy: 0.9940476190476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.0578e-03.\n",
      "Iterataion 346: Training Loss: 0.022552464940532216, Validation Loss: 0.11278557857475811\n",
      "Iteataion 346: Training Accuracy: 0.9929315476190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.0272e-03.\n",
      "Iterataion 347: Training Loss: 0.020247312193641627, Validation Loss: 0.11856605456119812\n",
      "Iteataion 347: Training Accuracy: 0.994140625, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.9970e-03.\n",
      "Iterataion 348: Training Loss: 0.018863963106128492, Validation Loss: 0.11702844226681741\n",
      "Iteataion 348: Training Accuracy: 0.9935825892857143, Validation Accuracy  0.9761904761904762\n",
      "Adjusting learning rate of group 0 to 2.9670e-03.\n",
      "Iterataion 349: Training Loss: 0.017128691485731633, Validation Loss: 0.11960337471171487\n",
      "Iteataion 349: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 2.9373e-03.\n",
      "Iterataion 350: Training Loss: 0.01704530625689139, Validation Loss: 0.11420617960734157\n",
      "Iteataion 350: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.9080e-03.\n",
      "Iterataion 351: Training Loss: 0.020730959895641325, Validation Loss: 0.12040698646408755\n",
      "Iteataion 351: Training Accuracy: 0.9939546130952381, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.8789e-03.\n",
      "Iterataion 352: Training Loss: 0.018753201663452283, Validation Loss: 0.13623733357980666\n",
      "Iteataion 352: Training Accuracy: 0.9940476190476191, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 2.8501e-03.\n",
      "Iterataion 353: Training Loss: 0.017951456169753955, Validation Loss: 0.123032444054488\n",
      "Iteataion 353: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 2.8216e-03.\n",
      "Iterataion 354: Training Loss: 0.018931346221180066, Validation Loss: 0.12262211354994555\n",
      "Iteataion 354: Training Accuracy: 0.994140625, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 2.7934e-03.\n",
      "Iterataion 355: Training Loss: 0.020719327381812036, Validation Loss: 0.11990130269224188\n",
      "Iteataion 355: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.7654e-03.\n",
      "Iterataion 356: Training Loss: 0.01938718904686735, Validation Loss: 0.11693693089679383\n",
      "Iteataion 356: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.7378e-03.\n",
      "Iterataion 357: Training Loss: 0.015673815287038973, Validation Loss: 0.11287997959738189\n",
      "Iteataion 357: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.7104e-03.\n",
      "Iterataion 358: Training Loss: 0.024296612696287162, Validation Loss: 0.10812355123642015\n",
      "Iteataion 358: Training Accuracy: 0.9936755952380952, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.6833e-03.\n",
      "Iterataion 359: Training Loss: 0.016077173641648613, Validation Loss: 0.11351860882629208\n",
      "Iteataion 359: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 2.6565e-03.\n",
      "Iterataion 360: Training Loss: 0.016595122874240406, Validation Loss: 0.11084415702853442\n",
      "Iteataion 360: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.6299e-03.\n",
      "Iterataion 361: Training Loss: 0.016551139585333625, Validation Loss: 0.1061723835584594\n",
      "Iteataion 361: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 2.6036e-03.\n",
      "Iterataion 362: Training Loss: 0.017662526128540364, Validation Loss: 0.10471489666620405\n",
      "Iteataion 362: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9802827380952381\n",
      "Adjusting learning rate of group 0 to 2.5776e-03.\n",
      "Iterataion 363: Training Loss: 0.014650167921393507, Validation Loss: 0.10812396553299594\n",
      "Iteataion 363: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 2.5518e-03.\n",
      "Iterataion 364: Training Loss: 0.01483992925248371, Validation Loss: 0.10525586743975376\n",
      "Iteataion 364: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 2.5263e-03.\n",
      "Iterataion 365: Training Loss: 0.015281544474070657, Validation Loss: 0.11093800422372069\n",
      "Iteataion 365: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9810267857142857\n",
      "Adjusting learning rate of group 0 to 2.5010e-03.\n",
      "Iterataion 366: Training Loss: 0.017590610406809058, Validation Loss: 0.10871108728120239\n",
      "Iteataion 366: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.4760e-03.\n",
      "Iterataion 367: Training Loss: 0.015407752667060178, Validation Loss: 0.11085571500007063\n",
      "Iteataion 367: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 2.4512e-03.\n",
      "Iterataion 368: Training Loss: 0.017219547008395664, Validation Loss: 0.135733726437249\n",
      "Iteataion 368: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.4267e-03.\n",
      "Iterataion 369: Training Loss: 0.019992226010821425, Validation Loss: 0.12868324110551352\n",
      "Iteataion 369: Training Accuracy: 0.9937686011904762, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 2.4025e-03.\n",
      "Iterataion 370: Training Loss: 0.01523463011103749, Validation Loss: 0.12408166179978629\n",
      "Iteataion 370: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.3784e-03.\n",
      "Iterataion 371: Training Loss: 0.014832337548284273, Validation Loss: 0.11531698912887539\n",
      "Iteataion 371: Training Accuracy: 0.9940476190476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.3547e-03.\n",
      "Iterataion 372: Training Loss: 0.01581296205107948, Validation Loss: 0.11623524825966054\n",
      "Iteataion 372: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.3311e-03.\n",
      "Iterataion 373: Training Loss: 0.018178018353026203, Validation Loss: 0.122503063851604\n",
      "Iteataion 373: Training Accuracy: 0.9937686011904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.3078e-03.\n",
      "Iterataion 374: Training Loss: 0.014785154745983752, Validation Loss: 0.11499574001901215\n",
      "Iteataion 374: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.2847e-03.\n",
      "Iterataion 375: Training Loss: 0.01853649599253183, Validation Loss: 0.12544224015721006\n",
      "Iteataion 375: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.2619e-03.\n",
      "Iterataion 376: Training Loss: 0.015612182838279018, Validation Loss: 0.11976514235366045\n",
      "Iteataion 376: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.2393e-03.\n",
      "Iterataion 377: Training Loss: 0.015155206426760617, Validation Loss: 0.11928396626863992\n",
      "Iteataion 377: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.2169e-03.\n",
      "Iterataion 378: Training Loss: 0.01731149283200112, Validation Loss: 0.11335657624153012\n",
      "Iteataion 378: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.1947e-03.\n",
      "Iterataion 379: Training Loss: 0.017926464933960582, Validation Loss: 0.11773962591116022\n",
      "Iteataion 379: Training Accuracy: 0.994140625, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.1727e-03.\n",
      "Iterataion 380: Training Loss: 0.014690283577872474, Validation Loss: 0.11898361161782793\n",
      "Iteataion 380: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.1510e-03.\n",
      "Iterataion 381: Training Loss: 0.017974289527656454, Validation Loss: 0.11361223151169081\n",
      "Iteataion 381: Training Accuracy: 0.994140625, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.1295e-03.\n",
      "Iterataion 382: Training Loss: 0.016622368647148108, Validation Loss: 0.11821901922897868\n",
      "Iteataion 382: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.1082e-03.\n",
      "Iterataion 383: Training Loss: 0.016660995895048592, Validation Loss: 0.11357877039344891\n",
      "Iteataion 383: Training Accuracy: 0.994140625, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.0871e-03.\n",
      "Iterataion 384: Training Loss: 0.015499232268563198, Validation Loss: 0.12230838932062886\n",
      "Iteataion 384: Training Accuracy: 0.9940476190476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.0663e-03.\n",
      "Iterataion 385: Training Loss: 0.016483063019413366, Validation Loss: 0.11154009617876443\n",
      "Iteataion 385: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 2.0456e-03.\n",
      "Iterataion 386: Training Loss: 0.018199805311808464, Validation Loss: 0.1180725195927818\n",
      "Iteataion 386: Training Accuracy: 0.9935825892857143, Validation Accuracy  0.9806547619047619\n",
      "Adjusting learning rate of group 0 to 2.0251e-03.\n",
      "Iterataion 387: Training Loss: 0.013096819117645772, Validation Loss: 0.11045036925479951\n",
      "Iteataion 387: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 2.0049e-03.\n",
      "Iterataion 388: Training Loss: 0.01806716202768012, Validation Loss: 0.11936042974021559\n",
      "Iteataion 388: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.9848e-03.\n",
      "Iterataion 389: Training Loss: 0.017803111334936415, Validation Loss: 0.11583423191715576\n",
      "Iteataion 389: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.9650e-03.\n",
      "Iterataion 390: Training Loss: 0.018362638722508477, Validation Loss: 0.12534018845166783\n",
      "Iteataion 390: Training Accuracy: 0.9938616071428571, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.9453e-03.\n",
      "Iterataion 391: Training Loss: 0.02001772966608126, Validation Loss: 0.12164309123678632\n",
      "Iteataion 391: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.9259e-03.\n",
      "Iterataion 392: Training Loss: 0.01595731651128833, Validation Loss: 0.11854689371368916\n",
      "Iteataion 392: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.9066e-03.\n",
      "Iterataion 393: Training Loss: 0.01495370194127694, Validation Loss: 0.13057820699972714\n",
      "Iteataion 393: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.8876e-03.\n",
      "Iterataion 394: Training Loss: 0.015470659011740705, Validation Loss: 0.12421055536620637\n",
      "Iteataion 394: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.8687e-03.\n",
      "Iterataion 395: Training Loss: 0.016108812373912262, Validation Loss: 0.1307739311099484\n",
      "Iteataion 395: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.8500e-03.\n",
      "Iterataion 396: Training Loss: 0.014535269738679673, Validation Loss: 0.12360710387470246\n",
      "Iteataion 396: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.8315e-03.\n",
      "Iterataion 397: Training Loss: 0.01872405391723241, Validation Loss: 0.11286583787721877\n",
      "Iteataion 397: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.8132e-03.\n",
      "Iterataion 398: Training Loss: 0.014120139460453016, Validation Loss: 0.12108338475454508\n",
      "Iteataion 398: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.7951e-03.\n",
      "Iterataion 399: Training Loss: 0.012715992009759362, Validation Loss: 0.11698761388585653\n",
      "Iteataion 399: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.7771e-03.\n",
      "Iterataion 400: Training Loss: 0.015506548783323634, Validation Loss: 0.12448840940416586\n",
      "Iteataion 400: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.7593e-03.\n",
      "Iterataion 401: Training Loss: 0.017239836350286905, Validation Loss: 0.12617858417513894\n",
      "Iteataion 401: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.7417e-03.\n",
      "Iterataion 402: Training Loss: 0.015018123591006427, Validation Loss: 0.11317141605654686\n",
      "Iteataion 402: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.7243e-03.\n",
      "Iterataion 403: Training Loss: 0.016985205983642688, Validation Loss: 0.11365535148851029\n",
      "Iteataion 403: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.7071e-03.\n",
      "Iterataion 404: Training Loss: 0.016133729081592538, Validation Loss: 0.11231658869371863\n",
      "Iteataion 404: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.6900e-03.\n",
      "Iterataion 405: Training Loss: 0.017320436506021858, Validation Loss: 0.10805739431284232\n",
      "Iteataion 405: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.6731e-03.\n",
      "Iterataion 406: Training Loss: 0.01549513166171532, Validation Loss: 0.12643063819694628\n",
      "Iteataion 406: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 1.6564e-03.\n",
      "Iterataion 407: Training Loss: 0.014808847888897057, Validation Loss: 0.11462545583717434\n",
      "Iteataion 407: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.6398e-03.\n",
      "Iterataion 408: Training Loss: 0.017685984290612047, Validation Loss: 0.11735100826964055\n",
      "Iteataion 408: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.6234e-03.\n",
      "Iterataion 409: Training Loss: 0.019336260200623134, Validation Loss: 0.11255020409092739\n",
      "Iteataion 409: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.6072e-03.\n",
      "Iterataion 410: Training Loss: 0.013390711304093125, Validation Loss: 0.11115592096864087\n",
      "Iteataion 410: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.5911e-03.\n",
      "Iterataion 411: Training Loss: 0.018053203908493742, Validation Loss: 0.11460282577758246\n",
      "Iteataion 411: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.5752e-03.\n",
      "Iterataion 412: Training Loss: 0.01719107870556258, Validation Loss: 0.11499581204318418\n",
      "Iteataion 412: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.5594e-03.\n",
      "Iterataion 413: Training Loss: 0.016767361256416643, Validation Loss: 0.10654870025734077\n",
      "Iteataion 413: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.5439e-03.\n",
      "Iterataion 414: Training Loss: 0.015585558328284007, Validation Loss: 0.11272017146097268\n",
      "Iteataion 414: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.5284e-03.\n",
      "Iterataion 415: Training Loss: 0.015613739557207344, Validation Loss: 0.11380910624681813\n",
      "Iteataion 415: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.5131e-03.\n",
      "Iterataion 416: Training Loss: 0.016491959300896007, Validation Loss: 0.11282705111292804\n",
      "Iteataion 416: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.4980e-03.\n",
      "Iterataion 417: Training Loss: 0.01397689362126263, Validation Loss: 0.12252253476848327\n",
      "Iteataion 417: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 1.4830e-03.\n",
      "Iterataion 418: Training Loss: 0.01673864769961261, Validation Loss: 0.1197374628334329\n",
      "Iteataion 418: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.4682e-03.\n",
      "Iterataion 419: Training Loss: 0.018429967605621794, Validation Loss: 0.11141668809804975\n",
      "Iteataion 419: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4535e-03.\n",
      "Iterataion 420: Training Loss: 0.01624480905401671, Validation Loss: 0.11247016015610226\n",
      "Iteataion 420: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.4390e-03.\n",
      "Iterataion 421: Training Loss: 0.01349588814205462, Validation Loss: 0.10747849975894319\n",
      "Iteataion 421: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4246e-03.\n",
      "Iterataion 422: Training Loss: 0.013775199105193515, Validation Loss: 0.10923961751452624\n",
      "Iteataion 422: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.4103e-03.\n",
      "Iterataion 423: Training Loss: 0.01349918255362866, Validation Loss: 0.11670425955331089\n",
      "Iteataion 423: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.3962e-03.\n",
      "Iterataion 424: Training Loss: 0.012257815125359301, Validation Loss: 0.10958080143503073\n",
      "Iteataion 424: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.3823e-03.\n",
      "Iterataion 425: Training Loss: 0.014161451271118897, Validation Loss: 0.11780449879787318\n",
      "Iteataion 425: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.3684e-03.\n",
      "Iterataion 426: Training Loss: 0.01343451998117073, Validation Loss: 0.12696209952814458\n",
      "Iteataion 426: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.3548e-03.\n",
      "Iterataion 427: Training Loss: 0.016095036011632577, Validation Loss: 0.11281320640374339\n",
      "Iteataion 427: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.3412e-03.\n",
      "Iterataion 428: Training Loss: 0.01506937819625067, Validation Loss: 0.1105496820698424\n",
      "Iteataion 428: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.3278e-03.\n",
      "Iterataion 429: Training Loss: 0.015750383281687128, Validation Loss: 0.11420436077410491\n",
      "Iteataion 429: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.3145e-03.\n",
      "Iterataion 430: Training Loss: 0.01668069853020754, Validation Loss: 0.11928256304804008\n",
      "Iteataion 430: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.3014e-03.\n",
      "Iterataion 431: Training Loss: 0.014548854148998288, Validation Loss: 0.12171581500669851\n",
      "Iteataion 431: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.2884e-03.\n",
      "Iterataion 432: Training Loss: 0.01531126993376494, Validation Loss: 0.12090382122480106\n",
      "Iteataion 432: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2755e-03.\n",
      "Iterataion 433: Training Loss: 0.01821491218131582, Validation Loss: 0.12218878115243392\n",
      "Iteataion 433: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.2627e-03.\n",
      "Iterataion 434: Training Loss: 0.012634122036648413, Validation Loss: 0.11495933157715538\n",
      "Iteataion 434: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2501e-03.\n",
      "Iterataion 435: Training Loss: 0.015514845546811797, Validation Loss: 0.12162248631825716\n",
      "Iteataion 435: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.2376e-03.\n",
      "Iterataion 436: Training Loss: 0.016657287260854872, Validation Loss: 0.12162651099611028\n",
      "Iteataion 436: Training Accuracy: 0.99609375, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.2252e-03.\n",
      "Iterataion 437: Training Loss: 0.013760308429743805, Validation Loss: 0.12575241831619655\n",
      "Iteataion 437: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2130e-03.\n",
      "Iterataion 438: Training Loss: 0.015045361564784662, Validation Loss: 0.12192348004091622\n",
      "Iteataion 438: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.2008e-03.\n",
      "Iterataion 439: Training Loss: 0.017468954400929014, Validation Loss: 0.12592353338443832\n",
      "Iteataion 439: Training Accuracy: 0.9936755952380952, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.1888e-03.\n",
      "Iterataion 440: Training Loss: 0.015214431168954864, Validation Loss: 0.11932051161349547\n",
      "Iteataion 440: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.1769e-03.\n",
      "Iterataion 441: Training Loss: 0.015856344811548618, Validation Loss: 0.11507829093720719\n",
      "Iteataion 441: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1652e-03.\n",
      "Iterataion 442: Training Loss: 0.014435063561523602, Validation Loss: 0.12060541045715714\n",
      "Iteataion 442: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1535e-03.\n",
      "Iterataion 443: Training Loss: 0.01601137785177572, Validation Loss: 0.1299556310930312\n",
      "Iteataion 443: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1420e-03.\n",
      "Iterataion 444: Training Loss: 0.016267322178115835, Validation Loss: 0.1127842115096339\n",
      "Iteataion 444: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1306e-03.\n",
      "Iterataion 445: Training Loss: 0.014376708647950057, Validation Loss: 0.12051944603870918\n",
      "Iteataion 445: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1193e-03.\n",
      "Iterataion 446: Training Loss: 0.01825756329240021, Validation Loss: 0.11864186868656472\n",
      "Iteataion 446: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1081e-03.\n",
      "Iterataion 447: Training Loss: 0.019751608353435805, Validation Loss: 0.12046570548640065\n",
      "Iteataion 447: Training Accuracy: 0.9938616071428571, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.0970e-03.\n",
      "Iterataion 448: Training Loss: 0.018425756103420506, Validation Loss: 0.11839228577588162\n",
      "Iteataion 448: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0860e-03.\n",
      "Iterataion 449: Training Loss: 0.021673978151074573, Validation Loss: 0.11761749229002062\n",
      "Iteataion 449: Training Accuracy: 0.9935825892857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0752e-03.\n",
      "Iterataion 450: Training Loss: 0.014693573045106548, Validation Loss: 0.11756379005113025\n",
      "Iteataion 450: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0644e-03.\n",
      "Iterataion 451: Training Loss: 0.016825821240220643, Validation Loss: 0.12256787560607602\n",
      "Iteataion 451: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0538e-03.\n",
      "Iterataion 452: Training Loss: 0.018444291821368662, Validation Loss: 0.11720102444353582\n",
      "Iteataion 452: Training Accuracy: 0.994140625, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0432e-03.\n",
      "Iterataion 453: Training Loss: 0.01615505235030561, Validation Loss: 0.12384539057228078\n",
      "Iteataion 453: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.0328e-03.\n",
      "Iterataion 454: Training Loss: 0.018033824844145032, Validation Loss: 0.11714867443107523\n",
      "Iteataion 454: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0225e-03.\n",
      "Iterataion 455: Training Loss: 0.018758597383261685, Validation Loss: 0.11539571244899956\n",
      "Iteataion 455: Training Accuracy: 0.9938616071428571, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.0122e-03.\n",
      "Iterataion 456: Training Loss: 0.018045381797285202, Validation Loss: 0.11146750967103489\n",
      "Iteataion 456: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0021e-03.\n",
      "Iterataion 457: Training Loss: 0.01360137421292013, Validation Loss: 0.11532856780672218\n",
      "Iteataion 457: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 9.9210e-04.\n",
      "Iterataion 458: Training Loss: 0.016027018600380506, Validation Loss: 0.11956003469857955\n",
      "Iteataion 458: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.8218e-04.\n",
      "Iterataion 459: Training Loss: 0.01577377080301124, Validation Loss: 0.11797736797953115\n",
      "Iteataion 459: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.7235e-04.\n",
      "Iterataion 460: Training Loss: 0.013207247963141718, Validation Loss: 0.12090317736572881\n",
      "Iteataion 460: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.6263e-04.\n",
      "Iterataion 461: Training Loss: 0.013896409760948695, Validation Loss: 0.11445942073606136\n",
      "Iteataion 461: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.5300e-04.\n",
      "Iterataion 462: Training Loss: 0.012617330779990705, Validation Loss: 0.11736827127908062\n",
      "Iteataion 462: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.4347e-04.\n",
      "Iterataion 463: Training Loss: 0.016864172587990982, Validation Loss: 0.1235662893159315\n",
      "Iteataion 463: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.3404e-04.\n",
      "Iterataion 464: Training Loss: 0.013600191563607646, Validation Loss: 0.1136997101002191\n",
      "Iteataion 464: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.2470e-04.\n",
      "Iterataion 465: Training Loss: 0.016507504119964395, Validation Loss: 0.11360081535389238\n",
      "Iteataion 465: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.1545e-04.\n",
      "Iterataion 466: Training Loss: 0.014521295686801728, Validation Loss: 0.11134943729209737\n",
      "Iteataion 466: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.0630e-04.\n",
      "Iterataion 467: Training Loss: 0.014941624302485355, Validation Loss: 0.11010359769414474\n",
      "Iteataion 467: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 8.9724e-04.\n",
      "Iterataion 468: Training Loss: 0.018511695644754113, Validation Loss: 0.12375354078859545\n",
      "Iteataion 468: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.8826e-04.\n",
      "Iterataion 469: Training Loss: 0.0127099282505593, Validation Loss: 0.1257059884558591\n",
      "Iteataion 469: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.7938e-04.\n",
      "Iterataion 470: Training Loss: 0.015070722974114633, Validation Loss: 0.124575902687999\n",
      "Iteataion 470: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.7059e-04.\n",
      "Iterataion 471: Training Loss: 0.013937979503702038, Validation Loss: 0.1183253967631949\n",
      "Iteataion 471: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.6188e-04.\n",
      "Iterataion 472: Training Loss: 0.015541762887523928, Validation Loss: 0.1189313529587419\n",
      "Iteataion 472: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 8.5326e-04.\n",
      "Iterataion 473: Training Loss: 0.017933227237199662, Validation Loss: 0.11883342778594119\n",
      "Iteataion 473: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.4473e-04.\n",
      "Iterataion 474: Training Loss: 0.013928113880282837, Validation Loss: 0.11720735915061994\n",
      "Iteataion 474: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.3628e-04.\n",
      "Iterataion 475: Training Loss: 0.015484484470265354, Validation Loss: 0.1196979795292974\n",
      "Iteataion 475: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.2792e-04.\n",
      "Iterataion 476: Training Loss: 0.01618967993633855, Validation Loss: 0.11318583352272626\n",
      "Iteataion 476: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.1964e-04.\n",
      "Iterataion 477: Training Loss: 0.01606214151722602, Validation Loss: 0.11089585996062563\n",
      "Iteataion 477: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 8.1144e-04.\n",
      "Iterataion 478: Training Loss: 0.013989863077403063, Validation Loss: 0.11755809966452056\n",
      "Iteataion 478: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.0333e-04.\n",
      "Iterataion 479: Training Loss: 0.012573980687089922, Validation Loss: 0.1211333902731606\n",
      "Iteataion 479: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 7.9530e-04.\n",
      "Iterataion 480: Training Loss: 0.018318622039483225, Validation Loss: 0.12218072891189921\n",
      "Iteataion 480: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.8734e-04.\n",
      "Iterataion 481: Training Loss: 0.014750813906747446, Validation Loss: 0.11688818414014106\n",
      "Iteataion 481: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.7947e-04.\n",
      "Iterataion 482: Training Loss: 0.012235324820928822, Validation Loss: 0.1201598864338338\n",
      "Iteataion 482: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 7.7167e-04.\n",
      "Iterataion 483: Training Loss: 0.015083278207983932, Validation Loss: 0.12052656690839951\n",
      "Iteataion 483: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.6396e-04.\n",
      "Iterataion 484: Training Loss: 0.01328869390128526, Validation Loss: 0.1151197904510787\n",
      "Iteataion 484: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.5632e-04.\n",
      "Iterataion 485: Training Loss: 0.014926837651619498, Validation Loss: 0.11754332993125612\n",
      "Iteataion 485: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.4876e-04.\n",
      "Iterataion 486: Training Loss: 0.013347578199767134, Validation Loss: 0.11030906500868363\n",
      "Iteataion 486: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.4127e-04.\n",
      "Iterataion 487: Training Loss: 0.014406066937204785, Validation Loss: 0.11895871238510419\n",
      "Iteataion 487: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.3385e-04.\n",
      "Iterataion 488: Training Loss: 0.016110788730341205, Validation Loss: 0.11529128843486854\n",
      "Iteataion 488: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.2652e-04.\n",
      "Iterataion 489: Training Loss: 0.011331142675031177, Validation Loss: 0.11422525721221663\n",
      "Iteataion 489: Training Accuracy: 0.9968377976190477, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 7.1925e-04.\n",
      "Iterataion 490: Training Loss: 0.013097616706028145, Validation Loss: 0.11597365810586957\n",
      "Iteataion 490: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.1206e-04.\n",
      "Iterataion 491: Training Loss: 0.012632358641834918, Validation Loss: 0.11903829555305448\n",
      "Iteataion 491: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 7.0494e-04.\n",
      "Iterataion 492: Training Loss: 0.014086482832054914, Validation Loss: 0.12019041947106172\n",
      "Iteataion 492: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 6.9789e-04.\n",
      "Iterataion 493: Training Loss: 0.01250672877088613, Validation Loss: 0.12326393863782514\n",
      "Iteataion 493: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 6.9091e-04.\n",
      "Iterataion 494: Training Loss: 0.012805067400293269, Validation Loss: 0.11552012222393121\n",
      "Iteataion 494: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.8400e-04.\n",
      "Iterataion 495: Training Loss: 0.015856291359139907, Validation Loss: 0.1146208995487541\n",
      "Iteataion 495: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.7716e-04.\n",
      "Iterataion 496: Training Loss: 0.01430545377661474, Validation Loss: 0.11459090192688674\n",
      "Iteataion 496: Training Accuracy: 0.99609375, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.7039e-04.\n",
      "Iterataion 497: Training Loss: 0.015500261076422085, Validation Loss: 0.11607938317195853\n",
      "Iteataion 497: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.6369e-04.\n",
      "Iterataion 498: Training Loss: 0.01527817144851942, Validation Loss: 0.12250424471184067\n",
      "Iteataion 498: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.5705e-04.\n",
      "Iterataion 499: Training Loss: 0.01781613740726363, Validation Loss: 0.11534498371865327\n",
      "Iteataion 499: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.5048e-04.\n",
      "Iterataion 500: Training Loss: 0.016121762272627176, Validation Loss: 0.12466638653664054\n",
      "Iteataion 500: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 6.4397e-04.\n",
      "Iterataion 501: Training Loss: 0.015462682563267804, Validation Loss: 0.12365962450801418\n",
      "Iteataion 501: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 6.3753e-04.\n",
      "Iterataion 502: Training Loss: 0.014591921844120935, Validation Loss: 0.11840218085960326\n",
      "Iteataion 502: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.3116e-04.\n",
      "Iterataion 503: Training Loss: 0.013933739843109099, Validation Loss: 0.12387610936861077\n",
      "Iteataion 503: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.2485e-04.\n",
      "Iterataion 504: Training Loss: 0.01709829947355616, Validation Loss: 0.11343012403742206\n",
      "Iteataion 504: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 6.1860e-04.\n",
      "Iterataion 505: Training Loss: 0.015813908584326686, Validation Loss: 0.12014772942596365\n",
      "Iteataion 505: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.1241e-04.\n",
      "Iterataion 506: Training Loss: 0.013954593597849953, Validation Loss: 0.11903758602296342\n",
      "Iteataion 506: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.0629e-04.\n",
      "Iterataion 507: Training Loss: 0.015223759310501265, Validation Loss: 0.1202640001258881\n",
      "Iteataion 507: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 6.0022e-04.\n",
      "Iterataion 508: Training Loss: 0.014397377597375824, Validation Loss: 0.11855237655165582\n",
      "Iteataion 508: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.9422e-04.\n",
      "Iterataion 509: Training Loss: 0.014339335139563397, Validation Loss: 0.11849625990016205\n",
      "Iteataion 509: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.8828e-04.\n",
      "Iterataion 510: Training Loss: 0.0140006557151586, Validation Loss: 0.11461832140367932\n",
      "Iteataion 510: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.8240e-04.\n",
      "Iterataion 511: Training Loss: 0.011773734314619524, Validation Loss: 0.12402779934927821\n",
      "Iteataion 511: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.7657e-04.\n",
      "Iterataion 512: Training Loss: 0.013741040248026469, Validation Loss: 0.11634364538462605\n",
      "Iteataion 512: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.7081e-04.\n",
      "Iterataion 513: Training Loss: 0.014269150305932532, Validation Loss: 0.123554903948566\n",
      "Iteataion 513: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 5.6510e-04.\n",
      "Iterataion 514: Training Loss: 0.014739423629153007, Validation Loss: 0.1217964410372987\n",
      "Iteataion 514: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.5945e-04.\n",
      "Iterataion 515: Training Loss: 0.01417509012145944, Validation Loss: 0.11714286979134535\n",
      "Iteataion 515: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.5385e-04.\n",
      "Iterataion 516: Training Loss: 0.015171219600876236, Validation Loss: 0.1184446986341599\n",
      "Iteataion 516: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.4832e-04.\n",
      "Iterataion 517: Training Loss: 0.016195422264818425, Validation Loss: 0.1147837514404162\n",
      "Iteataion 517: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.4283e-04.\n",
      "Iterataion 518: Training Loss: 0.015146295213967305, Validation Loss: 0.12180615491915221\n",
      "Iteataion 518: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.3740e-04.\n",
      "Iterataion 519: Training Loss: 0.015031302274584012, Validation Loss: 0.11992381070740521\n",
      "Iteataion 519: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 5.3203e-04.\n",
      "Iterataion 520: Training Loss: 0.01394741122246982, Validation Loss: 0.12167988335373016\n",
      "Iteataion 520: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 5.2671e-04.\n",
      "Iterataion 521: Training Loss: 0.016254936772416774, Validation Loss: 0.11928745501223248\n",
      "Iteataion 521: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.2144e-04.\n",
      "Iterataion 522: Training Loss: 0.016458911710407607, Validation Loss: 0.12321927142613454\n",
      "Iteataion 522: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.1623e-04.\n",
      "Iterataion 523: Training Loss: 0.017468557982708324, Validation Loss: 0.12449951299818278\n",
      "Iteataion 523: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.1107e-04.\n",
      "Iterataion 524: Training Loss: 0.015564291740413532, Validation Loss: 0.12523764583691047\n",
      "Iteataion 524: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.0596e-04.\n",
      "Iterataion 525: Training Loss: 0.017144328789105136, Validation Loss: 0.11893768363813984\n",
      "Iteataion 525: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.0090e-04.\n",
      "Iterataion 526: Training Loss: 0.013190222863654445, Validation Loss: 0.11605351751460126\n",
      "Iteataion 526: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 4.9589e-04.\n",
      "Iterataion 527: Training Loss: 0.015029866138576323, Validation Loss: 0.11343712843500259\n",
      "Iteataion 527: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.9093e-04.\n",
      "Iterataion 528: Training Loss: 0.018451001909198964, Validation Loss: 0.11653836858075499\n",
      "Iteataion 528: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.8602e-04.\n",
      "Iterataion 529: Training Loss: 0.01584601779308025, Validation Loss: 0.11442917847165429\n",
      "Iteataion 529: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.8116e-04.\n",
      "Iterataion 530: Training Loss: 0.015527041666251523, Validation Loss: 0.11882221583481424\n",
      "Iteataion 530: Training Accuracy: 0.9937686011904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.7635e-04.\n",
      "Iterataion 531: Training Loss: 0.015346152863909997, Validation Loss: 0.11781245293578406\n",
      "Iteataion 531: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.7158e-04.\n",
      "Iterataion 532: Training Loss: 0.014010488883101432, Validation Loss: 0.12292427872023659\n",
      "Iteataion 532: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.6687e-04.\n",
      "Iterataion 533: Training Loss: 0.015002115159769526, Validation Loss: 0.12143447677457206\n",
      "Iteataion 533: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.6220e-04.\n",
      "Iterataion 534: Training Loss: 0.013153616557159869, Validation Loss: 0.12486719973697667\n",
      "Iteataion 534: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.5758e-04.\n",
      "Iterataion 535: Training Loss: 0.010740729550409972, Validation Loss: 0.12134873865473243\n",
      "Iteataion 535: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.5300e-04.\n",
      "Iterataion 536: Training Loss: 0.015505163443433735, Validation Loss: 0.11870982683627163\n",
      "Iteataion 536: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.4847e-04.\n",
      "Iterataion 537: Training Loss: 0.011579121948180799, Validation Loss: 0.12421357762295662\n",
      "Iteataion 537: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.4399e-04.\n",
      "Iterataion 538: Training Loss: 0.013485402997421424, Validation Loss: 0.11979518339276404\n",
      "Iteataion 538: Training Accuracy: 0.99609375, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 4.3955e-04.\n",
      "Iterataion 539: Training Loss: 0.013050993836678643, Validation Loss: 0.12302934694694491\n",
      "Iteataion 539: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.3515e-04.\n",
      "Iterataion 540: Training Loss: 0.016493391909066332, Validation Loss: 0.12773180763782344\n",
      "Iteataion 540: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 4.3080e-04.\n",
      "Iterataion 541: Training Loss: 0.014695389971449346, Validation Loss: 0.11914896428664555\n",
      "Iteataion 541: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.2649e-04.\n",
      "Iterataion 542: Training Loss: 0.012806668884572601, Validation Loss: 0.11810572546759121\n",
      "Iteataion 542: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 4.2223e-04.\n",
      "Iterataion 543: Training Loss: 0.015267774256010412, Validation Loss: 0.11623567643024527\n",
      "Iteataion 543: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.1800e-04.\n",
      "Iterataion 544: Training Loss: 0.012283948464646746, Validation Loss: 0.12201998899293291\n",
      "Iteataion 544: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.1382e-04.\n",
      "Iterataion 545: Training Loss: 0.01271660534161684, Validation Loss: 0.11765697194269018\n",
      "Iteataion 545: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.0969e-04.\n",
      "Iterataion 546: Training Loss: 0.014436618628853117, Validation Loss: 0.11822228231069791\n",
      "Iteataion 546: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.0559e-04.\n",
      "Iterataion 547: Training Loss: 0.015145848277945094, Validation Loss: 0.11958787435234138\n",
      "Iteataion 547: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.0153e-04.\n",
      "Iterataion 548: Training Loss: 0.016553999885392492, Validation Loss: 0.1228994769739873\n",
      "Iteataion 548: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.9752e-04.\n",
      "Iterataion 549: Training Loss: 0.017261920171799585, Validation Loss: 0.11482359363453282\n",
      "Iteataion 549: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.9354e-04.\n",
      "Iterataion 550: Training Loss: 0.01474121253146974, Validation Loss: 0.12104075252669068\n",
      "Iteataion 550: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.8961e-04.\n",
      "Iterataion 551: Training Loss: 0.014394547116718238, Validation Loss: 0.11925202022056754\n",
      "Iteataion 551: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.8571e-04.\n",
      "Iterataion 552: Training Loss: 0.015146902179405439, Validation Loss: 0.12071275331148106\n",
      "Iteataion 552: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.8185e-04.\n",
      "Iterataion 553: Training Loss: 0.01198961206556376, Validation Loss: 0.11454236639021873\n",
      "Iteataion 553: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.7804e-04.\n",
      "Iterataion 554: Training Loss: 0.015456468008059875, Validation Loss: 0.11629780635902114\n",
      "Iteataion 554: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.7426e-04.\n",
      "Iterataion 555: Training Loss: 0.011692741251248074, Validation Loss: 0.1152735047763577\n",
      "Iteataion 555: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.7051e-04.\n",
      "Iterataion 556: Training Loss: 0.011110500123910886, Validation Loss: 0.12117206034528819\n",
      "Iteataion 556: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.6681e-04.\n",
      "Iterataion 557: Training Loss: 0.013194843151810172, Validation Loss: 0.12125538761454929\n",
      "Iteataion 557: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.6314e-04.\n",
      "Iterataion 558: Training Loss: 0.011294425247323527, Validation Loss: 0.11925502395024523\n",
      "Iteataion 558: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.5951e-04.\n",
      "Iterataion 559: Training Loss: 0.015559635894696512, Validation Loss: 0.11735403281920476\n",
      "Iteataion 559: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.5591e-04.\n",
      "Iterataion 560: Training Loss: 0.015127697215041893, Validation Loss: 0.12235454971569863\n",
      "Iteataion 560: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.5235e-04.\n",
      "Iterataion 561: Training Loss: 0.014470112174372942, Validation Loss: 0.12523712293903638\n",
      "Iteataion 561: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.4883e-04.\n",
      "Iterataion 562: Training Loss: 0.013144702658274707, Validation Loss: 0.123319952111271\n",
      "Iteataion 562: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 3.4534e-04.\n",
      "Iterataion 563: Training Loss: 0.014061447998200693, Validation Loss: 0.11868911097252105\n",
      "Iteataion 563: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.4189e-04.\n",
      "Iterataion 564: Training Loss: 0.013166402533516556, Validation Loss: 0.1175468079121102\n",
      "Iteataion 564: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.3847e-04.\n",
      "Iterataion 565: Training Loss: 0.014706465934297282, Validation Loss: 0.11866345299157972\n",
      "Iteataion 565: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.3509e-04.\n",
      "Iterataion 566: Training Loss: 0.014308026843302755, Validation Loss: 0.11994139844460822\n",
      "Iteataion 566: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 3.3173e-04.\n",
      "Iterataion 567: Training Loss: 0.013273250144309627, Validation Loss: 0.12167687464800732\n",
      "Iteataion 567: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.2842e-04.\n",
      "Iterataion 568: Training Loss: 0.01404812157172905, Validation Loss: 0.11934731557124817\n",
      "Iteataion 568: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.2513e-04.\n",
      "Iterataion 569: Training Loss: 0.015452504488444346, Validation Loss: 0.12083203759521427\n",
      "Iteataion 569: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.2188e-04.\n",
      "Iterataion 570: Training Loss: 0.014488647581066959, Validation Loss: 0.12169604709303779\n",
      "Iteataion 570: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.1866e-04.\n",
      "Iterataion 571: Training Loss: 0.014042263135870271, Validation Loss: 0.1195520849773524\n",
      "Iteataion 571: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.1548e-04.\n",
      "Iterataion 572: Training Loss: 0.015762874917587277, Validation Loss: 0.12080767502860598\n",
      "Iteataion 572: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.1232e-04.\n",
      "Iterataion 573: Training Loss: 0.013874086744464309, Validation Loss: 0.12584790895499925\n",
      "Iteataion 573: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.0920e-04.\n",
      "Iterataion 574: Training Loss: 0.0120542438200279, Validation Loss: 0.11662572991846856\n",
      "Iteataion 574: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.0611e-04.\n",
      "Iterataion 575: Training Loss: 0.017294543163019965, Validation Loss: 0.11847718278366345\n",
      "Iteataion 575: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.0305e-04.\n",
      "Iterataion 576: Training Loss: 0.010074329447289818, Validation Loss: 0.11596252878264683\n",
      "Iteataion 576: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.0001e-04.\n",
      "Iterataion 577: Training Loss: 0.012821369053841942, Validation Loss: 0.1193082119613636\n",
      "Iteataion 577: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.9701e-04.\n",
      "Iterataion 578: Training Loss: 0.013974615228766698, Validation Loss: 0.12190395296429193\n",
      "Iteataion 578: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.9404e-04.\n",
      "Iterataion 579: Training Loss: 0.013169963339421742, Validation Loss: 0.11881332677539165\n",
      "Iteataion 579: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.9110e-04.\n",
      "Iterataion 580: Training Loss: 0.013821700133012418, Validation Loss: 0.12302054829963642\n",
      "Iteataion 580: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.8819e-04.\n",
      "Iterataion 581: Training Loss: 0.0149823404149038, Validation Loss: 0.11943902573747016\n",
      "Iteataion 581: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.8531e-04.\n",
      "Iterataion 582: Training Loss: 0.011412302754132055, Validation Loss: 0.11863980174104388\n",
      "Iteataion 582: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9802827380952381\n",
      "Adjusting learning rate of group 0 to 2.8246e-04.\n",
      "Iterataion 583: Training Loss: 0.014790655048926567, Validation Loss: 0.12358610318808975\n",
      "Iteataion 583: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.7963e-04.\n",
      "Iterataion 584: Training Loss: 0.01395009947026812, Validation Loss: 0.12522069298273247\n",
      "Iteataion 584: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.7684e-04.\n",
      "Iterataion 585: Training Loss: 0.012631770632924054, Validation Loss: 0.12320169881014607\n",
      "Iteataion 585: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 2.7407e-04.\n",
      "Iterataion 586: Training Loss: 0.013821467832337318, Validation Loss: 0.11858711198324383\n",
      "Iteataion 586: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.7133e-04.\n",
      "Iterataion 587: Training Loss: 0.014757594565441274, Validation Loss: 0.12395424543732278\n",
      "Iteataion 587: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.6861e-04.\n",
      "Iterataion 588: Training Loss: 0.013467986572360965, Validation Loss: 0.12398295042320813\n",
      "Iteataion 588: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.6593e-04.\n",
      "Iterataion 589: Training Loss: 0.019864933531798287, Validation Loss: 0.11749167650052142\n",
      "Iteataion 589: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.6327e-04.\n",
      "Iterataion 590: Training Loss: 0.012412203996564947, Validation Loss: 0.11771500942285923\n",
      "Iteataion 590: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.6064e-04.\n",
      "Iterataion 591: Training Loss: 0.01145522729047535, Validation Loss: 0.1176763592109016\n",
      "Iteataion 591: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.5803e-04.\n",
      "Iterataion 592: Training Loss: 0.012151262481016537, Validation Loss: 0.12242356750534893\n",
      "Iteataion 592: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.5545e-04.\n",
      "Iterataion 593: Training Loss: 0.01367774149709699, Validation Loss: 0.1190617139260966\n",
      "Iteataion 593: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.5290e-04.\n",
      "Iterataion 594: Training Loss: 0.013567973550445327, Validation Loss: 0.11831481460831128\n",
      "Iteataion 594: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.5037e-04.\n",
      "Iterataion 595: Training Loss: 0.015149800435564631, Validation Loss: 0.1261725116602043\n",
      "Iteataion 595: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.4786e-04.\n",
      "Iterataion 596: Training Loss: 0.014956192278322724, Validation Loss: 0.11740304062727884\n",
      "Iteataion 596: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.4538e-04.\n",
      "Iterataion 597: Training Loss: 0.015789855064016985, Validation Loss: 0.1168344346749619\n",
      "Iteataion 597: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.4293e-04.\n",
      "Iterataion 598: Training Loss: 0.014554618833751089, Validation Loss: 0.12450484275568004\n",
      "Iteataion 598: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.4050e-04.\n",
      "Iterataion 599: Training Loss: 0.010993632191860446, Validation Loss: 0.11892673531092884\n",
      "Iteataion 599: Training Accuracy: 0.9970238095238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.3810e-04.\n",
      "Iterataion 600: Training Loss: 0.012458568148023565, Validation Loss: 0.12156783782013851\n",
      "Iteataion 600: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.3571e-04.\n",
      "Iterataion 601: Training Loss: 0.013995519532504197, Validation Loss: 0.11477121323199443\n",
      "Iteataion 601: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.3336e-04.\n",
      "Iterataion 602: Training Loss: 0.014109093545828694, Validation Loss: 0.12056089830641611\n",
      "Iteataion 602: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.3102e-04.\n",
      "Iterataion 603: Training Loss: 0.014649597763412906, Validation Loss: 0.12100921323375277\n",
      "Iteataion 603: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.2871e-04.\n",
      "Iterataion 604: Training Loss: 0.015390343410952832, Validation Loss: 0.1177687987744831\n",
      "Iteataion 604: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.2643e-04.\n",
      "Iterataion 605: Training Loss: 0.015621567273778773, Validation Loss: 0.1138984430794286\n",
      "Iteataion 605: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.2416e-04.\n",
      "Iterataion 606: Training Loss: 0.015499862860212058, Validation Loss: 0.11798539181188794\n",
      "Iteataion 606: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.2192e-04.\n",
      "Iterataion 607: Training Loss: 0.014530571567105174, Validation Loss: 0.11958229081512134\n",
      "Iteataion 607: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.1970e-04.\n",
      "Iterataion 608: Training Loss: 0.01329541989584024, Validation Loss: 0.11636215442416781\n",
      "Iteataion 608: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.1750e-04.\n",
      "Iterataion 609: Training Loss: 0.012491390094771692, Validation Loss: 0.11981071066963146\n",
      "Iteataion 609: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.1533e-04.\n",
      "Iterataion 610: Training Loss: 0.0154170405447642, Validation Loss: 0.11476829293944942\n",
      "Iteataion 610: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.1318e-04.\n",
      "Iterataion 611: Training Loss: 0.018603946225721847, Validation Loss: 0.11567891421358714\n",
      "Iteataion 611: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.1104e-04.\n",
      "Iterataion 612: Training Loss: 0.012775633505386618, Validation Loss: 0.11277110525406897\n",
      "Iteataion 612: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.0893e-04.\n",
      "Iterataion 613: Training Loss: 0.013737654702077079, Validation Loss: 0.11540538525186116\n",
      "Iteataion 613: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.0684e-04.\n",
      "Iterataion 614: Training Loss: 0.012716805486567598, Validation Loss: 0.1172033203538598\n",
      "Iteataion 614: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 2.0478e-04.\n",
      "Iterataion 615: Training Loss: 0.01164574440273116, Validation Loss: 0.11795887708516292\n",
      "Iteataion 615: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.0273e-04.\n",
      "Iterataion 616: Training Loss: 0.012521691017708891, Validation Loss: 0.11634604565844667\n",
      "Iteataion 616: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.0070e-04.\n",
      "Iterataion 617: Training Loss: 0.015775961973418587, Validation Loss: 0.11944923595036948\n",
      "Iteataion 617: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.9869e-04.\n",
      "Iterataion 618: Training Loss: 0.015286305741878215, Validation Loss: 0.11907202811704426\n",
      "Iteataion 618: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.9671e-04.\n",
      "Iterataion 619: Training Loss: 0.016346244174571607, Validation Loss: 0.11795368548283898\n",
      "Iteataion 619: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.9474e-04.\n",
      "Iterataion 620: Training Loss: 0.014018227089360959, Validation Loss: 0.12161512237337486\n",
      "Iteataion 620: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.9279e-04.\n",
      "Iterataion 621: Training Loss: 0.014412098787453104, Validation Loss: 0.11869926141751022\n",
      "Iteataion 621: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.9086e-04.\n",
      "Iterataion 622: Training Loss: 0.017518712614954333, Validation Loss: 0.11834262116391939\n",
      "Iteataion 622: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.8896e-04.\n",
      "Iterataion 623: Training Loss: 0.013930149606434617, Validation Loss: 0.11603320025975203\n",
      "Iteataion 623: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.8707e-04.\n",
      "Iterataion 624: Training Loss: 0.012740705570786031, Validation Loss: 0.12022979205570797\n",
      "Iteataion 624: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.8520e-04.\n",
      "Iterataion 625: Training Loss: 0.013999620869736227, Validation Loss: 0.11770479549602719\n",
      "Iteataion 625: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.8334e-04.\n",
      "Iterataion 626: Training Loss: 0.014591355847116716, Validation Loss: 0.12714308319704198\n",
      "Iteataion 626: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.8151e-04.\n",
      "Iterataion 627: Training Loss: 0.014048940865382201, Validation Loss: 0.12165696710268627\n",
      "Iteataion 627: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.7970e-04.\n",
      "Iterataion 628: Training Loss: 0.013293361341131817, Validation Loss: 0.11723430001563052\n",
      "Iteataion 628: Training Accuracy: 0.99609375, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.7790e-04.\n",
      "Iterataion 629: Training Loss: 0.011854355083360243, Validation Loss: 0.11877764093905414\n",
      "Iteataion 629: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.7612e-04.\n",
      "Iterataion 630: Training Loss: 0.014414748251521793, Validation Loss: 0.12002139730185907\n",
      "Iteataion 630: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.7436e-04.\n",
      "Iterataion 631: Training Loss: 0.0120803728869776, Validation Loss: 0.1178412277722822\n",
      "Iteataion 631: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.7261e-04.\n",
      "Iterataion 632: Training Loss: 0.01380693800151376, Validation Loss: 0.11744670821609339\n",
      "Iteataion 632: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.7089e-04.\n",
      "Iterataion 633: Training Loss: 0.015551223698968603, Validation Loss: 0.11859036263407821\n",
      "Iteataion 633: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.6918e-04.\n",
      "Iterataion 634: Training Loss: 0.013265012879681657, Validation Loss: 0.12261469928241085\n",
      "Iteataion 634: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.6749e-04.\n",
      "Iterataion 635: Training Loss: 0.013658438362550648, Validation Loss: 0.12084722466108094\n",
      "Iteataion 635: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.6581e-04.\n",
      "Iterataion 636: Training Loss: 0.020336855364639958, Validation Loss: 0.12209267833798261\n",
      "Iteataion 636: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6416e-04.\n",
      "Iterataion 637: Training Loss: 0.011705739394528791, Validation Loss: 0.12074577885327815\n",
      "Iteataion 637: Training Accuracy: 0.9969308035714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6251e-04.\n",
      "Iterataion 638: Training Loss: 0.015394963002359372, Validation Loss: 0.12039944713526382\n",
      "Iteataion 638: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.6089e-04.\n",
      "Iterataion 639: Training Loss: 0.012863662147031494, Validation Loss: 0.1181968582578276\n",
      "Iteataion 639: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.5928e-04.\n",
      "Iterataion 640: Training Loss: 0.014650461060227826, Validation Loss: 0.12054156825207628\n",
      "Iteataion 640: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.5769e-04.\n",
      "Iterataion 641: Training Loss: 0.014396746112396216, Validation Loss: 0.1196040796604371\n",
      "Iteataion 641: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.5611e-04.\n",
      "Iterataion 642: Training Loss: 0.016128306936550728, Validation Loss: 0.11562936838216535\n",
      "Iteataion 642: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.5455e-04.\n",
      "Iterataion 643: Training Loss: 0.012504011957939647, Validation Loss: 0.12491074236246144\n",
      "Iteataion 643: Training Accuracy: 0.99609375, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.5300e-04.\n",
      "Iterataion 644: Training Loss: 0.01258446934910402, Validation Loss: 0.12076331519879537\n",
      "Iteataion 644: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.5147e-04.\n",
      "Iterataion 645: Training Loss: 0.012612676641117492, Validation Loss: 0.11917091371128108\n",
      "Iteataion 645: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.4996e-04.\n",
      "Iterataion 646: Training Loss: 0.01894599956552314, Validation Loss: 0.12308959428947873\n",
      "Iteataion 646: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.4846e-04.\n",
      "Iterataion 647: Training Loss: 0.013438067713182162, Validation Loss: 0.12197198141820548\n",
      "Iteataion 647: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.4697e-04.\n",
      "Iterataion 648: Training Loss: 0.016273756552638186, Validation Loss: 0.11885389923217433\n",
      "Iteataion 648: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.4550e-04.\n",
      "Iterataion 649: Training Loss: 0.015892752755571345, Validation Loss: 0.12531195062627198\n",
      "Iteataion 649: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.4405e-04.\n",
      "Iterataion 650: Training Loss: 0.014360921147201366, Validation Loss: 0.12771544024836634\n",
      "Iteataion 650: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4261e-04.\n",
      "Iterataion 651: Training Loss: 0.01313302632662451, Validation Loss: 0.12156965425337392\n",
      "Iteataion 651: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.4118e-04.\n",
      "Iterataion 652: Training Loss: 0.013793854487461768, Validation Loss: 0.12119015837769682\n",
      "Iteataion 652: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.3977e-04.\n",
      "Iterataion 653: Training Loss: 0.011925880005652877, Validation Loss: 0.12207674312337143\n",
      "Iteataion 653: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.3837e-04.\n",
      "Iterataion 654: Training Loss: 0.012873311013835176, Validation Loss: 0.12569738465514624\n",
      "Iteataion 654: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.3699e-04.\n",
      "Iterataion 655: Training Loss: 0.013584567025836424, Validation Loss: 0.12036357815207051\n",
      "Iteataion 655: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.3562e-04.\n",
      "Iterataion 656: Training Loss: 0.0127226416959879, Validation Loss: 0.12082624289479743\n",
      "Iteataion 656: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.3426e-04.\n",
      "Iterataion 657: Training Loss: 0.015369224063194674, Validation Loss: 0.11708076413516409\n",
      "Iteataion 657: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.3292e-04.\n",
      "Iterataion 658: Training Loss: 0.013608616881677601, Validation Loss: 0.12016048278125775\n",
      "Iteataion 658: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.3159e-04.\n",
      "Iterataion 659: Training Loss: 0.013593776304202299, Validation Loss: 0.11925661660412826\n",
      "Iteataion 659: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.3028e-04.\n",
      "Iterataion 660: Training Loss: 0.01572205186392805, Validation Loss: 0.1246326182679296\n",
      "Iteataion 660: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.2897e-04.\n",
      "Iterataion 661: Training Loss: 0.01133497027174185, Validation Loss: 0.12142243129825901\n",
      "Iteataion 661: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.2768e-04.\n",
      "Iterataion 662: Training Loss: 0.015731099103145234, Validation Loss: 0.12146854179161715\n",
      "Iteataion 662: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.2641e-04.\n",
      "Iterataion 663: Training Loss: 0.011869635038749833, Validation Loss: 0.1263067409191735\n",
      "Iteataion 663: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2514e-04.\n",
      "Iterataion 664: Training Loss: 0.014597990691960192, Validation Loss: 0.12434923893874283\n",
      "Iteataion 664: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.2389e-04.\n",
      "Iterataion 665: Training Loss: 0.014499943688076859, Validation Loss: 0.1198728391417961\n",
      "Iteataion 665: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.2265e-04.\n",
      "Iterataion 666: Training Loss: 0.012137613368003133, Validation Loss: 0.12382882078058972\n",
      "Iteataion 666: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2143e-04.\n",
      "Iterataion 667: Training Loss: 0.015124594349369497, Validation Loss: 0.12002186226465444\n",
      "Iteataion 667: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2021e-04.\n",
      "Iterataion 668: Training Loss: 0.018564591834999197, Validation Loss: 0.11933913358015849\n",
      "Iteataion 668: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1901e-04.\n",
      "Iterataion 669: Training Loss: 0.01160821769108388, Validation Loss: 0.11932394016965679\n",
      "Iteataion 669: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1782e-04.\n",
      "Iterataion 670: Training Loss: 0.015626943366975708, Validation Loss: 0.1206989925746556\n",
      "Iteataion 670: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 1.1664e-04.\n",
      "Iterataion 671: Training Loss: 0.012617957355310962, Validation Loss: 0.12187992516484839\n",
      "Iteataion 671: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1547e-04.\n",
      "Iterataion 672: Training Loss: 0.01186475658062204, Validation Loss: 0.11874712454211875\n",
      "Iteataion 672: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1432e-04.\n",
      "Iterataion 673: Training Loss: 0.016206898924672954, Validation Loss: 0.11647218594429787\n",
      "Iteataion 673: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1318e-04.\n",
      "Iterataion 674: Training Loss: 0.013951575614457593, Validation Loss: 0.13100525232531676\n",
      "Iteataion 674: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1204e-04.\n",
      "Iterataion 675: Training Loss: 0.01394174306274916, Validation Loss: 0.12076739374570912\n",
      "Iteataion 675: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1092e-04.\n",
      "Iterataion 676: Training Loss: 0.01651032471577609, Validation Loss: 0.12216672833537592\n",
      "Iteataion 676: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0982e-04.\n",
      "Iterataion 677: Training Loss: 0.0148934453530976, Validation Loss: 0.12247517096764612\n",
      "Iteataion 677: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0872e-04.\n",
      "Iterataion 678: Training Loss: 0.013311657857660114, Validation Loss: 0.11949012817945559\n",
      "Iteataion 678: Training Accuracy: 0.99609375, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0763e-04.\n",
      "Iterataion 679: Training Loss: 0.015311582601269495, Validation Loss: 0.11859269137778206\n",
      "Iteataion 679: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.0655e-04.\n",
      "Iterataion 680: Training Loss: 0.013702549230973766, Validation Loss: 0.11702999694233124\n",
      "Iteataion 680: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0549e-04.\n",
      "Iterataion 681: Training Loss: 0.016331625648866224, Validation Loss: 0.11806791932492448\n",
      "Iteataion 681: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0443e-04.\n",
      "Iterataion 682: Training Loss: 0.0120506819024261, Validation Loss: 0.1200059704772174\n",
      "Iteataion 682: Training Accuracy: 0.9967447916666666, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0339e-04.\n",
      "Iterataion 683: Training Loss: 0.014411151084650175, Validation Loss: 0.11768038628094761\n",
      "Iteataion 683: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0235e-04.\n",
      "Iterataion 684: Training Loss: 0.012647712712307198, Validation Loss: 0.1176484840646636\n",
      "Iteataion 684: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.0133e-04.\n",
      "Iterataion 685: Training Loss: 0.012270093689676832, Validation Loss: 0.12439451378588451\n",
      "Iteataion 685: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0032e-04.\n",
      "Iterataion 686: Training Loss: 0.012780540267250942, Validation Loss: 0.1165290891232605\n",
      "Iteataion 686: Training Accuracy: 0.99609375, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.9315e-05.\n",
      "Iterataion 687: Training Loss: 0.013441826982986918, Validation Loss: 0.12412987533025444\n",
      "Iteataion 687: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.8322e-05.\n",
      "Iterataion 688: Training Loss: 0.014817342311136903, Validation Loss: 0.12289076421705143\n",
      "Iteataion 688: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.7338e-05.\n",
      "Iterataion 689: Training Loss: 0.014866446793528307, Validation Loss: 0.11900074810368895\n",
      "Iteataion 689: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.6365e-05.\n",
      "Iterataion 690: Training Loss: 0.014061564122832765, Validation Loss: 0.11898111703056025\n",
      "Iteataion 690: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.5401e-05.\n",
      "Iterataion 691: Training Loss: 0.014230787915959787, Validation Loss: 0.11858952342583684\n",
      "Iteataion 691: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 9.4447e-05.\n",
      "Iterataion 692: Training Loss: 0.015184676140814484, Validation Loss: 0.11929673150113625\n",
      "Iteataion 692: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.3503e-05.\n",
      "Iterataion 693: Training Loss: 0.011877514597782754, Validation Loss: 0.12080833257925583\n",
      "Iteataion 693: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.2568e-05.\n",
      "Iterataion 694: Training Loss: 0.014109645117789473, Validation Loss: 0.12079654735081442\n",
      "Iteataion 694: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.1642e-05.\n",
      "Iterataion 695: Training Loss: 0.014532269941173036, Validation Loss: 0.11604203896315927\n",
      "Iteataion 695: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.0726e-05.\n",
      "Iterataion 696: Training Loss: 0.016289118205093985, Validation Loss: 0.12985325151083355\n",
      "Iteataion 696: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 8.9819e-05.\n",
      "Iterataion 697: Training Loss: 0.015864236186039608, Validation Loss: 0.12054767331574112\n",
      "Iteataion 697: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.8920e-05.\n",
      "Iterataion 698: Training Loss: 0.012687180198423709, Validation Loss: 0.12332208768646347\n",
      "Iteataion 698: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.8031e-05.\n",
      "Iterataion 699: Training Loss: 0.014831811979463224, Validation Loss: 0.12279442912279968\n",
      "Iteataion 699: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 8.7151e-05.\n",
      "Iterataion 700: Training Loss: 0.012533565435257412, Validation Loss: 0.1235200163742198\n",
      "Iteataion 700: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 8.6279e-05.\n",
      "Iterataion 701: Training Loss: 0.01259795939643912, Validation Loss: 0.12099052175436532\n",
      "Iteataion 701: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.5417e-05.\n",
      "Iterataion 702: Training Loss: 0.012857803797961385, Validation Loss: 0.1187433687126741\n",
      "Iteataion 702: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 8.4562e-05.\n",
      "Iterataion 703: Training Loss: 0.014532273612089712, Validation Loss: 0.12192712729887628\n",
      "Iteataion 703: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 8.3717e-05.\n",
      "Iterataion 704: Training Loss: 0.016637648917451602, Validation Loss: 0.1297887683471256\n",
      "Iteataion 704: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 8.2880e-05.\n",
      "Iterataion 705: Training Loss: 0.01331916680346204, Validation Loss: 0.12058585531521225\n",
      "Iteataion 705: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.2051e-05.\n",
      "Iterataion 706: Training Loss: 0.014657465044986233, Validation Loss: 0.12771991430355872\n",
      "Iteataion 706: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.1230e-05.\n",
      "Iterataion 707: Training Loss: 0.014527727360941727, Validation Loss: 0.12328237286916502\n",
      "Iteataion 707: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 8.0418e-05.\n",
      "Iterataion 708: Training Loss: 0.012177131565365784, Validation Loss: 0.128055933544912\n",
      "Iteataion 708: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.9614e-05.\n",
      "Iterataion 709: Training Loss: 0.012760191434341856, Validation Loss: 0.12369795814625033\n",
      "Iteataion 709: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.8818e-05.\n",
      "Iterataion 710: Training Loss: 0.014734150731167895, Validation Loss: 0.11956751838868779\n",
      "Iteataion 710: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 7.8029e-05.\n",
      "Iterataion 711: Training Loss: 0.014171825363551696, Validation Loss: 0.12277455808220022\n",
      "Iteataion 711: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.7249e-05.\n",
      "Iterataion 712: Training Loss: 0.01445432620445088, Validation Loss: 0.11921303036193955\n",
      "Iteataion 712: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.6477e-05.\n",
      "Iterataion 713: Training Loss: 0.014085753213315868, Validation Loss: 0.12100542971023881\n",
      "Iteataion 713: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.5712e-05.\n",
      "Iterataion 714: Training Loss: 0.012747269114207555, Validation Loss: 0.12286703372033449\n",
      "Iteataion 714: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.4955e-05.\n",
      "Iterataion 715: Training Loss: 0.012576857777270573, Validation Loss: 0.12131047949887722\n",
      "Iteataion 715: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.4205e-05.\n",
      "Iterataion 716: Training Loss: 0.014202737646082606, Validation Loss: 0.12269027039789163\n",
      "Iteataion 716: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.3463e-05.\n",
      "Iterataion 717: Training Loss: 0.011011303069967844, Validation Loss: 0.12299777914645015\n",
      "Iteataion 717: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.2729e-05.\n",
      "Iterataion 718: Training Loss: 0.013675270364222445, Validation Loss: 0.12087732564555709\n",
      "Iteataion 718: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.2001e-05.\n",
      "Iterataion 719: Training Loss: 0.013774241115842125, Validation Loss: 0.12502145813636073\n",
      "Iteataion 719: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.1281e-05.\n",
      "Iterataion 720: Training Loss: 0.0125702221232709, Validation Loss: 0.11960757934636004\n",
      "Iteataion 720: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.0568e-05.\n",
      "Iterataion 721: Training Loss: 0.0127674552211524, Validation Loss: 0.13018270806841006\n",
      "Iteataion 721: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.9863e-05.\n",
      "Iterataion 722: Training Loss: 0.013374541842930777, Validation Loss: 0.12364307381056544\n",
      "Iteataion 722: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.9164e-05.\n",
      "Iterataion 723: Training Loss: 0.01353621948649828, Validation Loss: 0.12261477781306361\n",
      "Iteataion 723: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.8472e-05.\n",
      "Iterataion 724: Training Loss: 0.013056148126272451, Validation Loss: 0.12187663409944124\n",
      "Iteataion 724: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.7788e-05.\n",
      "Iterataion 725: Training Loss: 0.013602777004303289, Validation Loss: 0.1186582679440063\n",
      "Iteataion 725: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.7110e-05.\n",
      "Iterataion 726: Training Loss: 0.016427624084663292, Validation Loss: 0.1189249425405273\n",
      "Iteataion 726: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.6439e-05.\n",
      "Iterataion 727: Training Loss: 0.014352677150700564, Validation Loss: 0.12592716007237892\n",
      "Iteataion 727: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.5774e-05.\n",
      "Iterataion 728: Training Loss: 0.011662231629970902, Validation Loss: 0.11965506933572725\n",
      "Iteataion 728: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.5117e-05.\n",
      "Iterataion 729: Training Loss: 0.018411056763174647, Validation Loss: 0.12532114023314334\n",
      "Iteataion 729: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.4465e-05.\n",
      "Iterataion 730: Training Loss: 0.010766204434703523, Validation Loss: 0.12716474396136884\n",
      "Iteataion 730: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.3821e-05.\n",
      "Iterataion 731: Training Loss: 0.01367977659708073, Validation Loss: 0.12186619667506708\n",
      "Iteataion 731: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.3183e-05.\n",
      "Iterataion 732: Training Loss: 0.01394495848617879, Validation Loss: 0.12708401873213715\n",
      "Iteataion 732: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.2551e-05.\n",
      "Iterataion 733: Training Loss: 0.013563968929598765, Validation Loss: 0.11769789552157063\n",
      "Iteataion 733: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.1925e-05.\n",
      "Iterataion 734: Training Loss: 0.012106748669537922, Validation Loss: 0.12338593837850523\n",
      "Iteataion 734: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.1306e-05.\n",
      "Iterataion 735: Training Loss: 0.013961590532336138, Validation Loss: 0.12072527688138596\n",
      "Iteataion 735: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.0693e-05.\n",
      "Iterataion 736: Training Loss: 0.015360613914365563, Validation Loss: 0.12781353820280014\n",
      "Iteataion 736: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.0086e-05.\n",
      "Iterataion 737: Training Loss: 0.012172056678515262, Validation Loss: 0.11640130250257576\n",
      "Iteataion 737: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.9485e-05.\n",
      "Iterataion 738: Training Loss: 0.014033963798697268, Validation Loss: 0.11690362106736113\n",
      "Iteataion 738: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 5.8890e-05.\n",
      "Iterataion 739: Training Loss: 0.017307177254327847, Validation Loss: 0.12012558739501755\n",
      "Iteataion 739: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.8301e-05.\n",
      "Iterataion 740: Training Loss: 0.014237853685884686, Validation Loss: 0.11985897745585024\n",
      "Iteataion 740: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.7718e-05.\n",
      "Iterataion 741: Training Loss: 0.01608066043668722, Validation Loss: 0.12124968498445503\n",
      "Iteataion 741: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.7141e-05.\n",
      "Iterataion 742: Training Loss: 0.014943328152081655, Validation Loss: 0.11521227965940631\n",
      "Iteataion 742: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.6570e-05.\n",
      "Iterataion 743: Training Loss: 0.015564966093592657, Validation Loss: 0.12189585002985351\n",
      "Iteataion 743: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 5.6004e-05.\n",
      "Iterataion 744: Training Loss: 0.013450186922003008, Validation Loss: 0.12028081471770548\n",
      "Iteataion 744: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.5444e-05.\n",
      "Iterataion 745: Training Loss: 0.011707583573036185, Validation Loss: 0.12078729492226024\n",
      "Iteataion 745: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.4890e-05.\n",
      "Iterataion 746: Training Loss: 0.01611367754814561, Validation Loss: 0.11969650180431128\n",
      "Iteataion 746: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.4341e-05.\n",
      "Iterataion 747: Training Loss: 0.013947002589354057, Validation Loss: 0.12262228543148944\n",
      "Iteataion 747: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.3797e-05.\n",
      "Iterataion 748: Training Loss: 0.013589652991312706, Validation Loss: 0.11999205511387029\n",
      "Iteataion 748: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.3259e-05.\n",
      "Iterataion 749: Training Loss: 0.016849880215842945, Validation Loss: 0.12124778859873825\n",
      "Iteataion 749: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.2727e-05.\n",
      "Iterataion 750: Training Loss: 0.011840759030638073, Validation Loss: 0.12684038919453486\n",
      "Iteataion 750: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.2199e-05.\n",
      "Iterataion 751: Training Loss: 0.014288824486259014, Validation Loss: 0.12160073057322468\n",
      "Iteataion 751: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.1678e-05.\n",
      "Iterataion 752: Training Loss: 0.012282102427676788, Validation Loss: 0.11911440677884058\n",
      "Iteataion 752: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.1161e-05.\n",
      "Iterataion 753: Training Loss: 0.014687203791363354, Validation Loss: 0.11911522364385835\n",
      "Iteataion 753: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.0649e-05.\n",
      "Iterataion 754: Training Loss: 0.013219599218545538, Validation Loss: 0.11769750372722472\n",
      "Iteataion 754: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.0143e-05.\n",
      "Iterataion 755: Training Loss: 0.014020404706271309, Validation Loss: 0.12028405366312121\n",
      "Iteataion 755: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.9641e-05.\n",
      "Iterataion 756: Training Loss: 0.017996150850036745, Validation Loss: 0.11544046043020832\n",
      "Iteataion 756: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.9145e-05.\n",
      "Iterataion 757: Training Loss: 0.015059381903603695, Validation Loss: 0.11621967771533513\n",
      "Iteataion 757: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 4.8653e-05.\n",
      "Iterataion 758: Training Loss: 0.013304798069833862, Validation Loss: 0.11653644495456275\n",
      "Iteataion 758: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.8167e-05.\n",
      "Iterataion 759: Training Loss: 0.01439650267122793, Validation Loss: 0.12024810757749237\n",
      "Iteataion 759: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.7685e-05.\n",
      "Iterataion 760: Training Loss: 0.0143583177128447, Validation Loss: 0.11782612363103687\n",
      "Iteataion 760: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.7208e-05.\n",
      "Iterataion 761: Training Loss: 0.012517894170850705, Validation Loss: 0.11743013811490793\n",
      "Iteataion 761: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.6736e-05.\n",
      "Iterataion 762: Training Loss: 0.015474003925954388, Validation Loss: 0.12009059504191277\n",
      "Iteataion 762: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.6269e-05.\n",
      "Iterataion 763: Training Loss: 0.013758358872888754, Validation Loss: 0.12111851645395069\n",
      "Iteataion 763: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.5806e-05.\n",
      "Iterataion 764: Training Loss: 0.01709789276774136, Validation Loss: 0.12636679262717868\n",
      "Iteataion 764: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.5348e-05.\n",
      "Iterataion 765: Training Loss: 0.010548233886390177, Validation Loss: 0.1170747660756361\n",
      "Iteataion 765: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.4895e-05.\n",
      "Iterataion 766: Training Loss: 0.013389615366245135, Validation Loss: 0.11894070129932427\n",
      "Iteataion 766: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.4446e-05.\n",
      "Iterataion 767: Training Loss: 0.013395597090112314, Validation Loss: 0.11643922732995324\n",
      "Iteataion 767: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.4001e-05.\n",
      "Iterataion 768: Training Loss: 0.017955859940398684, Validation Loss: 0.11787187580087381\n",
      "Iteataion 768: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 4.3561e-05.\n",
      "Iterataion 769: Training Loss: 0.014915558266415802, Validation Loss: 0.11962199641644342\n",
      "Iteataion 769: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.3126e-05.\n",
      "Iterataion 770: Training Loss: 0.012694473519348288, Validation Loss: 0.1204498457103377\n",
      "Iteataion 770: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.2694e-05.\n",
      "Iterataion 771: Training Loss: 0.01426287659779916, Validation Loss: 0.12384318343999727\n",
      "Iteataion 771: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.2267e-05.\n",
      "Iterataion 772: Training Loss: 0.013494886339936283, Validation Loss: 0.12118718679852375\n",
      "Iteataion 772: Training Accuracy: 0.99609375, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 4.1845e-05.\n",
      "Iterataion 773: Training Loss: 0.015163393940743126, Validation Loss: 0.11852498190256017\n",
      "Iteataion 773: Training Accuracy: 0.99609375, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.1426e-05.\n",
      "Iterataion 774: Training Loss: 0.012318316028693212, Validation Loss: 0.12026176211798972\n",
      "Iteataion 774: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.1012e-05.\n",
      "Iterataion 775: Training Loss: 0.012228180102594086, Validation Loss: 0.11951459679758267\n",
      "Iteataion 775: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 4.0602e-05.\n",
      "Iterataion 776: Training Loss: 0.014201677002815787, Validation Loss: 0.1211386713427889\n",
      "Iteataion 776: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.0196e-05.\n",
      "Iterataion 777: Training Loss: 0.01298719751934415, Validation Loss: 0.11778998647095272\n",
      "Iteataion 777: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.9794e-05.\n",
      "Iterataion 778: Training Loss: 0.01557711091639842, Validation Loss: 0.11998578279120166\n",
      "Iteataion 778: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.9396e-05.\n",
      "Iterataion 779: Training Loss: 0.0127769336949624, Validation Loss: 0.1262999766033495\n",
      "Iteataion 779: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 3.9002e-05.\n",
      "Iterataion 780: Training Loss: 0.014902915240580517, Validation Loss: 0.12134226571865062\n",
      "Iteataion 780: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.8612e-05.\n",
      "Iterataion 781: Training Loss: 0.015429321594235159, Validation Loss: 0.12389883921175014\n",
      "Iteataion 781: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.8226e-05.\n",
      "Iterataion 782: Training Loss: 0.016283846613295756, Validation Loss: 0.12605561036048685\n",
      "Iteataion 782: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.7844e-05.\n",
      "Iterataion 783: Training Loss: 0.013385832318088074, Validation Loss: 0.12358376161598532\n",
      "Iteataion 783: Training Accuracy: 0.99609375, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 3.7465e-05.\n",
      "Iterataion 784: Training Loss: 0.015733320383120798, Validation Loss: 0.1195457301318373\n",
      "Iteataion 784: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 3.7091e-05.\n",
      "Iterataion 785: Training Loss: 0.012657948959065312, Validation Loss: 0.12222278940920127\n",
      "Iteataion 785: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.6720e-05.\n",
      "Iterataion 786: Training Loss: 0.013760654315523925, Validation Loss: 0.12002186250884267\n",
      "Iteataion 786: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.6352e-05.\n",
      "Iterataion 787: Training Loss: 0.012592096375594261, Validation Loss: 0.12059034319685363\n",
      "Iteataion 787: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.5989e-05.\n",
      "Iterataion 788: Training Loss: 0.010717773446666835, Validation Loss: 0.11909226082526601\n",
      "Iteataion 788: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.5629e-05.\n",
      "Iterataion 789: Training Loss: 0.013212274439865723, Validation Loss: 0.1237994094106664\n",
      "Iteataion 789: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.5273e-05.\n",
      "Iterataion 790: Training Loss: 0.014355164115187505, Validation Loss: 0.11878902708441473\n",
      "Iteataion 790: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.4920e-05.\n",
      "Iterataion 791: Training Loss: 0.014436219896790767, Validation Loss: 0.12173606121696805\n",
      "Iteataion 791: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.4571e-05.\n",
      "Iterataion 792: Training Loss: 0.011931829233960566, Validation Loss: 0.11944215667644152\n",
      "Iteataion 792: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.4225e-05.\n",
      "Iterataion 793: Training Loss: 0.01642854040918013, Validation Loss: 0.11902704606366503\n",
      "Iteataion 793: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.3883e-05.\n",
      "Iterataion 794: Training Loss: 0.013785728489566025, Validation Loss: 0.12273555102107887\n",
      "Iteataion 794: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 3.3544e-05.\n",
      "Iterataion 795: Training Loss: 0.011897683044976393, Validation Loss: 0.12062148379712798\n",
      "Iteataion 795: Training Accuracy: 0.99609375, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 3.3209e-05.\n",
      "Iterataion 796: Training Loss: 0.013144603433557313, Validation Loss: 0.11722612472126125\n",
      "Iteataion 796: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.2876e-05.\n",
      "Iterataion 797: Training Loss: 0.018632660249058536, Validation Loss: 0.12306675428834107\n",
      "Iteataion 797: Training Accuracy: 0.994140625, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.2548e-05.\n",
      "Iterataion 798: Training Loss: 0.014435725047498451, Validation Loss: 0.12050526181630586\n",
      "Iteataion 798: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.2222e-05.\n",
      "Iterataion 799: Training Loss: 0.010913273444731057, Validation Loss: 0.12238532941782757\n",
      "Iteataion 799: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.1900e-05.\n",
      "Iterataion 800: Training Loss: 0.014933846004218041, Validation Loss: 0.11917931400239468\n",
      "Iteataion 800: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.1581e-05.\n",
      "Iterataion 801: Training Loss: 0.011873854596089728, Validation Loss: 0.12044058688178022\n",
      "Iteataion 801: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.1265e-05.\n",
      "Iterataion 802: Training Loss: 0.016289315642342865, Validation Loss: 0.12022860531933696\n",
      "Iteataion 802: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.0953e-05.\n",
      "Iterataion 803: Training Loss: 0.015069038542698579, Validation Loss: 0.11935187212941123\n",
      "Iteataion 803: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.0643e-05.\n",
      "Iterataion 804: Training Loss: 0.011628621147351597, Validation Loss: 0.12419827109083488\n",
      "Iteataion 804: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.0337e-05.\n",
      "Iterataion 805: Training Loss: 0.014698650608115277, Validation Loss: 0.11932523078114794\n",
      "Iteataion 805: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.0033e-05.\n",
      "Iterataion 806: Training Loss: 0.015837570789171116, Validation Loss: 0.11789342199122851\n",
      "Iteataion 806: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.9733e-05.\n",
      "Iterataion 807: Training Loss: 0.010984691563111167, Validation Loss: 0.11687898369528717\n",
      "Iteataion 807: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.9436e-05.\n",
      "Iterataion 808: Training Loss: 0.014161372328285841, Validation Loss: 0.11797819137090544\n",
      "Iteataion 808: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.9141e-05.\n",
      "Iterataion 809: Training Loss: 0.012866808983537753, Validation Loss: 0.11776744603341241\n",
      "Iteataion 809: Training Accuracy: 0.9967447916666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.8850e-05.\n",
      "Iterataion 810: Training Loss: 0.018347602872621313, Validation Loss: 0.12121623134163845\n",
      "Iteataion 810: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.8561e-05.\n",
      "Iterataion 811: Training Loss: 0.012345665007966296, Validation Loss: 0.11708786674184589\n",
      "Iteataion 811: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.8276e-05.\n",
      "Iterataion 812: Training Loss: 0.015987104363844054, Validation Loss: 0.11864569269847579\n",
      "Iteataion 812: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 2.7993e-05.\n",
      "Iterataion 813: Training Loss: 0.008504642862728992, Validation Loss: 0.11761507005345576\n",
      "Iteataion 813: Training Accuracy: 0.9978608630952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.7713e-05.\n",
      "Iterataion 814: Training Loss: 0.015643029134758207, Validation Loss: 0.12238144456897294\n",
      "Iteataion 814: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.7436e-05.\n",
      "Iterataion 815: Training Loss: 0.012563691270073408, Validation Loss: 0.1205442683067082\n",
      "Iteataion 815: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.7162e-05.\n",
      "Iterataion 816: Training Loss: 0.013178513919680886, Validation Loss: 0.12164524703559171\n",
      "Iteataion 816: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.6890e-05.\n",
      "Iterataion 817: Training Loss: 0.013175283255080642, Validation Loss: 0.12316950239530741\n",
      "Iteataion 817: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.6621e-05.\n",
      "Iterataion 818: Training Loss: 0.014609247389420989, Validation Loss: 0.12155651972095323\n",
      "Iteataion 818: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.6355e-05.\n",
      "Iterataion 819: Training Loss: 0.013598480458792389, Validation Loss: 0.12135368409969775\n",
      "Iteataion 819: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.6091e-05.\n",
      "Iterataion 820: Training Loss: 0.013989526237163158, Validation Loss: 0.11526568015901054\n",
      "Iteataion 820: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.5830e-05.\n",
      "Iterataion 821: Training Loss: 0.012110576299360735, Validation Loss: 0.11878854871682096\n",
      "Iteataion 821: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.5572e-05.\n",
      "Iterataion 822: Training Loss: 0.014736137232634457, Validation Loss: 0.1226407902956963\n",
      "Iteataion 822: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.5316e-05.\n",
      "Iterataion 823: Training Loss: 0.01653644818171976, Validation Loss: 0.11869596109708498\n",
      "Iteataion 823: Training Accuracy: 0.9940476190476191, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.5063e-05.\n",
      "Iterataion 824: Training Loss: 0.013481130355566149, Validation Loss: 0.11721228866656197\n",
      "Iteataion 824: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.4813e-05.\n",
      "Iterataion 825: Training Loss: 0.012232621201602631, Validation Loss: 0.11713799857534468\n",
      "Iteataion 825: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.4564e-05.\n",
      "Iterataion 826: Training Loss: 0.01531021454243246, Validation Loss: 0.11992314596172059\n",
      "Iteataion 826: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.4319e-05.\n",
      "Iterataion 827: Training Loss: 0.013131848147276979, Validation Loss: 0.11953136527615531\n",
      "Iteataion 827: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.4076e-05.\n",
      "Iterataion 828: Training Loss: 0.014232467760298469, Validation Loss: 0.11820897217215288\n",
      "Iteataion 828: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.3835e-05.\n",
      "Iterataion 829: Training Loss: 0.012431861868638455, Validation Loss: 0.11826250327342167\n",
      "Iteataion 829: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.3596e-05.\n",
      "Iterataion 830: Training Loss: 0.010537417580772325, Validation Loss: 0.11936332820346807\n",
      "Iteataion 830: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.3360e-05.\n",
      "Iterataion 831: Training Loss: 0.011792288014378042, Validation Loss: 0.11642117623847387\n",
      "Iteataion 831: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.3127e-05.\n",
      "Iterataion 832: Training Loss: 0.01444172296320328, Validation Loss: 0.1185373869077189\n",
      "Iteataion 832: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.2896e-05.\n",
      "Iterataion 833: Training Loss: 0.017237386531698446, Validation Loss: 0.12033521377754103\n",
      "Iteataion 833: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.2667e-05.\n",
      "Iterataion 834: Training Loss: 0.015630916998342438, Validation Loss: 0.11763242728974126\n",
      "Iteataion 834: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.2440e-05.\n",
      "Iterataion 835: Training Loss: 0.01257565613971287, Validation Loss: 0.12697115762971295\n",
      "Iteataion 835: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.2216e-05.\n",
      "Iterataion 836: Training Loss: 0.011245357851925847, Validation Loss: 0.12151688141123641\n",
      "Iteataion 836: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.1993e-05.\n",
      "Iterataion 837: Training Loss: 0.01176498672356104, Validation Loss: 0.11948400938730096\n",
      "Iteataion 837: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.1774e-05.\n",
      "Iterataion 838: Training Loss: 0.016920896661628184, Validation Loss: 0.11829595164134644\n",
      "Iteataion 838: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.1556e-05.\n",
      "Iterataion 839: Training Loss: 0.01177153436792596, Validation Loss: 0.11938175231377345\n",
      "Iteataion 839: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.1340e-05.\n",
      "Iterataion 840: Training Loss: 0.011820873877864532, Validation Loss: 0.1182621523664083\n",
      "Iteataion 840: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.1127e-05.\n",
      "Iterataion 841: Training Loss: 0.013234814231264444, Validation Loss: 0.11856149947526297\n",
      "Iteataion 841: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.0916e-05.\n",
      "Iterataion 842: Training Loss: 0.012684955120136862, Validation Loss: 0.1212472534488614\n",
      "Iteataion 842: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.0706e-05.\n",
      "Iterataion 843: Training Loss: 0.014880798765267161, Validation Loss: 0.11794661776242187\n",
      "Iteataion 843: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.0499e-05.\n",
      "Iterataion 844: Training Loss: 0.013978695961880961, Validation Loss: 0.12094977559527473\n",
      "Iteataion 844: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.0294e-05.\n",
      "Iterataion 845: Training Loss: 0.015388796561534242, Validation Loss: 0.11867290918101989\n",
      "Iteataion 845: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.0091e-05.\n",
      "Iterataion 846: Training Loss: 0.015552650108371587, Validation Loss: 0.12109016952184369\n",
      "Iteataion 846: Training Accuracy: 0.9940476190476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.9890e-05.\n",
      "Iterataion 847: Training Loss: 0.015119426493730931, Validation Loss: 0.12376872483192285\n",
      "Iteataion 847: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.9692e-05.\n",
      "Iterataion 848: Training Loss: 0.013261023575815089, Validation Loss: 0.12470914000750338\n",
      "Iteataion 848: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.9495e-05.\n",
      "Iterataion 849: Training Loss: 0.014171903628980027, Validation Loss: 0.12354936190347028\n",
      "Iteataion 849: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.9300e-05.\n",
      "Iterataion 850: Training Loss: 0.020689324535426688, Validation Loss: 0.12313980939897436\n",
      "Iteataion 850: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.9107e-05.\n",
      "Iterataion 851: Training Loss: 0.01188486524018275, Validation Loss: 0.12011833356909181\n",
      "Iteataion 851: Training Accuracy: 0.9969308035714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.8916e-05.\n",
      "Iterataion 852: Training Loss: 0.01460561121749123, Validation Loss: 0.1271333991714594\n",
      "Iteataion 852: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.8726e-05.\n",
      "Iterataion 853: Training Loss: 0.012165466539246661, Validation Loss: 0.12092598763694873\n",
      "Iteataion 853: Training Accuracy: 0.9967447916666666, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.8539e-05.\n",
      "Iterataion 854: Training Loss: 0.012847775987608771, Validation Loss: 0.12165631688336229\n",
      "Iteataion 854: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.8354e-05.\n",
      "Iterataion 855: Training Loss: 0.016091475000432107, Validation Loss: 0.12331975036635767\n",
      "Iteataion 855: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.8170e-05.\n",
      "Iterataion 856: Training Loss: 0.016484020706921437, Validation Loss: 0.11731271381864733\n",
      "Iteataion 856: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.7989e-05.\n",
      "Iterataion 857: Training Loss: 0.012658143594852666, Validation Loss: 0.11930563963350567\n",
      "Iteataion 857: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.7809e-05.\n",
      "Iterataion 858: Training Loss: 0.014958888632670591, Validation Loss: 0.12057197600512243\n",
      "Iteataion 858: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.7631e-05.\n",
      "Iterataion 859: Training Loss: 0.012652354406068815, Validation Loss: 0.12126232470277833\n",
      "Iteataion 859: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.7454e-05.\n",
      "Iterataion 860: Training Loss: 0.016730808486679603, Validation Loss: 0.11980242406091902\n",
      "Iteataion 860: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.7280e-05.\n",
      "Iterataion 861: Training Loss: 0.010874346835701865, Validation Loss: 0.12335317027925445\n",
      "Iteataion 861: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.7107e-05.\n",
      "Iterataion 862: Training Loss: 0.012621285897138679, Validation Loss: 0.12135697564780258\n",
      "Iteataion 862: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.6936e-05.\n",
      "Iterataion 863: Training Loss: 0.014081261021574447, Validation Loss: 0.11860592334769757\n",
      "Iteataion 863: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6767e-05.\n",
      "Iterataion 864: Training Loss: 0.013518642694626595, Validation Loss: 0.12410328170801399\n",
      "Iteataion 864: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.6599e-05.\n",
      "Iterataion 865: Training Loss: 0.01426463938003802, Validation Loss: 0.12830031608662953\n",
      "Iteataion 865: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6433e-05.\n",
      "Iterataion 866: Training Loss: 0.01652709701085257, Validation Loss: 0.12023525758754326\n",
      "Iteataion 866: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.6269e-05.\n",
      "Iterataion 867: Training Loss: 0.012341011740465252, Validation Loss: 0.12888465394981477\n",
      "Iteataion 867: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.6106e-05.\n",
      "Iterataion 868: Training Loss: 0.014354030170699604, Validation Loss: 0.12570090501188733\n",
      "Iteataion 868: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.5945e-05.\n",
      "Iterataion 869: Training Loss: 0.011796753928846049, Validation Loss: 0.11946941193806507\n",
      "Iteataion 869: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.5785e-05.\n",
      "Iterataion 870: Training Loss: 0.01628536075715416, Validation Loss: 0.12109166093556802\n",
      "Iteataion 870: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.5628e-05.\n",
      "Iterataion 871: Training Loss: 0.015594295239979458, Validation Loss: 0.11806212392601571\n",
      "Iteataion 871: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.5471e-05.\n",
      "Iterataion 872: Training Loss: 0.016062014648400826, Validation Loss: 0.11852383433142677\n",
      "Iteataion 872: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.5317e-05.\n",
      "Iterataion 873: Training Loss: 0.0134696671927437, Validation Loss: 0.1182245359267676\n",
      "Iteataion 873: Training Accuracy: 0.99609375, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.5163e-05.\n",
      "Iterataion 874: Training Loss: 0.016684937791363475, Validation Loss: 0.11951715231975313\n",
      "Iteataion 874: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.5012e-05.\n",
      "Iterataion 875: Training Loss: 0.015327443061487101, Validation Loss: 0.123364467285971\n",
      "Iteataion 875: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4862e-05.\n",
      "Iterataion 876: Training Loss: 0.014088323120059847, Validation Loss: 0.12320754272159098\n",
      "Iteataion 876: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 1.4713e-05.\n",
      "Iterataion 877: Training Loss: 0.013084931080898794, Validation Loss: 0.12204355622709888\n",
      "Iteataion 877: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4566e-05.\n",
      "Iterataion 878: Training Loss: 0.011271222613572038, Validation Loss: 0.11931667031248941\n",
      "Iteataion 878: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4420e-05.\n",
      "Iterataion 879: Training Loss: 0.01981563993010246, Validation Loss: 0.12132003197656581\n",
      "Iteataion 879: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.4276e-05.\n",
      "Iterataion 880: Training Loss: 0.016679662592433014, Validation Loss: 0.12362444646963168\n",
      "Iteataion 880: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4133e-05.\n",
      "Iterataion 881: Training Loss: 0.01332744777664085, Validation Loss: 0.12006118740153886\n",
      "Iteataion 881: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.3992e-05.\n",
      "Iterataion 882: Training Loss: 0.01373442658310349, Validation Loss: 0.12075424610094804\n",
      "Iteataion 882: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.3852e-05.\n",
      "Iterataion 883: Training Loss: 0.012107981143562502, Validation Loss: 0.1220040778095675\n",
      "Iteataion 883: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.3713e-05.\n",
      "Iterataion 884: Training Loss: 0.010985212544157744, Validation Loss: 0.12332425214685272\n",
      "Iteataion 884: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.3576e-05.\n",
      "Iterataion 885: Training Loss: 0.013099261034979949, Validation Loss: 0.11803196743982504\n",
      "Iteataion 885: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.3441e-05.\n",
      "Iterataion 886: Training Loss: 0.013081492091951512, Validation Loss: 0.12045462554456984\n",
      "Iteataion 886: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.3306e-05.\n",
      "Iterataion 887: Training Loss: 0.012329521104149676, Validation Loss: 0.12288064147464976\n",
      "Iteataion 887: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.3173e-05.\n",
      "Iterataion 888: Training Loss: 0.014885088097733519, Validation Loss: 0.12209634083215283\n",
      "Iteataion 888: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.3041e-05.\n",
      "Iterataion 889: Training Loss: 0.014135998867355944, Validation Loss: 0.1229767284736537\n",
      "Iteataion 889: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2911e-05.\n",
      "Iterataion 890: Training Loss: 0.012432713848245916, Validation Loss: 0.12022796762175858\n",
      "Iteataion 890: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2782e-05.\n",
      "Iterataion 891: Training Loss: 0.01401951235389995, Validation Loss: 0.11912306349883538\n",
      "Iteataion 891: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.2654e-05.\n",
      "Iterataion 892: Training Loss: 0.013604166599974862, Validation Loss: 0.12170861792472396\n",
      "Iteataion 892: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.2527e-05.\n",
      "Iterataion 893: Training Loss: 0.01366187726505781, Validation Loss: 0.11896258035515685\n",
      "Iteataion 893: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.2402e-05.\n",
      "Iterataion 894: Training Loss: 0.012188142882855219, Validation Loss: 0.11849010814117586\n",
      "Iteataion 894: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.2278e-05.\n",
      "Iterataion 895: Training Loss: 0.01311567610807293, Validation Loss: 0.11890849153079637\n",
      "Iteataion 895: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2155e-05.\n",
      "Iterataion 896: Training Loss: 0.014923586143971237, Validation Loss: 0.11665774370464156\n",
      "Iteataion 896: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2034e-05.\n",
      "Iterataion 897: Training Loss: 0.012004521422709958, Validation Loss: 0.12359342351555824\n",
      "Iteataion 897: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1914e-05.\n",
      "Iterataion 898: Training Loss: 0.012116566612343388, Validation Loss: 0.11966491492022192\n",
      "Iteataion 898: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1794e-05.\n",
      "Iterataion 899: Training Loss: 0.012962896479670137, Validation Loss: 0.12175374622627093\n",
      "Iteataion 899: Training Accuracy: 0.99609375, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1676e-05.\n",
      "Iterataion 900: Training Loss: 0.011346489321761122, Validation Loss: 0.12059778802837927\n",
      "Iteataion 900: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1560e-05.\n",
      "Iterataion 901: Training Loss: 0.01232462624697193, Validation Loss: 0.12005942885582221\n",
      "Iteataion 901: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.1444e-05.\n",
      "Iterataion 902: Training Loss: 0.019157397382143986, Validation Loss: 0.12813344426600762\n",
      "Iteataion 902: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1330e-05.\n",
      "Iterataion 903: Training Loss: 0.013951734979539374, Validation Loss: 0.12043644894459625\n",
      "Iteataion 903: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1216e-05.\n",
      "Iterataion 904: Training Loss: 0.009940972023303369, Validation Loss: 0.12190984892119404\n",
      "Iteataion 904: Training Accuracy: 0.9973958333333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1104e-05.\n",
      "Iterataion 905: Training Loss: 0.016440956298788886, Validation Loss: 0.12397673209027456\n",
      "Iteataion 905: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0993e-05.\n",
      "Iterataion 906: Training Loss: 0.013943502822895061, Validation Loss: 0.11622886683170047\n",
      "Iteataion 906: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0883e-05.\n",
      "Iterataion 907: Training Loss: 0.0110797265211321, Validation Loss: 0.12042348183799399\n",
      "Iteataion 907: Training Accuracy: 0.99609375, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 1.0774e-05.\n",
      "Iterataion 908: Training Loss: 0.013678986030563845, Validation Loss: 0.1269190159829322\n",
      "Iteataion 908: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.0667e-05.\n",
      "Iterataion 909: Training Loss: 0.013257935129783623, Validation Loss: 0.11920728064255744\n",
      "Iteataion 909: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0560e-05.\n",
      "Iterataion 910: Training Loss: 0.013637348359121667, Validation Loss: 0.12187753142874189\n",
      "Iteataion 910: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0454e-05.\n",
      "Iterataion 911: Training Loss: 0.015824705327116512, Validation Loss: 0.12284149565143375\n",
      "Iteataion 911: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.0350e-05.\n",
      "Iterataion 912: Training Loss: 0.012460450770425426, Validation Loss: 0.12278057996569793\n",
      "Iteataion 912: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.0246e-05.\n",
      "Iterataion 913: Training Loss: 0.012178313165720453, Validation Loss: 0.11911842963380012\n",
      "Iteataion 913: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.0144e-05.\n",
      "Iterataion 914: Training Loss: 0.01621014637503812, Validation Loss: 0.11813596786970909\n",
      "Iteataion 914: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0042e-05.\n",
      "Iterataion 915: Training Loss: 0.013414053177017674, Validation Loss: 0.11703662676935471\n",
      "Iteataion 915: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.9420e-06.\n",
      "Iterataion 916: Training Loss: 0.015378889106848405, Validation Loss: 0.12264005408804046\n",
      "Iteataion 916: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.8426e-06.\n",
      "Iterataion 917: Training Loss: 0.011961232067063496, Validation Loss: 0.12081939860803598\n",
      "Iteataion 917: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.7441e-06.\n",
      "Iterataion 918: Training Loss: 0.013176653217865868, Validation Loss: 0.122446767192209\n",
      "Iteataion 918: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.6467e-06.\n",
      "Iterataion 919: Training Loss: 0.014212937236479121, Validation Loss: 0.12011658329028273\n",
      "Iteataion 919: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.5502e-06.\n",
      "Iterataion 920: Training Loss: 0.013124795844234682, Validation Loss: 0.1212263134998133\n",
      "Iteataion 920: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.4547e-06.\n",
      "Iterataion 921: Training Loss: 0.014061046840412497, Validation Loss: 0.1223421827662827\n",
      "Iteataion 921: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 9.3602e-06.\n",
      "Iterataion 922: Training Loss: 0.01335238369180358, Validation Loss: 0.1226721622302515\n",
      "Iteataion 922: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.2666e-06.\n",
      "Iterataion 923: Training Loss: 0.012492569397317948, Validation Loss: 0.12455360483940373\n",
      "Iteataion 923: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.1739e-06.\n",
      "Iterataion 924: Training Loss: 0.010586985937615265, Validation Loss: 0.12294664771704958\n",
      "Iteataion 924: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.0822e-06.\n",
      "Iterataion 925: Training Loss: 0.01520818725930984, Validation Loss: 0.12435942389235673\n",
      "Iteataion 925: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 8.9914e-06.\n",
      "Iterataion 926: Training Loss: 0.014062322287201256, Validation Loss: 0.11810944753091374\n",
      "Iteataion 926: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.9014e-06.\n",
      "Iterataion 927: Training Loss: 0.012347245430308924, Validation Loss: 0.1209395156602557\n",
      "Iteataion 927: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 8.8124e-06.\n",
      "Iterataion 928: Training Loss: 0.011477162646552169, Validation Loss: 0.1235807400634058\n",
      "Iteataion 928: Training Accuracy: 0.9967447916666666, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 8.7243e-06.\n",
      "Iterataion 929: Training Loss: 0.01672360963103763, Validation Loss: 0.1248929783611036\n",
      "Iteataion 929: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.6371e-06.\n",
      "Iterataion 930: Training Loss: 0.013191987115549603, Validation Loss: 0.12386113766966979\n",
      "Iteataion 930: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.5507e-06.\n",
      "Iterataion 931: Training Loss: 0.015074178651930252, Validation Loss: 0.12452439606195406\n",
      "Iteataion 931: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.4652e-06.\n",
      "Iterataion 932: Training Loss: 0.014983960040977426, Validation Loss: 0.11684041276500311\n",
      "Iteataion 932: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.3805e-06.\n",
      "Iterataion 933: Training Loss: 0.012589281296962592, Validation Loss: 0.11793538561465627\n",
      "Iteataion 933: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.2967e-06.\n",
      "Iterataion 934: Training Loss: 0.015202808330145045, Validation Loss: 0.12023797451813774\n",
      "Iteataion 934: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 8.2138e-06.\n",
      "Iterataion 935: Training Loss: 0.014655965870256051, Validation Loss: 0.12142713623768764\n",
      "Iteataion 935: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.1316e-06.\n",
      "Iterataion 936: Training Loss: 0.013792403744293856, Validation Loss: 0.12077754561181703\n",
      "Iteataion 936: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.0503e-06.\n",
      "Iterataion 937: Training Loss: 0.014930315917318766, Validation Loss: 0.12305743578983266\n",
      "Iteataion 937: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.9698e-06.\n",
      "Iterataion 938: Training Loss: 0.011672535122959167, Validation Loss: 0.11830420888642348\n",
      "Iteataion 938: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.8901e-06.\n",
      "Iterataion 939: Training Loss: 0.014610597223509103, Validation Loss: 0.12081004963000873\n",
      "Iteataion 939: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.8112e-06.\n",
      "Iterataion 940: Training Loss: 0.016839572120441158, Validation Loss: 0.12117659378933107\n",
      "Iteataion 940: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.7331e-06.\n",
      "Iterataion 941: Training Loss: 0.012267076640743986, Validation Loss: 0.12219578908506508\n",
      "Iteataion 941: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.6558e-06.\n",
      "Iterataion 942: Training Loss: 0.010706363126989677, Validation Loss: 0.12121611375861414\n",
      "Iteataion 942: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.5792e-06.\n",
      "Iterataion 943: Training Loss: 0.017964790461753623, Validation Loss: 0.1267370674077694\n",
      "Iteataion 943: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.5034e-06.\n",
      "Iterataion 944: Training Loss: 0.012387691305122132, Validation Loss: 0.1243480805466633\n",
      "Iteataion 944: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.4284e-06.\n",
      "Iterataion 945: Training Loss: 0.01477545396439469, Validation Loss: 0.12000830250042605\n",
      "Iteataion 945: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.3541e-06.\n",
      "Iterataion 946: Training Loss: 0.015572300879981836, Validation Loss: 0.11743258185707396\n",
      "Iteataion 946: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.2806e-06.\n",
      "Iterataion 947: Training Loss: 0.013115063529778105, Validation Loss: 0.12174641259480268\n",
      "Iteataion 947: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.2077e-06.\n",
      "Iterataion 948: Training Loss: 0.011642221789068158, Validation Loss: 0.12138722985187864\n",
      "Iteataion 948: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.1357e-06.\n",
      "Iterataion 949: Training Loss: 0.013388448875135335, Validation Loss: 0.12038313117724411\n",
      "Iteataion 949: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.0643e-06.\n",
      "Iterataion 950: Training Loss: 0.014341129739259922, Validation Loss: 0.12255237878601226\n",
      "Iteataion 950: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.9937e-06.\n",
      "Iterataion 951: Training Loss: 0.012024822371975592, Validation Loss: 0.12013820419797855\n",
      "Iteataion 951: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 6.9237e-06.\n",
      "Iterataion 952: Training Loss: 0.013723187138114549, Validation Loss: 0.12234122754449434\n",
      "Iteataion 952: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.8545e-06.\n",
      "Iterataion 953: Training Loss: 0.01478260390608276, Validation Loss: 0.11706996009338692\n",
      "Iteataion 953: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.7860e-06.\n",
      "Iterataion 954: Training Loss: 0.015128579663397175, Validation Loss: 0.11680913367876555\n",
      "Iteataion 954: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.7181e-06.\n",
      "Iterataion 955: Training Loss: 0.012651828998800166, Validation Loss: 0.12120943795321737\n",
      "Iteataion 955: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.6509e-06.\n",
      "Iterataion 956: Training Loss: 0.01086653418027556, Validation Loss: 0.12063038000757466\n",
      "Iteataion 956: Training Accuracy: 0.9967447916666666, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 6.5844e-06.\n",
      "Iterataion 957: Training Loss: 0.015655074750274018, Validation Loss: 0.1209503521137621\n",
      "Iteataion 957: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.5186e-06.\n",
      "Iterataion 958: Training Loss: 0.01365996794851809, Validation Loss: 0.12142967172932424\n",
      "Iteataion 958: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.4534e-06.\n",
      "Iterataion 959: Training Loss: 0.015231218832770841, Validation Loss: 0.12051048058953999\n",
      "Iteataion 959: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.3888e-06.\n",
      "Iterataion 960: Training Loss: 0.01200300372522157, Validation Loss: 0.12496509786025144\n",
      "Iteataion 960: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 6.3250e-06.\n",
      "Iterataion 961: Training Loss: 0.01420898719646823, Validation Loss: 0.1259679631131315\n",
      "Iteataion 961: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.2617e-06.\n",
      "Iterataion 962: Training Loss: 0.015024857681654505, Validation Loss: 0.12134149803910632\n",
      "Iteataion 962: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.1991e-06.\n",
      "Iterataion 963: Training Loss: 0.012664703290468962, Validation Loss: 0.12152310464852036\n",
      "Iteataion 963: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.1371e-06.\n",
      "Iterataion 964: Training Loss: 0.015619539978501282, Validation Loss: 0.11974948383839347\n",
      "Iteataion 964: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.0757e-06.\n",
      "Iterataion 965: Training Loss: 0.014263383688301986, Validation Loss: 0.12594978840419704\n",
      "Iteataion 965: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.0150e-06.\n",
      "Iterataion 966: Training Loss: 0.014861711320079707, Validation Loss: 0.12133404525655617\n",
      "Iteataion 966: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.9548e-06.\n",
      "Iterataion 967: Training Loss: 0.016635009159074683, Validation Loss: 0.11741725907649664\n",
      "Iteataion 967: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.8953e-06.\n",
      "Iterataion 968: Training Loss: 0.012508425458326021, Validation Loss: 0.121402617509863\n",
      "Iteataion 968: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.8363e-06.\n",
      "Iterataion 969: Training Loss: 0.016960926781775163, Validation Loss: 0.1187474759190525\n",
      "Iteataion 969: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.7780e-06.\n",
      "Iterataion 970: Training Loss: 0.017948120985107643, Validation Loss: 0.12753249021536647\n",
      "Iteataion 970: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.7202e-06.\n",
      "Iterataion 971: Training Loss: 0.012668407710532596, Validation Loss: 0.12283095348308362\n",
      "Iteataion 971: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.6630e-06.\n",
      "Iterataion 972: Training Loss: 0.01133316097844498, Validation Loss: 0.12466845551517042\n",
      "Iteataion 972: Training Accuracy: 0.9969308035714286, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.6063e-06.\n",
      "Iterataion 973: Training Loss: 0.013344232759070387, Validation Loss: 0.12165776073716854\n",
      "Iteataion 973: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.5503e-06.\n",
      "Iterataion 974: Training Loss: 0.015741978362613932, Validation Loss: 0.12181464477907866\n",
      "Iteataion 974: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.4948e-06.\n",
      "Iterataion 975: Training Loss: 0.014074891108376794, Validation Loss: 0.12178925412462843\n",
      "Iteataion 975: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.4398e-06.\n",
      "Iterataion 976: Training Loss: 0.012035194802353114, Validation Loss: 0.11814093569339049\n",
      "Iteataion 976: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.3854e-06.\n",
      "Iterataion 977: Training Loss: 0.01387198923802572, Validation Loss: 0.12165855346943207\n",
      "Iteataion 977: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.3316e-06.\n",
      "Iterataion 978: Training Loss: 0.011386779610110826, Validation Loss: 0.11813681606748482\n",
      "Iteataion 978: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 5.2783e-06.\n",
      "Iterataion 979: Training Loss: 0.013291032987292633, Validation Loss: 0.1245754694639955\n",
      "Iteataion 979: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.2255e-06.\n",
      "Iterataion 980: Training Loss: 0.013580406828285724, Validation Loss: 0.11740296901623923\n",
      "Iteataion 980: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.1732e-06.\n",
      "Iterataion 981: Training Loss: 0.01247595335269057, Validation Loss: 0.12610317452487013\n",
      "Iteataion 981: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.1215e-06.\n",
      "Iterataion 982: Training Loss: 0.013606655063919032, Validation Loss: 0.12187615933362395\n",
      "Iteataion 982: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.0703e-06.\n",
      "Iterataion 983: Training Loss: 0.015228356851312238, Validation Loss: 0.12226984581609097\n",
      "Iteataion 983: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.0196e-06.\n",
      "Iterataion 984: Training Loss: 0.01302234144305565, Validation Loss: 0.13113591987242149\n",
      "Iteataion 984: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.9694e-06.\n",
      "Iterataion 985: Training Loss: 0.014806361290212152, Validation Loss: 0.1187248296635339\n",
      "Iteataion 985: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.9197e-06.\n",
      "Iterataion 986: Training Loss: 0.01219898775623537, Validation Loss: 0.11985921282491578\n",
      "Iteataion 986: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.8705e-06.\n",
      "Iterataion 987: Training Loss: 0.013929318545336003, Validation Loss: 0.12080303017368041\n",
      "Iteataion 987: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.8218e-06.\n",
      "Iterataion 988: Training Loss: 0.015422243398194575, Validation Loss: 0.12174210182416662\n",
      "Iteataion 988: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.7736e-06.\n",
      "Iterataion 989: Training Loss: 0.011420483589046886, Validation Loss: 0.11887085400862483\n",
      "Iteataion 989: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.7258e-06.\n",
      "Iterataion 990: Training Loss: 0.012987076242636989, Validation Loss: 0.11770314206908707\n",
      "Iteataion 990: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.6786e-06.\n",
      "Iterataion 991: Training Loss: 0.014197669136979266, Validation Loss: 0.11911305026775908\n",
      "Iteataion 991: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.6318e-06.\n",
      "Iterataion 992: Training Loss: 0.013533738214511447, Validation Loss: 0.12323245004092048\n",
      "Iteataion 992: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.5855e-06.\n",
      "Iterataion 993: Training Loss: 0.014057260489406365, Validation Loss: 0.12093115078353482\n",
      "Iteataion 993: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.5396e-06.\n",
      "Iterataion 994: Training Loss: 0.01480831285348876, Validation Loss: 0.12001739273546264\n",
      "Iteataion 994: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.4942e-06.\n",
      "Iterataion 995: Training Loss: 0.016226552869123546, Validation Loss: 0.11958648226502147\n",
      "Iteataion 995: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.4493e-06.\n",
      "Iterataion 996: Training Loss: 0.01057548054339208, Validation Loss: 0.12152398601401507\n",
      "Iteataion 996: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.4048e-06.\n",
      "Iterataion 997: Training Loss: 0.012642165053772466, Validation Loss: 0.12041091438661125\n",
      "Iteataion 997: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.3607e-06.\n",
      "Iterataion 998: Training Loss: 0.012658521587211738, Validation Loss: 0.1206053339609331\n",
      "Iteataion 998: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.3171e-06.\n",
      "Iterataion 999: Training Loss: 0.014461844474109291, Validation Loss: 0.11756832726731352\n",
      "Iteataion 999: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 4.2740e-06.\n",
      "Iterataion 1000: Training Loss: 0.01137258094096902, Validation Loss: 0.11563347772022187\n",
      "Iteataion 1000: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.2312e-06.\n",
      "Iterataion 1001: Training Loss: 0.016275130763711284, Validation Loss: 0.12371822049068969\n",
      "Iteataion 1001: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.1889e-06.\n",
      "Iterataion 1002: Training Loss: 0.013533800928734945, Validation Loss: 0.12182353279360275\n",
      "Iteataion 1002: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.1470e-06.\n",
      "Iterataion 1003: Training Loss: 0.01727502895372747, Validation Loss: 0.11870368453532049\n",
      "Iteataion 1003: Training Accuracy: 0.994140625, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.1055e-06.\n",
      "Iterataion 1004: Training Loss: 0.016505852973222466, Validation Loss: 0.1215003934524181\n",
      "Iteataion 1004: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.0645e-06.\n",
      "Iterataion 1005: Training Loss: 0.016031232724889197, Validation Loss: 0.11863723818053741\n",
      "Iteataion 1005: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.0238e-06.\n",
      "Iterataion 1006: Training Loss: 0.013892464422687755, Validation Loss: 0.12525244478971084\n",
      "Iteataion 1006: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.9836e-06.\n",
      "Iterataion 1007: Training Loss: 0.010154776388610585, Validation Loss: 0.12114875260229427\n",
      "Iteataion 1007: Training Accuracy: 0.9969308035714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.9438e-06.\n",
      "Iterataion 1008: Training Loss: 0.014079510819858419, Validation Loss: 0.11644005139426487\n",
      "Iteataion 1008: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.9043e-06.\n",
      "Iterataion 1009: Training Loss: 0.01341211910392325, Validation Loss: 0.11842060195446787\n",
      "Iteataion 1009: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.8653e-06.\n",
      "Iterataion 1010: Training Loss: 0.015482816076976899, Validation Loss: 0.11683632892119221\n",
      "Iteataion 1010: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.8266e-06.\n",
      "Iterataion 1011: Training Loss: 0.013289944633345182, Validation Loss: 0.11995537877054431\n",
      "Iteataion 1011: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.7884e-06.\n",
      "Iterataion 1012: Training Loss: 0.012927793758268842, Validation Loss: 0.11855517543579747\n",
      "Iteataion 1012: Training Accuracy: 0.99609375, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.7505e-06.\n",
      "Iterataion 1013: Training Loss: 0.011919424709310466, Validation Loss: 0.11789241786648678\n",
      "Iteataion 1013: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.7130e-06.\n",
      "Iterataion 1014: Training Loss: 0.014905691001331434, Validation Loss: 0.11818084212888895\n",
      "Iteataion 1014: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.6758e-06.\n",
      "Iterataion 1015: Training Loss: 0.011352872807277412, Validation Loss: 0.1218447323715337\n",
      "Iteataion 1015: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.6391e-06.\n",
      "Iterataion 1016: Training Loss: 0.015418636623399143, Validation Loss: 0.11869482953873713\n",
      "Iteataion 1016: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.6027e-06.\n",
      "Iterataion 1017: Training Loss: 0.015032891683387822, Validation Loss: 0.1198191272617295\n",
      "Iteataion 1017: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.5667e-06.\n",
      "Iterataion 1018: Training Loss: 0.013875444508039163, Validation Loss: 0.12330461056369198\n",
      "Iteataion 1018: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.5310e-06.\n",
      "Iterataion 1019: Training Loss: 0.014636787795392004, Validation Loss: 0.11763645852944336\n",
      "Iteataion 1019: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.4957e-06.\n",
      "Iterataion 1020: Training Loss: 0.014917681621064148, Validation Loss: 0.12074598869757454\n",
      "Iteataion 1020: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.4607e-06.\n",
      "Iterataion 1021: Training Loss: 0.015476449598902613, Validation Loss: 0.12496715758802233\n",
      "Iteataion 1021: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.4261e-06.\n",
      "Iterataion 1022: Training Loss: 0.015770747503377276, Validation Loss: 0.11834184770052117\n",
      "Iteataion 1022: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.3919e-06.\n",
      "Iterataion 1023: Training Loss: 0.012561808099229905, Validation Loss: 0.12122576030130248\n",
      "Iteataion 1023: Training Accuracy: 0.9967447916666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.3580e-06.\n",
      "Iterataion 1024: Training Loss: 0.011537034925621303, Validation Loss: 0.11829480822709185\n",
      "Iteataion 1024: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.3244e-06.\n",
      "Iterataion 1025: Training Loss: 0.01578285996237502, Validation Loss: 0.11990131310573439\n",
      "Iteataion 1025: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.2911e-06.\n",
      "Iterataion 1026: Training Loss: 0.013721745313963613, Validation Loss: 0.12035866225672114\n",
      "Iteataion 1026: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.2582e-06.\n",
      "Iterataion 1027: Training Loss: 0.013345754787627005, Validation Loss: 0.12293636089718969\n",
      "Iteataion 1027: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.2256e-06.\n",
      "Iterataion 1028: Training Loss: 0.015745344830218222, Validation Loss: 0.12070557445844227\n",
      "Iteataion 1028: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.1934e-06.\n",
      "Iterataion 1029: Training Loss: 0.011524567114604737, Validation Loss: 0.12572033885616538\n",
      "Iteataion 1029: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.1614e-06.\n",
      "Iterataion 1030: Training Loss: 0.012382453714265952, Validation Loss: 0.12009240544497649\n",
      "Iteataion 1030: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.1298e-06.\n",
      "Iterataion 1031: Training Loss: 0.012202035470323325, Validation Loss: 0.12207318771426089\n",
      "Iteataion 1031: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.0985e-06.\n",
      "Iterataion 1032: Training Loss: 0.014586645644158125, Validation Loss: 0.12146792283406617\n",
      "Iteataion 1032: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.0675e-06.\n",
      "Iterataion 1033: Training Loss: 0.013726973566672804, Validation Loss: 0.11990635182776647\n",
      "Iteataion 1033: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.0369e-06.\n",
      "Iterataion 1034: Training Loss: 0.014732564180464801, Validation Loss: 0.12040315581224405\n",
      "Iteataion 1034: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.0065e-06.\n",
      "Iterataion 1035: Training Loss: 0.015076728723803815, Validation Loss: 0.12097253634952145\n",
      "Iteataion 1035: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.9764e-06.\n",
      "Iterataion 1036: Training Loss: 0.01354331389894921, Validation Loss: 0.12449532210622437\n",
      "Iteataion 1036: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.9467e-06.\n",
      "Iterataion 1037: Training Loss: 0.013615679464994477, Validation Loss: 0.12357194671157475\n",
      "Iteataion 1037: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.9172e-06.\n",
      "Iterataion 1038: Training Loss: 0.014434119190673573, Validation Loss: 0.11745894097910467\n",
      "Iteataion 1038: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.8880e-06.\n",
      "Iterataion 1039: Training Loss: 0.013602537044789642, Validation Loss: 0.12205759930799193\n",
      "Iteataion 1039: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.8592e-06.\n",
      "Iterataion 1040: Training Loss: 0.014671193463846339, Validation Loss: 0.11924641846222007\n",
      "Iteataion 1040: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 2.8306e-06.\n",
      "Iterataion 1041: Training Loss: 0.011915075125989733, Validation Loss: 0.12254009106006224\n",
      "Iteataion 1041: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.8023e-06.\n",
      "Iterataion 1042: Training Loss: 0.013098544150125235, Validation Loss: 0.1227399530606174\n",
      "Iteataion 1042: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.7742e-06.\n",
      "Iterataion 1043: Training Loss: 0.012952489910499488, Validation Loss: 0.11899227112611165\n",
      "Iteataion 1043: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.7465e-06.\n",
      "Iterataion 1044: Training Loss: 0.014813357235342375, Validation Loss: 0.1278431732257226\n",
      "Iteataion 1044: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.7190e-06.\n",
      "Iterataion 1045: Training Loss: 0.012558597032312572, Validation Loss: 0.12272113759110387\n",
      "Iteataion 1045: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.6918e-06.\n",
      "Iterataion 1046: Training Loss: 0.012495040841969455, Validation Loss: 0.1176626809032225\n",
      "Iteataion 1046: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.6649e-06.\n",
      "Iterataion 1047: Training Loss: 0.012440731454240492, Validation Loss: 0.12175440848393297\n",
      "Iteataion 1047: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.6383e-06.\n",
      "Iterataion 1048: Training Loss: 0.010371508925503488, Validation Loss: 0.11873867095550295\n",
      "Iteataion 1048: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.6119e-06.\n",
      "Iterataion 1049: Training Loss: 0.010485382549169133, Validation Loss: 0.11844303480011592\n",
      "Iteataion 1049: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.5858e-06.\n",
      "Iterataion 1050: Training Loss: 0.013249767072670284, Validation Loss: 0.1214538574653178\n",
      "Iteataion 1050: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.5599e-06.\n",
      "Iterataion 1051: Training Loss: 0.01310137541292648, Validation Loss: 0.12059191534744303\n",
      "Iteataion 1051: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.5343e-06.\n",
      "Iterataion 1052: Training Loss: 0.014292351973680836, Validation Loss: 0.12133034569972263\n",
      "Iteataion 1052: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.5090e-06.\n",
      "Iterataion 1053: Training Loss: 0.019614153032917473, Validation Loss: 0.12096386707370828\n",
      "Iteataion 1053: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.4839e-06.\n",
      "Iterataion 1054: Training Loss: 0.017768622272854258, Validation Loss: 0.11950640947836247\n",
      "Iteataion 1054: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.4590e-06.\n",
      "Iterataion 1055: Training Loss: 0.014665589471100858, Validation Loss: 0.12112559309007781\n",
      "Iteataion 1055: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.4344e-06.\n",
      "Iterataion 1056: Training Loss: 0.01124243264283126, Validation Loss: 0.12236220845044023\n",
      "Iteataion 1056: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.4101e-06.\n",
      "Iterataion 1057: Training Loss: 0.013829746363059935, Validation Loss: 0.1194528546865757\n",
      "Iteataion 1057: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.3860e-06.\n",
      "Iterataion 1058: Training Loss: 0.012566669447093778, Validation Loss: 0.11964982196620506\n",
      "Iteataion 1058: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.3621e-06.\n",
      "Iterataion 1059: Training Loss: 0.015387133098120974, Validation Loss: 0.12416846610793117\n",
      "Iteataion 1059: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.3385e-06.\n",
      "Iterataion 1060: Training Loss: 0.01589599948740302, Validation Loss: 0.11894935890237188\n",
      "Iteataion 1060: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.3151e-06.\n",
      "Iterataion 1061: Training Loss: 0.013722281811360136, Validation Loss: 0.11725607897416211\n",
      "Iteataion 1061: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.2920e-06.\n",
      "Iterataion 1062: Training Loss: 0.010989689786638227, Validation Loss: 0.12037264506145176\n",
      "Iteataion 1062: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.2691e-06.\n",
      "Iterataion 1063: Training Loss: 0.016581109757353916, Validation Loss: 0.12162161941310709\n",
      "Iteataion 1063: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.2464e-06.\n",
      "Iterataion 1064: Training Loss: 0.014527425780079557, Validation Loss: 0.11793320037555177\n",
      "Iteataion 1064: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.2239e-06.\n",
      "Iterataion 1065: Training Loss: 0.011777927040493305, Validation Loss: 0.121045078778435\n",
      "Iteataion 1065: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.2017e-06.\n",
      "Iterataion 1066: Training Loss: 0.01734965592817944, Validation Loss: 0.11999153712105642\n",
      "Iteataion 1066: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.1797e-06.\n",
      "Iterataion 1067: Training Loss: 0.013252322409897318, Validation Loss: 0.11859530450175687\n",
      "Iteataion 1067: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.1579e-06.\n",
      "Iterataion 1068: Training Loss: 0.013875643690472223, Validation Loss: 0.1303922162453712\n",
      "Iteataion 1068: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.1363e-06.\n",
      "Iterataion 1069: Training Loss: 0.014223295918346555, Validation Loss: 0.11768825829920654\n",
      "Iteataion 1069: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 2.1149e-06.\n",
      "Iterataion 1070: Training Loss: 0.012928317796786087, Validation Loss: 0.11941726227921275\n",
      "Iteataion 1070: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.0938e-06.\n",
      "Iterataion 1071: Training Loss: 0.015575274017856952, Validation Loss: 0.12143637596845354\n",
      "Iteataion 1071: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.0728e-06.\n",
      "Iterataion 1072: Training Loss: 0.010591941388445198, Validation Loss: 0.11503546350286342\n",
      "Iteataion 1072: Training Accuracy: 0.9970238095238095, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.0521e-06.\n",
      "Iterataion 1073: Training Loss: 0.018405755866781812, Validation Loss: 0.12190387912219526\n",
      "Iteataion 1073: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.0316e-06.\n",
      "Iterataion 1074: Training Loss: 0.015097542093930109, Validation Loss: 0.12009779719363262\n",
      "Iteataion 1074: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.0113e-06.\n",
      "Iterataion 1075: Training Loss: 0.011900084815754884, Validation Loss: 0.12102569872939323\n",
      "Iteataion 1075: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.9912e-06.\n",
      "Iterataion 1076: Training Loss: 0.016311418321394936, Validation Loss: 0.12320843251938818\n",
      "Iteataion 1076: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.9712e-06.\n",
      "Iterataion 1077: Training Loss: 0.013626733231030594, Validation Loss: 0.12640613088634137\n",
      "Iteataion 1077: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.9515e-06.\n",
      "Iterataion 1078: Training Loss: 0.019076703268613576, Validation Loss: 0.12211586434178327\n",
      "Iteataion 1078: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.9320e-06.\n",
      "Iterataion 1079: Training Loss: 0.014044790707171677, Validation Loss: 0.12227943386504904\n",
      "Iteataion 1079: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.9127e-06.\n",
      "Iterataion 1080: Training Loss: 0.013313768882043716, Validation Loss: 0.12462270670434142\n",
      "Iteataion 1080: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.8936e-06.\n",
      "Iterataion 1081: Training Loss: 0.014216138785049699, Validation Loss: 0.12099597099515405\n",
      "Iteataion 1081: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.8746e-06.\n",
      "Iterataion 1082: Training Loss: 0.013924832407539866, Validation Loss: 0.12736194366560794\n",
      "Iteataion 1082: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.8559e-06.\n",
      "Iterataion 1083: Training Loss: 0.014255445051281629, Validation Loss: 0.11952632467444169\n",
      "Iteataion 1083: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.8373e-06.\n",
      "Iterataion 1084: Training Loss: 0.014734288705979938, Validation Loss: 0.11845182679116545\n",
      "Iteataion 1084: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.8190e-06.\n",
      "Iterataion 1085: Training Loss: 0.012871546634545405, Validation Loss: 0.12058184448368393\n",
      "Iteataion 1085: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.8008e-06.\n",
      "Iterataion 1086: Training Loss: 0.0142677591816999, Validation Loss: 0.1166332768242261\n",
      "Iteataion 1086: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.7828e-06.\n",
      "Iterataion 1087: Training Loss: 0.01305812102056549, Validation Loss: 0.12049696899853965\n",
      "Iteataion 1087: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.7649e-06.\n",
      "Iterataion 1088: Training Loss: 0.010750415083508894, Validation Loss: 0.12005246521993086\n",
      "Iteataion 1088: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.7473e-06.\n",
      "Iterataion 1089: Training Loss: 0.014074480633877362, Validation Loss: 0.12519031999172733\n",
      "Iteataion 1089: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.7298e-06.\n",
      "Iterataion 1090: Training Loss: 0.017969202708583994, Validation Loss: 0.11706685370811057\n",
      "Iteataion 1090: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.7125e-06.\n",
      "Iterataion 1091: Training Loss: 0.014267126556965494, Validation Loss: 0.12283785012266712\n",
      "Iteataion 1091: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.6954e-06.\n",
      "Iterataion 1092: Training Loss: 0.013206408695285738, Validation Loss: 0.11757681428003353\n",
      "Iteataion 1092: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.6784e-06.\n",
      "Iterataion 1093: Training Loss: 0.012392128056332101, Validation Loss: 0.12191771297352161\n",
      "Iteataion 1093: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.6616e-06.\n",
      "Iterataion 1094: Training Loss: 0.013000852149363307, Validation Loss: 0.12363642068841017\n",
      "Iteataion 1094: Training Accuracy: 0.99609375, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.6450e-06.\n",
      "Iterataion 1095: Training Loss: 0.010662002234704357, Validation Loss: 0.12398157509259607\n",
      "Iteataion 1095: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.6286e-06.\n",
      "Iterataion 1096: Training Loss: 0.01669339378434791, Validation Loss: 0.12144150372904089\n",
      "Iteataion 1096: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6123e-06.\n",
      "Iterataion 1097: Training Loss: 0.01427151588897338, Validation Loss: 0.1274777814453445\n",
      "Iteataion 1097: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.5962e-06.\n",
      "Iterataion 1098: Training Loss: 0.012054906553110598, Validation Loss: 0.12550975233827513\n",
      "Iteataion 1098: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.5802e-06.\n",
      "Iterataion 1099: Training Loss: 0.014860211160524698, Validation Loss: 0.12629456925858948\n",
      "Iteataion 1099: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.5644e-06.\n",
      "Iterataion 1100: Training Loss: 0.012722297383208821, Validation Loss: 0.12343129178611334\n",
      "Iteataion 1100: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.5488e-06.\n",
      "Iterataion 1101: Training Loss: 0.013511676606018107, Validation Loss: 0.11713441563968933\n",
      "Iteataion 1101: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.5333e-06.\n",
      "Iterataion 1102: Training Loss: 0.011171246545938608, Validation Loss: 0.12189200407223458\n",
      "Iteataion 1102: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.5179e-06.\n",
      "Iterataion 1103: Training Loss: 0.013918399905247758, Validation Loss: 0.12087953704261653\n",
      "Iteataion 1103: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.5028e-06.\n",
      "Iterataion 1104: Training Loss: 0.012299633338318268, Validation Loss: 0.12136222487287142\n",
      "Iteataion 1104: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4877e-06.\n",
      "Iterataion 1105: Training Loss: 0.013063719672496671, Validation Loss: 0.1232598605224999\n",
      "Iteataion 1105: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4729e-06.\n",
      "Iterataion 1106: Training Loss: 0.014808577567117266, Validation Loss: 0.11829851193228601\n",
      "Iteataion 1106: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4581e-06.\n",
      "Iterataion 1107: Training Loss: 0.01435519044753164, Validation Loss: 0.11763331576011984\n",
      "Iteataion 1107: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4435e-06.\n",
      "Iterataion 1108: Training Loss: 0.011207285951816024, Validation Loss: 0.1144021420239857\n",
      "Iteataion 1108: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.4291e-06.\n",
      "Iterataion 1109: Training Loss: 0.012907061019346319, Validation Loss: 0.11919816463004525\n",
      "Iteataion 1109: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4148e-06.\n",
      "Iterataion 1110: Training Loss: 0.01416663106525328, Validation Loss: 0.12376077634441417\n",
      "Iteataion 1110: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4007e-06.\n",
      "Iterataion 1111: Training Loss: 0.015984495839279723, Validation Loss: 0.1197368248419768\n",
      "Iteataion 1111: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.3867e-06.\n",
      "Iterataion 1112: Training Loss: 0.013810400938208098, Validation Loss: 0.11932011286262423\n",
      "Iteataion 1112: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 1.3728e-06.\n",
      "Iterataion 1113: Training Loss: 0.015190868469409667, Validation Loss: 0.11806834642008719\n",
      "Iteataion 1113: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.3591e-06.\n",
      "Iterataion 1114: Training Loss: 0.01784462968067372, Validation Loss: 0.11850291303722416\n",
      "Iteataion 1114: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.3455e-06.\n",
      "Iterataion 1115: Training Loss: 0.01228438063300198, Validation Loss: 0.12394790820601373\n",
      "Iteataion 1115: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.3320e-06.\n",
      "Iterataion 1116: Training Loss: 0.012744836104736791, Validation Loss: 0.11692143588826605\n",
      "Iteataion 1116: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.3187e-06.\n",
      "Iterataion 1117: Training Loss: 0.014314083712563075, Validation Loss: 0.11849491822635527\n",
      "Iteataion 1117: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.3055e-06.\n",
      "Iterataion 1118: Training Loss: 0.014208325568808265, Validation Loss: 0.12113184052684185\n",
      "Iteataion 1118: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.2925e-06.\n",
      "Iterataion 1119: Training Loss: 0.013651772551057291, Validation Loss: 0.11888981403899379\n",
      "Iteataion 1119: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.2795e-06.\n",
      "Iterataion 1120: Training Loss: 0.014660207245186596, Validation Loss: 0.11678502029773392\n",
      "Iteataion 1120: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2667e-06.\n",
      "Iterataion 1121: Training Loss: 0.015183341270800635, Validation Loss: 0.11717710440137946\n",
      "Iteataion 1121: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2541e-06.\n",
      "Iterataion 1122: Training Loss: 0.01070448000755713, Validation Loss: 0.11773740322465395\n",
      "Iteataion 1122: Training Accuracy: 0.9968377976190477, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2415e-06.\n",
      "Iterataion 1123: Training Loss: 0.013524696628234075, Validation Loss: 0.11840536942699834\n",
      "Iteataion 1123: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2291e-06.\n",
      "Iterataion 1124: Training Loss: 0.012896239491595055, Validation Loss: 0.12033537654958597\n",
      "Iteataion 1124: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.2168e-06.\n",
      "Iterataion 1125: Training Loss: 0.01577139798845276, Validation Loss: 0.11763173836516216\n",
      "Iteataion 1125: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2047e-06.\n",
      "Iterataion 1126: Training Loss: 0.009544302434744146, Validation Loss: 0.11812221889367054\n",
      "Iteataion 1126: Training Accuracy: 0.9973028273809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1926e-06.\n",
      "Iterataion 1127: Training Loss: 0.011624248232169657, Validation Loss: 0.12045140894876634\n",
      "Iteataion 1127: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.1807e-06.\n",
      "Iterataion 1128: Training Loss: 0.014711121564611102, Validation Loss: 0.12348535745092327\n",
      "Iteataion 1128: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.1689e-06.\n",
      "Iterataion 1129: Training Loss: 0.013173910656394604, Validation Loss: 0.11629771205977105\n",
      "Iteataion 1129: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1572e-06.\n",
      "Iterataion 1130: Training Loss: 0.014922870925354386, Validation Loss: 0.1285475730759705\n",
      "Iteataion 1130: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1456e-06.\n",
      "Iterataion 1131: Training Loss: 0.015024055227878487, Validation Loss: 0.12582472159609584\n",
      "Iteataion 1131: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1342e-06.\n",
      "Iterataion 1132: Training Loss: 0.01487541767213672, Validation Loss: 0.12182138427998303\n",
      "Iteataion 1132: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.1228e-06.\n",
      "Iterataion 1133: Training Loss: 0.009899766170796185, Validation Loss: 0.12400872463987936\n",
      "Iteataion 1133: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1116e-06.\n",
      "Iterataion 1134: Training Loss: 0.013907245781361878, Validation Loss: 0.12450878083047162\n",
      "Iteataion 1134: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.1005e-06.\n",
      "Iterataion 1135: Training Loss: 0.014713725751659046, Validation Loss: 0.1183124818106568\n",
      "Iteataion 1135: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0895e-06.\n",
      "Iterataion 1136: Training Loss: 0.010642365220666467, Validation Loss: 0.1258452850615424\n",
      "Iteataion 1136: Training Accuracy: 0.9968377976190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0786e-06.\n",
      "Iterataion 1137: Training Loss: 0.012365005268021013, Validation Loss: 0.12054610203400754\n",
      "Iteataion 1137: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.0678e-06.\n",
      "Iterataion 1138: Training Loss: 0.01207569743817516, Validation Loss: 0.11610580915613554\n",
      "Iteataion 1138: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0571e-06.\n",
      "Iterataion 1139: Training Loss: 0.01459312639153886, Validation Loss: 0.12104113904259554\n",
      "Iteataion 1139: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0465e-06.\n",
      "Iterataion 1140: Training Loss: 0.015071136863347321, Validation Loss: 0.12352275817013322\n",
      "Iteataion 1140: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0361e-06.\n",
      "Iterataion 1141: Training Loss: 0.011566902590116687, Validation Loss: 0.12252437790625774\n",
      "Iteataion 1141: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.0257e-06.\n",
      "Iterataion 1142: Training Loss: 0.014233762488462042, Validation Loss: 0.11862824724067184\n",
      "Iteataion 1142: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0155e-06.\n",
      "Iterataion 1143: Training Loss: 0.015306759551083836, Validation Loss: 0.12155694429756983\n",
      "Iteataion 1143: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0053e-06.\n",
      "Iterataion 1144: Training Loss: 0.01465318636905296, Validation Loss: 0.12361127988821487\n",
      "Iteataion 1144: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 9.9525e-07.\n",
      "Iterataion 1145: Training Loss: 0.013839791065310601, Validation Loss: 0.12018061677212599\n",
      "Iteataion 1145: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.8530e-07.\n",
      "Iterataion 1146: Training Loss: 0.014400893927748388, Validation Loss: 0.12758586496375957\n",
      "Iteataion 1146: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.7545e-07.\n",
      "Iterataion 1147: Training Loss: 0.012954870121787766, Validation Loss: 0.11962051281816236\n",
      "Iteataion 1147: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.6569e-07.\n",
      "Iterataion 1148: Training Loss: 0.015200491330808051, Validation Loss: 0.11803461361971752\n",
      "Iteataion 1148: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 9.5603e-07.\n",
      "Iterataion 1149: Training Loss: 0.012123775957737809, Validation Loss: 0.11859105309051257\n",
      "Iteataion 1149: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.4647e-07.\n",
      "Iterataion 1150: Training Loss: 0.009424866667549924, Validation Loss: 0.12555683143976396\n",
      "Iteataion 1150: Training Accuracy: 0.9972098214285714, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 9.3701e-07.\n",
      "Iterataion 1151: Training Loss: 0.014813057834653373, Validation Loss: 0.11892904363936041\n",
      "Iteataion 1151: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 9.2764e-07.\n",
      "Iterataion 1152: Training Loss: 0.013619117848163827, Validation Loss: 0.11908489665323187\n",
      "Iteataion 1152: Training Accuracy: 0.99609375, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.1836e-07.\n",
      "Iterataion 1153: Training Loss: 0.019309759587551396, Validation Loss: 0.11921037732277111\n",
      "Iteataion 1153: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.0918e-07.\n",
      "Iterataion 1154: Training Loss: 0.012124838774729642, Validation Loss: 0.12396101184081422\n",
      "Iteataion 1154: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.0009e-07.\n",
      "Iterataion 1155: Training Loss: 0.012288306747747217, Validation Loss: 0.12156758608762175\n",
      "Iteataion 1155: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.9109e-07.\n",
      "Iterataion 1156: Training Loss: 0.012353151983338893, Validation Loss: 0.11825387672771041\n",
      "Iteataion 1156: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 8.8218e-07.\n",
      "Iterataion 1157: Training Loss: 0.014444875694716539, Validation Loss: 0.11946795387307137\n",
      "Iteataion 1157: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 8.7335e-07.\n",
      "Iterataion 1158: Training Loss: 0.01604279076637321, Validation Loss: 0.12387157594160426\n",
      "Iteataion 1158: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.6462e-07.\n",
      "Iterataion 1159: Training Loss: 0.014032939372620472, Validation Loss: 0.12118610126255988\n",
      "Iteataion 1159: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 8.5597e-07.\n",
      "Iterataion 1160: Training Loss: 0.011993245184379714, Validation Loss: 0.12125817824881978\n",
      "Iteataion 1160: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.4741e-07.\n",
      "Iterataion 1161: Training Loss: 0.01647836489541579, Validation Loss: 0.11982750634821814\n",
      "Iteataion 1161: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 8.3894e-07.\n",
      "Iterataion 1162: Training Loss: 0.015166119593237442, Validation Loss: 0.12323457248247706\n",
      "Iteataion 1162: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 8.3055e-07.\n",
      "Iterataion 1163: Training Loss: 0.013178039288837016, Validation Loss: 0.11737160297911386\n",
      "Iteataion 1163: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.2225e-07.\n",
      "Iterataion 1164: Training Loss: 0.017875370291907975, Validation Loss: 0.11932618602991059\n",
      "Iteataion 1164: Training Accuracy: 0.9939546130952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 8.1402e-07.\n",
      "Iterataion 1165: Training Loss: 0.014060156800140052, Validation Loss: 0.12088936675771526\n",
      "Iteataion 1165: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 8.0588e-07.\n",
      "Iterataion 1166: Training Loss: 0.014439198840095823, Validation Loss: 0.11956681858140566\n",
      "Iteataion 1166: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 7.9782e-07.\n",
      "Iterataion 1167: Training Loss: 0.014411415082010758, Validation Loss: 0.11987437697116105\n",
      "Iteataion 1167: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.8985e-07.\n",
      "Iterataion 1168: Training Loss: 0.013244073822833654, Validation Loss: 0.11863507071748466\n",
      "Iteataion 1168: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.8195e-07.\n",
      "Iterataion 1169: Training Loss: 0.01316344607440186, Validation Loss: 0.12115055871076837\n",
      "Iteataion 1169: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.7413e-07.\n",
      "Iterataion 1170: Training Loss: 0.013015585253712257, Validation Loss: 0.11822409921456356\n",
      "Iteataion 1170: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 7.6639e-07.\n",
      "Iterataion 1171: Training Loss: 0.012760475776325577, Validation Loss: 0.12462014111224562\n",
      "Iteataion 1171: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.5872e-07.\n",
      "Iterataion 1172: Training Loss: 0.010501464315262082, Validation Loss: 0.12102674216134246\n",
      "Iteataion 1172: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.5114e-07.\n",
      "Iterataion 1173: Training Loss: 0.01506007495538393, Validation Loss: 0.11979353502279193\n",
      "Iteataion 1173: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.4362e-07.\n",
      "Iterataion 1174: Training Loss: 0.0130709392509373, Validation Loss: 0.11742513455598183\n",
      "Iteataion 1174: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.3619e-07.\n",
      "Iterataion 1175: Training Loss: 0.014637961838161573, Validation Loss: 0.12149583091235311\n",
      "Iteataion 1175: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.2883e-07.\n",
      "Iterataion 1176: Training Loss: 0.011035245813082201, Validation Loss: 0.1223854595147891\n",
      "Iteataion 1176: Training Accuracy: 0.99609375, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.2154e-07.\n",
      "Iterataion 1177: Training Loss: 0.01342156408218706, Validation Loss: 0.11927950252898083\n",
      "Iteataion 1177: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.1432e-07.\n",
      "Iterataion 1178: Training Loss: 0.02092522802319333, Validation Loss: 0.12287521085392389\n",
      "Iteataion 1178: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.0718e-07.\n",
      "Iterataion 1179: Training Loss: 0.010536328647188106, Validation Loss: 0.11781482162839937\n",
      "Iteataion 1179: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.0011e-07.\n",
      "Iterataion 1180: Training Loss: 0.014919905806194523, Validation Loss: 0.12310831986151909\n",
      "Iteataion 1180: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.9311e-07.\n",
      "Iterataion 1181: Training Loss: 0.012706124157892976, Validation Loss: 0.1188450423481011\n",
      "Iteataion 1181: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.8618e-07.\n",
      "Iterataion 1182: Training Loss: 0.011326134318142883, Validation Loss: 0.11874881868602753\n",
      "Iteataion 1182: Training Accuracy: 0.9967447916666666, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.7931e-07.\n",
      "Iterataion 1183: Training Loss: 0.014597117828350225, Validation Loss: 0.11848508958596872\n",
      "Iteataion 1183: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 6.7252e-07.\n",
      "Iterataion 1184: Training Loss: 0.014495219417860241, Validation Loss: 0.11822442852937412\n",
      "Iteataion 1184: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.6580e-07.\n",
      "Iterataion 1185: Training Loss: 0.013058502064644175, Validation Loss: 0.11891773403707392\n",
      "Iteataion 1185: Training Accuracy: 0.99609375, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.5914e-07.\n",
      "Iterataion 1186: Training Loss: 0.016190377988400843, Validation Loss: 0.12248451016820604\n",
      "Iteataion 1186: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.5255e-07.\n",
      "Iterataion 1187: Training Loss: 0.015572286715827225, Validation Loss: 0.11901614327472067\n",
      "Iteataion 1187: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.4602e-07.\n",
      "Iterataion 1188: Training Loss: 0.016261539486979976, Validation Loss: 0.12024208245708085\n",
      "Iteataion 1188: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.3956e-07.\n",
      "Iterataion 1189: Training Loss: 0.01336451134439502, Validation Loss: 0.11998665009812656\n",
      "Iteataion 1189: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.3316e-07.\n",
      "Iterataion 1190: Training Loss: 0.013667366190668485, Validation Loss: 0.12533836643120683\n",
      "Iteataion 1190: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.2683e-07.\n",
      "Iterataion 1191: Training Loss: 0.014860566163820376, Validation Loss: 0.12048342179722811\n",
      "Iteataion 1191: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.2056e-07.\n",
      "Iterataion 1192: Training Loss: 0.016534221955487215, Validation Loss: 0.12109701985652309\n",
      "Iteataion 1192: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.1436e-07.\n",
      "Iterataion 1193: Training Loss: 0.013318425814536105, Validation Loss: 0.11851099793651573\n",
      "Iteataion 1193: Training Accuracy: 0.99609375, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.0822e-07.\n",
      "Iterataion 1194: Training Loss: 0.015968514884324343, Validation Loss: 0.12406312896892792\n",
      "Iteataion 1194: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.0213e-07.\n",
      "Iterataion 1195: Training Loss: 0.015046442280457952, Validation Loss: 0.12175662069377012\n",
      "Iteataion 1195: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.9611e-07.\n",
      "Iterataion 1196: Training Loss: 0.01394028070732717, Validation Loss: 0.12226841859547875\n",
      "Iteataion 1196: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.9015e-07.\n",
      "Iterataion 1197: Training Loss: 0.01475434810844038, Validation Loss: 0.11805235846223673\n",
      "Iteataion 1197: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.8425e-07.\n",
      "Iterataion 1198: Training Loss: 0.013739630533939975, Validation Loss: 0.11636606872042005\n",
      "Iteataion 1198: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.7841e-07.\n",
      "Iterataion 1199: Training Loss: 0.014626878860419126, Validation Loss: 0.12160456289037518\n",
      "Iteataion 1199: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.7262e-07.\n",
      "Iterataion 1200: Training Loss: 0.013336265394826626, Validation Loss: 0.11738652850802216\n",
      "Iteataion 1200: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.6690e-07.\n",
      "Iterataion 1201: Training Loss: 0.014807753207393458, Validation Loss: 0.11714271418807073\n",
      "Iteataion 1201: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.6123e-07.\n",
      "Iterataion 1202: Training Loss: 0.016118558868208153, Validation Loss: 0.12003388465382159\n",
      "Iteataion 1202: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.5562e-07.\n",
      "Iterataion 1203: Training Loss: 0.014292885726603574, Validation Loss: 0.12582072018498056\n",
      "Iteataion 1203: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.5006e-07.\n",
      "Iterataion 1204: Training Loss: 0.014429152903459341, Validation Loss: 0.12247236819920788\n",
      "Iteataion 1204: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.4456e-07.\n",
      "Iterataion 1205: Training Loss: 0.015996303668832628, Validation Loss: 0.12007444033615018\n",
      "Iteataion 1205: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.3911e-07.\n",
      "Iterataion 1206: Training Loss: 0.014065938248176374, Validation Loss: 0.11933442777684299\n",
      "Iteataion 1206: Training Accuracy: 0.99609375, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 5.3372e-07.\n",
      "Iterataion 1207: Training Loss: 0.013746674060173233, Validation Loss: 0.11996390780990535\n",
      "Iteataion 1207: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.2838e-07.\n",
      "Iterataion 1208: Training Loss: 0.011722613163857058, Validation Loss: 0.11730787250860708\n",
      "Iteataion 1208: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.2310e-07.\n",
      "Iterataion 1209: Training Loss: 0.012875215049685274, Validation Loss: 0.11772936805741997\n",
      "Iteataion 1209: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.1787e-07.\n",
      "Iterataion 1210: Training Loss: 0.014869648259841352, Validation Loss: 0.1263590594526471\n",
      "Iteataion 1210: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.1269e-07.\n",
      "Iterataion 1211: Training Loss: 0.01329049751811527, Validation Loss: 0.11871219631398051\n",
      "Iteataion 1211: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.0756e-07.\n",
      "Iterataion 1212: Training Loss: 0.013463856590511612, Validation Loss: 0.12162005027227966\n",
      "Iteataion 1212: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.0249e-07.\n",
      "Iterataion 1213: Training Loss: 0.016624209914575357, Validation Loss: 0.11779887353427844\n",
      "Iteataion 1213: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 4.9746e-07.\n",
      "Iterataion 1214: Training Loss: 0.013755692377851016, Validation Loss: 0.11840740201296285\n",
      "Iteataion 1214: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.9249e-07.\n",
      "Iterataion 1215: Training Loss: 0.01186843794992913, Validation Loss: 0.1185346362024841\n",
      "Iteataion 1215: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.8756e-07.\n",
      "Iterataion 1216: Training Loss: 0.012910173684818681, Validation Loss: 0.12187472704184674\n",
      "Iteataion 1216: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.8269e-07.\n",
      "Iterataion 1217: Training Loss: 0.014435413588587095, Validation Loss: 0.1257941975831849\n",
      "Iteataion 1217: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.7786e-07.\n",
      "Iterataion 1218: Training Loss: 0.012819849184371285, Validation Loss: 0.12471533479401842\n",
      "Iteataion 1218: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.7308e-07.\n",
      "Iterataion 1219: Training Loss: 0.01440683002308329, Validation Loss: 0.1234040237990174\n",
      "Iteataion 1219: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.6835e-07.\n",
      "Iterataion 1220: Training Loss: 0.013386384006986997, Validation Loss: 0.12995176227115912\n",
      "Iteataion 1220: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.6367e-07.\n",
      "Iterataion 1221: Training Loss: 0.012332212358704785, Validation Loss: 0.1182950875344232\n",
      "Iteataion 1221: Training Accuracy: 0.9969308035714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.5903e-07.\n",
      "Iterataion 1222: Training Loss: 0.013102946409462076, Validation Loss: 0.12155753611189472\n",
      "Iteataion 1222: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.5444e-07.\n",
      "Iterataion 1223: Training Loss: 0.01432889741953479, Validation Loss: 0.12281363477033176\n",
      "Iteataion 1223: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.4990e-07.\n",
      "Iterataion 1224: Training Loss: 0.013358079954845174, Validation Loss: 0.12142261715248091\n",
      "Iteataion 1224: Training Accuracy: 0.99609375, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.4540e-07.\n",
      "Iterataion 1225: Training Loss: 0.01246368717632262, Validation Loss: 0.11694431255810053\n",
      "Iteataion 1225: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.4094e-07.\n",
      "Iterataion 1226: Training Loss: 0.010692798648263791, Validation Loss: 0.12281714459574532\n",
      "Iteataion 1226: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.3653e-07.\n",
      "Iterataion 1227: Training Loss: 0.012901200151487817, Validation Loss: 0.12289027034066527\n",
      "Iteataion 1227: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.3217e-07.\n",
      "Iterataion 1228: Training Loss: 0.014493983046536495, Validation Loss: 0.12025423650629818\n",
      "Iteataion 1228: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.2785e-07.\n",
      "Iterataion 1229: Training Loss: 0.01527143227916579, Validation Loss: 0.12141232073829486\n",
      "Iteataion 1229: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.2357e-07.\n",
      "Iterataion 1230: Training Loss: 0.012819662568867653, Validation Loss: 0.11901364535683902\n",
      "Iteataion 1230: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.1933e-07.\n",
      "Iterataion 1231: Training Loss: 0.010788500495812672, Validation Loss: 0.12432084347280424\n",
      "Iteataion 1231: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.1514e-07.\n",
      "Iterataion 1232: Training Loss: 0.015103165197261459, Validation Loss: 0.11935379389650756\n",
      "Iteataion 1232: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.1099e-07.\n",
      "Iterataion 1233: Training Loss: 0.011834726393889234, Validation Loss: 0.1189479548455693\n",
      "Iteataion 1233: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.0688e-07.\n",
      "Iterataion 1234: Training Loss: 0.01351784674320398, Validation Loss: 0.11656429326422967\n",
      "Iteataion 1234: Training Accuracy: 0.99609375, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.0281e-07.\n",
      "Iterataion 1235: Training Loss: 0.01327942155979847, Validation Loss: 0.12096417265115078\n",
      "Iteataion 1235: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.9878e-07.\n",
      "Iterataion 1236: Training Loss: 0.015005936345446598, Validation Loss: 0.11809509628304712\n",
      "Iteataion 1236: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.9479e-07.\n",
      "Iterataion 1237: Training Loss: 0.015430670459183145, Validation Loss: 0.12136184772414087\n",
      "Iteataion 1237: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.9085e-07.\n",
      "Iterataion 1238: Training Loss: 0.015451417883515112, Validation Loss: 0.12372833279972305\n",
      "Iteataion 1238: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.8694e-07.\n",
      "Iterataion 1239: Training Loss: 0.01162096817575501, Validation Loss: 0.1298765836215419\n",
      "Iteataion 1239: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.8307e-07.\n",
      "Iterataion 1240: Training Loss: 0.011252588681001105, Validation Loss: 0.12551645333978076\n",
      "Iteataion 1240: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.7924e-07.\n",
      "Iterataion 1241: Training Loss: 0.01615842581764254, Validation Loss: 0.11956775269226921\n",
      "Iteataion 1241: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.7545e-07.\n",
      "Iterataion 1242: Training Loss: 0.01282276872396999, Validation Loss: 0.11896091537186648\n",
      "Iteataion 1242: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.7169e-07.\n",
      "Iterataion 1243: Training Loss: 0.014996239556136267, Validation Loss: 0.11887801379510542\n",
      "Iteataion 1243: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.6797e-07.\n",
      "Iterataion 1244: Training Loss: 0.01492599239726244, Validation Loss: 0.11714407304165567\n",
      "Iteataion 1244: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.6429e-07.\n",
      "Iterataion 1245: Training Loss: 0.016104727039081574, Validation Loss: 0.11657301641407242\n",
      "Iteataion 1245: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.6065e-07.\n",
      "Iterataion 1246: Training Loss: 0.012256443599506677, Validation Loss: 0.11977246470278038\n",
      "Iteataion 1246: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.5704e-07.\n",
      "Iterataion 1247: Training Loss: 0.014439253341288077, Validation Loss: 0.11940076108737963\n",
      "Iteataion 1247: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 3.5347e-07.\n",
      "Iterataion 1248: Training Loss: 0.012862557981861755, Validation Loss: 0.12054053895890986\n",
      "Iteataion 1248: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.4994e-07.\n",
      "Iterataion 1249: Training Loss: 0.011326446820435276, Validation Loss: 0.11720906325797664\n",
      "Iteataion 1249: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.4644e-07.\n",
      "Iterataion 1250: Training Loss: 0.013371540863669203, Validation Loss: 0.11820001300586183\n",
      "Iteataion 1250: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.4298e-07.\n",
      "Iterataion 1251: Training Loss: 0.013618172751112233, Validation Loss: 0.11710288051924692\n",
      "Iteataion 1251: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.3955e-07.\n",
      "Iterataion 1252: Training Loss: 0.012515867331997955, Validation Loss: 0.12038398739915886\n",
      "Iteataion 1252: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.3615e-07.\n",
      "Iterataion 1253: Training Loss: 0.014262439218464078, Validation Loss: 0.11739369482511836\n",
      "Iteataion 1253: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 3.3279e-07.\n",
      "Iterataion 1254: Training Loss: 0.01380503629205308, Validation Loss: 0.11947134772326978\n",
      "Iteataion 1254: Training Accuracy: 0.99609375, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.2946e-07.\n",
      "Iterataion 1255: Training Loss: 0.014145809659158565, Validation Loss: 0.12118715673639643\n",
      "Iteataion 1255: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.2617e-07.\n",
      "Iterataion 1256: Training Loss: 0.012044013597936967, Validation Loss: 0.12312124798744463\n",
      "Iteataion 1256: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.2291e-07.\n",
      "Iterataion 1257: Training Loss: 0.010999207196145146, Validation Loss: 0.12097421998765728\n",
      "Iteataion 1257: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.1968e-07.\n",
      "Iterataion 1258: Training Loss: 0.014325161327706918, Validation Loss: 0.12347799757915753\n",
      "Iteataion 1258: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.1648e-07.\n",
      "Iterataion 1259: Training Loss: 0.010829113598447293, Validation Loss: 0.11708009940651586\n",
      "Iteataion 1259: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.1331e-07.\n",
      "Iterataion 1260: Training Loss: 0.011855456109847427, Validation Loss: 0.1218537716706079\n",
      "Iteataion 1260: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.1018e-07.\n",
      "Iterataion 1261: Training Loss: 0.014342922691714497, Validation Loss: 0.12106292518054522\n",
      "Iteataion 1261: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.0708e-07.\n",
      "Iterataion 1262: Training Loss: 0.013109618923027337, Validation Loss: 0.11820584033877111\n",
      "Iteataion 1262: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 3.0401e-07.\n",
      "Iterataion 1263: Training Loss: 0.0141411987100212, Validation Loss: 0.12275821745123078\n",
      "Iteataion 1263: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.0097e-07.\n",
      "Iterataion 1264: Training Loss: 0.014817351232942273, Validation Loss: 0.1238960435929163\n",
      "Iteataion 1264: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.9796e-07.\n",
      "Iterataion 1265: Training Loss: 0.0161217078397505, Validation Loss: 0.12071144039509818\n",
      "Iteataion 1265: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.9498e-07.\n",
      "Iterataion 1266: Training Loss: 0.01311439291495986, Validation Loss: 0.1208974920701599\n",
      "Iteataion 1266: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.9203e-07.\n",
      "Iterataion 1267: Training Loss: 0.01399297860289316, Validation Loss: 0.12074877789368989\n",
      "Iteataion 1267: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.8911e-07.\n",
      "Iterataion 1268: Training Loss: 0.013825024146841794, Validation Loss: 0.12125967100841879\n",
      "Iteataion 1268: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.8622e-07.\n",
      "Iterataion 1269: Training Loss: 0.012986118039625145, Validation Loss: 0.11860472260741517\n",
      "Iteataion 1269: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.8336e-07.\n",
      "Iterataion 1270: Training Loss: 0.012792329467738237, Validation Loss: 0.11887410852529971\n",
      "Iteataion 1270: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.8052e-07.\n",
      "Iterataion 1271: Training Loss: 0.013373008293439886, Validation Loss: 0.11802486142586553\n",
      "Iteataion 1271: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.7772e-07.\n",
      "Iterataion 1272: Training Loss: 0.01531975199140798, Validation Loss: 0.1246530886415801\n",
      "Iteataion 1272: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.7494e-07.\n",
      "Iterataion 1273: Training Loss: 0.011591362213774468, Validation Loss: 0.12329806498444934\n",
      "Iteataion 1273: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.7219e-07.\n",
      "Iterataion 1274: Training Loss: 0.015130586718616192, Validation Loss: 0.11989669893050521\n",
      "Iteataion 1274: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.6947e-07.\n",
      "Iterataion 1275: Training Loss: 0.011013359910338659, Validation Loss: 0.12221171942301004\n",
      "Iteataion 1275: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.6677e-07.\n",
      "Iterataion 1276: Training Loss: 0.013393350394650413, Validation Loss: 0.11851475269266791\n",
      "Iteataion 1276: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.6411e-07.\n",
      "Iterataion 1277: Training Loss: 0.016430791003509665, Validation Loss: 0.12042496488685152\n",
      "Iteataion 1277: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.6147e-07.\n",
      "Iterataion 1278: Training Loss: 0.015459155746976828, Validation Loss: 0.12027988589380118\n",
      "Iteataion 1278: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.5885e-07.\n",
      "Iterataion 1279: Training Loss: 0.013804550524201513, Validation Loss: 0.11936346363210937\n",
      "Iteataion 1279: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 2.5626e-07.\n",
      "Iterataion 1280: Training Loss: 0.015474035201418565, Validation Loss: 0.1184370522103386\n",
      "Iteataion 1280: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.5370e-07.\n",
      "Iterataion 1281: Training Loss: 0.014610204178892902, Validation Loss: 0.12238537411421264\n",
      "Iteataion 1281: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.5116e-07.\n",
      "Iterataion 1282: Training Loss: 0.013717412853628833, Validation Loss: 0.125381175899969\n",
      "Iteataion 1282: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9765625\n",
      "Adjusting learning rate of group 0 to 2.4865e-07.\n",
      "Iterataion 1283: Training Loss: 0.012437867653182524, Validation Loss: 0.11851013708354269\n",
      "Iteataion 1283: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.4616e-07.\n",
      "Iterataion 1284: Training Loss: 0.013537423359648419, Validation Loss: 0.1236561541985039\n",
      "Iteataion 1284: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.4370e-07.\n",
      "Iterataion 1285: Training Loss: 0.012588487204699638, Validation Loss: 0.11900728864441966\n",
      "Iteataion 1285: Training Accuracy: 0.99609375, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.4127e-07.\n",
      "Iterataion 1286: Training Loss: 0.012032315006736153, Validation Loss: 0.12402227410348132\n",
      "Iteataion 1286: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.3885e-07.\n",
      "Iterataion 1287: Training Loss: 0.01204905402951199, Validation Loss: 0.11986617272415925\n",
      "Iteataion 1287: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.3646e-07.\n",
      "Iterataion 1288: Training Loss: 0.01959766574259039, Validation Loss: 0.11788491025515946\n",
      "Iteataion 1288: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.3410e-07.\n",
      "Iterataion 1289: Training Loss: 0.01520636495311527, Validation Loss: 0.12167935998451601\n",
      "Iteataion 1289: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.3176e-07.\n",
      "Iterataion 1290: Training Loss: 0.013489345973566687, Validation Loss: 0.11927895825469821\n",
      "Iteataion 1290: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.2944e-07.\n",
      "Iterataion 1291: Training Loss: 0.01278229607711825, Validation Loss: 0.1212120019978412\n",
      "Iteataion 1291: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.2715e-07.\n",
      "Iterataion 1292: Training Loss: 0.012383450815679984, Validation Loss: 0.12150357793249962\n",
      "Iteataion 1292: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.2488e-07.\n",
      "Iterataion 1293: Training Loss: 0.011784054617422582, Validation Loss: 0.11938405136589142\n",
      "Iteataion 1293: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 2.2263e-07.\n",
      "Iterataion 1294: Training Loss: 0.0135292977392311, Validation Loss: 0.11612630083378996\n",
      "Iteataion 1294: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.2040e-07.\n",
      "Iterataion 1295: Training Loss: 0.013649455092158615, Validation Loss: 0.11873632378126608\n",
      "Iteataion 1295: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.1820e-07.\n",
      "Iterataion 1296: Training Loss: 0.013878690468183645, Validation Loss: 0.11584529135285354\n",
      "Iteataion 1296: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.1601e-07.\n",
      "Iterataion 1297: Training Loss: 0.012512578139246113, Validation Loss: 0.1158976929302032\n",
      "Iteataion 1297: Training Accuracy: 0.9967447916666666, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.1385e-07.\n",
      "Iterataion 1298: Training Loss: 0.012200321281024863, Validation Loss: 0.12506855786607668\n",
      "Iteataion 1298: Training Accuracy: 0.99609375, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.1172e-07.\n",
      "Iterataion 1299: Training Loss: 0.011419530846053055, Validation Loss: 0.11767512563581965\n",
      "Iteataion 1299: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.0960e-07.\n",
      "Iterataion 1300: Training Loss: 0.012264515545838206, Validation Loss: 0.12033069799455427\n",
      "Iteataion 1300: Training Accuracy: 0.9967447916666666, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.0750e-07.\n",
      "Iterataion 1301: Training Loss: 0.015788576563940143, Validation Loss: 0.12668293668383096\n",
      "Iteataion 1301: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 2.0543e-07.\n",
      "Iterataion 1302: Training Loss: 0.01444186530358989, Validation Loss: 0.12106781457437248\n",
      "Iteataion 1302: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.0337e-07.\n",
      "Iterataion 1303: Training Loss: 0.01204425699780221, Validation Loss: 0.11858284332017165\n",
      "Iteataion 1303: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.0134e-07.\n",
      "Iterataion 1304: Training Loss: 0.011918462268467211, Validation Loss: 0.11960844153243048\n",
      "Iteataion 1304: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.9933e-07.\n",
      "Iterataion 1305: Training Loss: 0.013784909812931507, Validation Loss: 0.1169645100230033\n",
      "Iteataion 1305: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.9733e-07.\n",
      "Iterataion 1306: Training Loss: 0.012993031962841616, Validation Loss: 0.11707545113153528\n",
      "Iteataion 1306: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.9536e-07.\n",
      "Iterataion 1307: Training Loss: 0.012978622372140885, Validation Loss: 0.11950361318517158\n",
      "Iteataion 1307: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.9341e-07.\n",
      "Iterataion 1308: Training Loss: 0.009582440074307365, Validation Loss: 0.12028952734544873\n",
      "Iteataion 1308: Training Accuracy: 0.9973958333333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.9147e-07.\n",
      "Iterataion 1309: Training Loss: 0.013996833902616388, Validation Loss: 0.12329905247173795\n",
      "Iteataion 1309: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.8956e-07.\n",
      "Iterataion 1310: Training Loss: 0.013599346740754087, Validation Loss: 0.11509770660365863\n",
      "Iteataion 1310: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.8766e-07.\n",
      "Iterataion 1311: Training Loss: 0.016880016724968017, Validation Loss: 0.12148924613876905\n",
      "Iteataion 1311: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.8578e-07.\n",
      "Iterataion 1312: Training Loss: 0.01479184591841555, Validation Loss: 0.12305919390751004\n",
      "Iteataion 1312: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.8393e-07.\n",
      "Iterataion 1313: Training Loss: 0.010782499557143513, Validation Loss: 0.12379425386443915\n",
      "Iteataion 1313: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.8209e-07.\n",
      "Iterataion 1314: Training Loss: 0.012084806101636482, Validation Loss: 0.11554710884726174\n",
      "Iteataion 1314: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.8027e-07.\n",
      "Iterataion 1315: Training Loss: 0.014891974994645058, Validation Loss: 0.11976349080569201\n",
      "Iteataion 1315: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.7846e-07.\n",
      "Iterataion 1316: Training Loss: 0.01125696278386331, Validation Loss: 0.12146380128304861\n",
      "Iteataion 1316: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.7668e-07.\n",
      "Iterataion 1317: Training Loss: 0.015319340984151605, Validation Loss: 0.12370641492292989\n",
      "Iteataion 1317: Training Accuracy: 0.994140625, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.7491e-07.\n",
      "Iterataion 1318: Training Loss: 0.010895174484655351, Validation Loss: 0.1175110306230192\n",
      "Iteataion 1318: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.7316e-07.\n",
      "Iterataion 1319: Training Loss: 0.01500685617775924, Validation Loss: 0.11784291459054391\n",
      "Iteataion 1319: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.7143e-07.\n",
      "Iterataion 1320: Training Loss: 0.01187864852118345, Validation Loss: 0.12084019187164902\n",
      "Iteataion 1320: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.6972e-07.\n",
      "Iterataion 1321: Training Loss: 0.015984079494171716, Validation Loss: 0.11805108365199597\n",
      "Iteataion 1321: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6802e-07.\n",
      "Iterataion 1322: Training Loss: 0.011711419800339646, Validation Loss: 0.12321534121363628\n",
      "Iteataion 1322: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.6634e-07.\n",
      "Iterataion 1323: Training Loss: 0.014045218798550805, Validation Loss: 0.11839262722131069\n",
      "Iteataion 1323: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6468e-07.\n",
      "Iterataion 1324: Training Loss: 0.013111645855988282, Validation Loss: 0.12480054315031938\n",
      "Iteataion 1324: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6303e-07.\n",
      "Iterataion 1325: Training Loss: 0.015190052784195806, Validation Loss: 0.12312385799056601\n",
      "Iteataion 1325: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.6140e-07.\n",
      "Iterataion 1326: Training Loss: 0.011279105649902737, Validation Loss: 0.12198140233522281\n",
      "Iteataion 1326: Training Accuracy: 0.9967447916666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.5979e-07.\n",
      "Iterataion 1327: Training Loss: 0.012974359530085576, Validation Loss: 0.12142466580517954\n",
      "Iteataion 1327: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.5819e-07.\n",
      "Iterataion 1328: Training Loss: 0.013487410143960245, Validation Loss: 0.117129125588335\n",
      "Iteataion 1328: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.5661e-07.\n",
      "Iterataion 1329: Training Loss: 0.012722923827997525, Validation Loss: 0.12016648242658959\n",
      "Iteataion 1329: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.5504e-07.\n",
      "Iterataion 1330: Training Loss: 0.010718282664189126, Validation Loss: 0.12457908694802715\n",
      "Iteataion 1330: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.5349e-07.\n",
      "Iterataion 1331: Training Loss: 0.013152879488363047, Validation Loss: 0.11833754457567432\n",
      "Iteataion 1331: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.5195e-07.\n",
      "Iterataion 1332: Training Loss: 0.01402425890667141, Validation Loss: 0.12170981584264465\n",
      "Iteataion 1332: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.5044e-07.\n",
      "Iterataion 1333: Training Loss: 0.012107730930089716, Validation Loss: 0.12216129051464633\n",
      "Iteataion 1333: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.4893e-07.\n",
      "Iterataion 1334: Training Loss: 0.012993411783165225, Validation Loss: 0.12157264472235267\n",
      "Iteataion 1334: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.4744e-07.\n",
      "Iterataion 1335: Training Loss: 0.015138975536997269, Validation Loss: 0.11683216422197136\n",
      "Iteataion 1335: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4597e-07.\n",
      "Iterataion 1336: Training Loss: 0.009967996581829805, Validation Loss: 0.12080433204338499\n",
      "Iteataion 1336: Training Accuracy: 0.9973958333333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4451e-07.\n",
      "Iterataion 1337: Training Loss: 0.014104097788110599, Validation Loss: 0.12380116568060547\n",
      "Iteataion 1337: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4306e-07.\n",
      "Iterataion 1338: Training Loss: 0.012917486384363209, Validation Loss: 0.11809322742529486\n",
      "Iteataion 1338: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4163e-07.\n",
      "Iterataion 1339: Training Loss: 0.01323367696893987, Validation Loss: 0.11976338411033971\n",
      "Iteataion 1339: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4022e-07.\n",
      "Iterataion 1340: Training Loss: 0.014501249877572852, Validation Loss: 0.12280850215508353\n",
      "Iteataion 1340: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.3881e-07.\n",
      "Iterataion 1341: Training Loss: 0.014753260786023303, Validation Loss: 0.12194599555918902\n",
      "Iteataion 1341: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.3743e-07.\n",
      "Iterataion 1342: Training Loss: 0.011451588295996858, Validation Loss: 0.11806754257158013\n",
      "Iteataion 1342: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.3605e-07.\n",
      "Iterataion 1343: Training Loss: 0.01572031917679263, Validation Loss: 0.11952731117645915\n",
      "Iteataion 1343: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.3469e-07.\n",
      "Iterataion 1344: Training Loss: 0.015343632805230888, Validation Loss: 0.1229708181472677\n",
      "Iteataion 1344: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.3334e-07.\n",
      "Iterataion 1345: Training Loss: 0.013969227920138572, Validation Loss: 0.12450672331743123\n",
      "Iteataion 1345: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.3201e-07.\n",
      "Iterataion 1346: Training Loss: 0.012558925218258365, Validation Loss: 0.122258561651972\n",
      "Iteataion 1346: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.3069e-07.\n",
      "Iterataion 1347: Training Loss: 0.013804050260028261, Validation Loss: 0.11946576830033757\n",
      "Iteataion 1347: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.2938e-07.\n",
      "Iterataion 1348: Training Loss: 0.01614881826886729, Validation Loss: 0.11961305748512287\n",
      "Iteataion 1348: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.2809e-07.\n",
      "Iterataion 1349: Training Loss: 0.015783421212317936, Validation Loss: 0.11988625114658712\n",
      "Iteataion 1349: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2681e-07.\n",
      "Iterataion 1350: Training Loss: 0.012548445182131648, Validation Loss: 0.11990952218042278\n",
      "Iteataion 1350: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2554e-07.\n",
      "Iterataion 1351: Training Loss: 0.01352179564729411, Validation Loss: 0.11951226455148128\n",
      "Iteataion 1351: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2428e-07.\n",
      "Iterataion 1352: Training Loss: 0.01504371361423585, Validation Loss: 0.12118248861544288\n",
      "Iteataion 1352: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.2304e-07.\n",
      "Iterataion 1353: Training Loss: 0.012663234269746975, Validation Loss: 0.12168055940447829\n",
      "Iteataion 1353: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.2181e-07.\n",
      "Iterataion 1354: Training Loss: 0.015510705590016672, Validation Loss: 0.11406928690990842\n",
      "Iteataion 1354: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2059e-07.\n",
      "Iterataion 1355: Training Loss: 0.012464407896260524, Validation Loss: 0.12448797067456947\n",
      "Iteataion 1355: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.1939e-07.\n",
      "Iterataion 1356: Training Loss: 0.015230912624573904, Validation Loss: 0.11950182369782408\n",
      "Iteataion 1356: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.1819e-07.\n",
      "Iterataion 1357: Training Loss: 0.013653858351830705, Validation Loss: 0.1220213209545785\n",
      "Iteataion 1357: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.1701e-07.\n",
      "Iterataion 1358: Training Loss: 0.013612024056652705, Validation Loss: 0.12320723831185094\n",
      "Iteataion 1358: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1584e-07.\n",
      "Iterataion 1359: Training Loss: 0.011619751039100531, Validation Loss: 0.11914817989440407\n",
      "Iteataion 1359: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1468e-07.\n",
      "Iterataion 1360: Training Loss: 0.01151458150219217, Validation Loss: 0.12189386852608039\n",
      "Iteataion 1360: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.1354e-07.\n",
      "Iterataion 1361: Training Loss: 0.01587742690134983, Validation Loss: 0.1189769260264456\n",
      "Iteataion 1361: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1240e-07.\n",
      "Iterataion 1362: Training Loss: 0.012507334818246545, Validation Loss: 0.11984567094605597\n",
      "Iteataion 1362: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1128e-07.\n",
      "Iterataion 1363: Training Loss: 0.014086720671345797, Validation Loss: 0.11618174628564724\n",
      "Iteataion 1363: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1016e-07.\n",
      "Iterataion 1364: Training Loss: 0.012130127576302491, Validation Loss: 0.12627802292884485\n",
      "Iteataion 1364: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0906e-07.\n",
      "Iterataion 1365: Training Loss: 0.012803336554890063, Validation Loss: 0.11572017622884453\n",
      "Iteataion 1365: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0797e-07.\n",
      "Iterataion 1366: Training Loss: 0.0155222382374501, Validation Loss: 0.12266298573714023\n",
      "Iteataion 1366: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0689e-07.\n",
      "Iterataion 1367: Training Loss: 0.013577393017197585, Validation Loss: 0.1219649904765325\n",
      "Iteataion 1367: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0582e-07.\n",
      "Iterataion 1368: Training Loss: 0.013667313681433011, Validation Loss: 0.12367164890392593\n",
      "Iteataion 1368: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0477e-07.\n",
      "Iterataion 1369: Training Loss: 0.013630290555978239, Validation Loss: 0.1180066892028241\n",
      "Iteataion 1369: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.0372e-07.\n",
      "Iterataion 1370: Training Loss: 0.01785768187429873, Validation Loss: 0.11827857413317827\n",
      "Iteataion 1370: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0268e-07.\n",
      "Iterataion 1371: Training Loss: 0.01334903104747311, Validation Loss: 0.12337031601303507\n",
      "Iteataion 1371: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.0165e-07.\n",
      "Iterataion 1372: Training Loss: 0.014458906800035823, Validation Loss: 0.11880006010377235\n",
      "Iteataion 1372: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0064e-07.\n",
      "Iterataion 1373: Training Loss: 0.01534960989200393, Validation Loss: 0.12230245630958163\n",
      "Iteataion 1373: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.9631e-08.\n",
      "Iterataion 1374: Training Loss: 0.013048418947951421, Validation Loss: 0.11652661069713692\n",
      "Iteataion 1374: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 9.8634e-08.\n",
      "Iterataion 1375: Training Loss: 0.012624376911452476, Validation Loss: 0.12077022248470201\n",
      "Iteataion 1375: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.7648e-08.\n",
      "Iterataion 1376: Training Loss: 0.012689853379151555, Validation Loss: 0.11944133463236163\n",
      "Iteataion 1376: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 9.6671e-08.\n",
      "Iterataion 1377: Training Loss: 0.01629577832077602, Validation Loss: 0.12422051955377911\n",
      "Iteataion 1377: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.5705e-08.\n",
      "Iterataion 1378: Training Loss: 0.01589440768563696, Validation Loss: 0.12125936650994756\n",
      "Iteataion 1378: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 9.4748e-08.\n",
      "Iterataion 1379: Training Loss: 0.013368797030168848, Validation Loss: 0.12287898830751456\n",
      "Iteataion 1379: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.3800e-08.\n",
      "Iterataion 1380: Training Loss: 0.010537702397305329, Validation Loss: 0.12082396174508442\n",
      "Iteataion 1380: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 9.2862e-08.\n",
      "Iterataion 1381: Training Loss: 0.013756876625608608, Validation Loss: 0.12160683385374751\n",
      "Iteataion 1381: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.1934e-08.\n",
      "Iterataion 1382: Training Loss: 0.012551846331045377, Validation Loss: 0.11874614812138422\n",
      "Iteataion 1382: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.1014e-08.\n",
      "Iterataion 1383: Training Loss: 0.017065595438275877, Validation Loss: 0.11879963276158201\n",
      "Iteataion 1383: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 9.0104e-08.\n",
      "Iterataion 1384: Training Loss: 0.011528833886025708, Validation Loss: 0.11680496158575207\n",
      "Iteataion 1384: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.9203e-08.\n",
      "Iterataion 1385: Training Loss: 0.014998632010377799, Validation Loss: 0.12596844345836605\n",
      "Iteataion 1385: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.8311e-08.\n",
      "Iterataion 1386: Training Loss: 0.01186611089844279, Validation Loss: 0.11622947449625538\n",
      "Iteataion 1386: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.7428e-08.\n",
      "Iterataion 1387: Training Loss: 0.012584136401283594, Validation Loss: 0.11692107577521423\n",
      "Iteataion 1387: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.6554e-08.\n",
      "Iterataion 1388: Training Loss: 0.01068734485463624, Validation Loss: 0.11956532795703402\n",
      "Iteataion 1388: Training Accuracy: 0.9970238095238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.5688e-08.\n",
      "Iterataion 1389: Training Loss: 0.0152395101416435, Validation Loss: 0.11685905588518192\n",
      "Iteataion 1389: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.4831e-08.\n",
      "Iterataion 1390: Training Loss: 0.012597876713502439, Validation Loss: 0.11975813151206594\n",
      "Iteataion 1390: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.3983e-08.\n",
      "Iterataion 1391: Training Loss: 0.015269210740392693, Validation Loss: 0.11959863975558929\n",
      "Iteataion 1391: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.3143e-08.\n",
      "Iterataion 1392: Training Loss: 0.013332151654831686, Validation Loss: 0.11697475307283173\n",
      "Iteataion 1392: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.2312e-08.\n",
      "Iterataion 1393: Training Loss: 0.01208039150157843, Validation Loss: 0.12195350902890446\n",
      "Iteataion 1393: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.1489e-08.\n",
      "Iterataion 1394: Training Loss: 0.014740784169790966, Validation Loss: 0.12290341809119393\n",
      "Iteataion 1394: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.0674e-08.\n",
      "Iterataion 1395: Training Loss: 0.012918811302261237, Validation Loss: 0.12237644378697818\n",
      "Iteataion 1395: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.9867e-08.\n",
      "Iterataion 1396: Training Loss: 0.012371345532257778, Validation Loss: 0.11839811955848369\n",
      "Iteataion 1396: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.9068e-08.\n",
      "Iterataion 1397: Training Loss: 0.013566533057751066, Validation Loss: 0.12043249329109108\n",
      "Iteataion 1397: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 7.8278e-08.\n",
      "Iterataion 1398: Training Loss: 0.015053749369934179, Validation Loss: 0.12190161025003962\n",
      "Iteataion 1398: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.7495e-08.\n",
      "Iterataion 1399: Training Loss: 0.01043130916701546, Validation Loss: 0.11665317401568201\n",
      "Iteataion 1399: Training Accuracy: 0.9968377976190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.6720e-08.\n",
      "Iterataion 1400: Training Loss: 0.014816552909121787, Validation Loss: 0.12220788793780318\n",
      "Iteataion 1400: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.5953e-08.\n",
      "Iterataion 1401: Training Loss: 0.01247903258430989, Validation Loss: 0.11955013286702834\n",
      "Iteataion 1401: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.5193e-08.\n",
      "Iterataion 1402: Training Loss: 0.01546831760858046, Validation Loss: 0.11936388926853131\n",
      "Iteataion 1402: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.4441e-08.\n",
      "Iterataion 1403: Training Loss: 0.014574607411778705, Validation Loss: 0.11960379012133472\n",
      "Iteataion 1403: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.3697e-08.\n",
      "Iterataion 1404: Training Loss: 0.014221137025132832, Validation Loss: 0.11977852572951034\n",
      "Iteataion 1404: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.2960e-08.\n",
      "Iterataion 1405: Training Loss: 0.017999501882851526, Validation Loss: 0.12431162761001871\n",
      "Iteataion 1405: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.2230e-08.\n",
      "Iterataion 1406: Training Loss: 0.013525731138526714, Validation Loss: 0.12006440144117422\n",
      "Iteataion 1406: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 7.1508e-08.\n",
      "Iterataion 1407: Training Loss: 0.012913411088959832, Validation Loss: 0.11921846127512342\n",
      "Iteataion 1407: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.0793e-08.\n",
      "Iterataion 1408: Training Loss: 0.011832843437054735, Validation Loss: 0.11584204814479142\n",
      "Iteataion 1408: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.0085e-08.\n",
      "Iterataion 1409: Training Loss: 0.011399070826055159, Validation Loss: 0.11732128073273954\n",
      "Iteataion 1409: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.9384e-08.\n",
      "Iterataion 1410: Training Loss: 0.014314172374681307, Validation Loss: 0.12098664762281881\n",
      "Iteataion 1410: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.8690e-08.\n",
      "Iterataion 1411: Training Loss: 0.015451776539602925, Validation Loss: 0.1233711655510067\n",
      "Iteataion 1411: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.8003e-08.\n",
      "Iterataion 1412: Training Loss: 0.01504225449874986, Validation Loss: 0.11600166757267377\n",
      "Iteataion 1412: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.7323e-08.\n",
      "Iterataion 1413: Training Loss: 0.014002701208346752, Validation Loss: 0.11846393531347375\n",
      "Iteataion 1413: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.6650e-08.\n",
      "Iterataion 1414: Training Loss: 0.011533407062050903, Validation Loss: 0.11939637859851666\n",
      "Iteataion 1414: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 6.5984e-08.\n",
      "Iterataion 1415: Training Loss: 0.016540164032966334, Validation Loss: 0.12230558897703658\n",
      "Iteataion 1415: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.5324e-08.\n",
      "Iterataion 1416: Training Loss: 0.011517932686277158, Validation Loss: 0.12462562729076414\n",
      "Iteataion 1416: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.4670e-08.\n",
      "Iterataion 1417: Training Loss: 0.01714779898886078, Validation Loss: 0.12895913168265508\n",
      "Iteataion 1417: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.4024e-08.\n",
      "Iterataion 1418: Training Loss: 0.013390988686775879, Validation Loss: 0.11960973645980674\n",
      "Iteataion 1418: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.3384e-08.\n",
      "Iterataion 1419: Training Loss: 0.013474131157603616, Validation Loss: 0.13039801653372352\n",
      "Iteataion 1419: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.2750e-08.\n",
      "Iterataion 1420: Training Loss: 0.01389982043849137, Validation Loss: 0.11875066587917234\n",
      "Iteataion 1420: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.2122e-08.\n",
      "Iterataion 1421: Training Loss: 0.015030985823407223, Validation Loss: 0.11913220474081931\n",
      "Iteataion 1421: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 6.1501e-08.\n",
      "Iterataion 1422: Training Loss: 0.01495966581159974, Validation Loss: 0.11652969660964317\n",
      "Iteataion 1422: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 6.0886e-08.\n",
      "Iterataion 1423: Training Loss: 0.016074018101528576, Validation Loss: 0.12382438607377613\n",
      "Iteataion 1423: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.0277e-08.\n",
      "Iterataion 1424: Training Loss: 0.012312370438712878, Validation Loss: 0.12024504992764488\n",
      "Iteataion 1424: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.9674e-08.\n",
      "Iterataion 1425: Training Loss: 0.013689193623642364, Validation Loss: 0.12534831845053904\n",
      "Iteataion 1425: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.9078e-08.\n",
      "Iterataion 1426: Training Loss: 0.016339930237450742, Validation Loss: 0.12042071599166886\n",
      "Iteataion 1426: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.8487e-08.\n",
      "Iterataion 1427: Training Loss: 0.01808924598599823, Validation Loss: 0.12313780966697534\n",
      "Iteataion 1427: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.7902e-08.\n",
      "Iterataion 1428: Training Loss: 0.014571711099302274, Validation Loss: 0.12151715304651411\n",
      "Iteataion 1428: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.7323e-08.\n",
      "Iterataion 1429: Training Loss: 0.01195005521866281, Validation Loss: 0.12031286059475572\n",
      "Iteataion 1429: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.6750e-08.\n",
      "Iterataion 1430: Training Loss: 0.012963287772305454, Validation Loss: 0.12334646862894637\n",
      "Iteataion 1430: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.6182e-08.\n",
      "Iterataion 1431: Training Loss: 0.013495952099726207, Validation Loss: 0.12217258271355205\n",
      "Iteataion 1431: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.5620e-08.\n",
      "Iterataion 1432: Training Loss: 0.016508625665871975, Validation Loss: 0.11984424598986373\n",
      "Iteataion 1432: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.5064e-08.\n",
      "Iterataion 1433: Training Loss: 0.012187117492692256, Validation Loss: 0.11886533399796817\n",
      "Iteataion 1433: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.4514e-08.\n",
      "Iterataion 1434: Training Loss: 0.013504477790110705, Validation Loss: 0.11849135444102037\n",
      "Iteataion 1434: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.3968e-08.\n",
      "Iterataion 1435: Training Loss: 0.017897791038009387, Validation Loss: 0.11759586475800904\n",
      "Iteataion 1435: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.3429e-08.\n",
      "Iterataion 1436: Training Loss: 0.014700739766982758, Validation Loss: 0.1276406359009831\n",
      "Iteataion 1436: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.2894e-08.\n",
      "Iterataion 1437: Training Loss: 0.013287297756554737, Validation Loss: 0.12081094367270608\n",
      "Iteataion 1437: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.2365e-08.\n",
      "Iterataion 1438: Training Loss: 0.013824143624219007, Validation Loss: 0.12155652237721015\n",
      "Iteataion 1438: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.1842e-08.\n",
      "Iterataion 1439: Training Loss: 0.013187317228192899, Validation Loss: 0.12254142505116761\n",
      "Iteataion 1439: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.1323e-08.\n",
      "Iterataion 1440: Training Loss: 0.012177700149125425, Validation Loss: 0.11929603598205508\n",
      "Iteataion 1440: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.0810e-08.\n",
      "Iterataion 1441: Training Loss: 0.01444086860596972, Validation Loss: 0.12299340583452183\n",
      "Iteataion 1441: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.0302e-08.\n",
      "Iterataion 1442: Training Loss: 0.014267271500663597, Validation Loss: 0.12976947443832348\n",
      "Iteataion 1442: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.9799e-08.\n",
      "Iterataion 1443: Training Loss: 0.011759679132241555, Validation Loss: 0.11864957432319387\n",
      "Iteataion 1443: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.9301e-08.\n",
      "Iterataion 1444: Training Loss: 0.012227719654029369, Validation Loss: 0.11931907193502411\n",
      "Iteataion 1444: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.8808e-08.\n",
      "Iterataion 1445: Training Loss: 0.013622962114746923, Validation Loss: 0.12418842160358752\n",
      "Iteataion 1445: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.8320e-08.\n",
      "Iterataion 1446: Training Loss: 0.012791114824602358, Validation Loss: 0.11944342264905572\n",
      "Iteataion 1446: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.7837e-08.\n",
      "Iterataion 1447: Training Loss: 0.011930135465617442, Validation Loss: 0.11725965930112046\n",
      "Iteataion 1447: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.7358e-08.\n",
      "Iterataion 1448: Training Loss: 0.015616254645056777, Validation Loss: 0.12031957574427218\n",
      "Iteataion 1448: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.6885e-08.\n",
      "Iterataion 1449: Training Loss: 0.013876251957914653, Validation Loss: 0.12144739379703136\n",
      "Iteataion 1449: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.6416e-08.\n",
      "Iterataion 1450: Training Loss: 0.013749173565796984, Validation Loss: 0.12604698836491102\n",
      "Iteataion 1450: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.5952e-08.\n",
      "Iterataion 1451: Training Loss: 0.013735319525219534, Validation Loss: 0.1250867628728085\n",
      "Iteataion 1451: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.5492e-08.\n",
      "Iterataion 1452: Training Loss: 0.01826921493075732, Validation Loss: 0.12042991663173136\n",
      "Iteataion 1452: Training Accuracy: 0.994140625, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.5037e-08.\n",
      "Iterataion 1453: Training Loss: 0.013245047109472025, Validation Loss: 0.11856529937500543\n",
      "Iteataion 1453: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.4587e-08.\n",
      "Iterataion 1454: Training Loss: 0.013852046454788191, Validation Loss: 0.11809488617042761\n",
      "Iteataion 1454: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.4141e-08.\n",
      "Iterataion 1455: Training Loss: 0.01200951248129222, Validation Loss: 0.11986951983147641\n",
      "Iteataion 1455: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.3700e-08.\n",
      "Iterataion 1456: Training Loss: 0.013023541494890278, Validation Loss: 0.12061831336354882\n",
      "Iteataion 1456: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.3263e-08.\n",
      "Iterataion 1457: Training Loss: 0.012305478615237366, Validation Loss: 0.12242933018729318\n",
      "Iteataion 1457: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.2830e-08.\n",
      "Iterataion 1458: Training Loss: 0.01712432386047586, Validation Loss: 0.12028109537801002\n",
      "Iteataion 1458: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.2402e-08.\n",
      "Iterataion 1459: Training Loss: 0.012155296058605932, Validation Loss: 0.12309665009436174\n",
      "Iteataion 1459: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.1978e-08.\n",
      "Iterataion 1460: Training Loss: 0.010875204773926493, Validation Loss: 0.11951411643602158\n",
      "Iteataion 1460: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.1558e-08.\n",
      "Iterataion 1461: Training Loss: 0.014744444524912543, Validation Loss: 0.12174831912852824\n",
      "Iteataion 1461: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.1142e-08.\n",
      "Iterataion 1462: Training Loss: 0.013638241472200932, Validation Loss: 0.12061122886796777\n",
      "Iteataion 1462: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.0731e-08.\n",
      "Iterataion 1463: Training Loss: 0.014904898781298722, Validation Loss: 0.11821063212402982\n",
      "Iteataion 1463: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.0324e-08.\n",
      "Iterataion 1464: Training Loss: 0.013725040587150452, Validation Loss: 0.12327331167407243\n",
      "Iteataion 1464: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.9920e-08.\n",
      "Iterataion 1465: Training Loss: 0.011296855491756122, Validation Loss: 0.12517067835035892\n",
      "Iteataion 1465: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.9521e-08.\n",
      "Iterataion 1466: Training Loss: 0.012569212001116813, Validation Loss: 0.11876339760393177\n",
      "Iteataion 1466: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.9126e-08.\n",
      "Iterataion 1467: Training Loss: 0.01240101177105959, Validation Loss: 0.12423179105560227\n",
      "Iteataion 1467: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.8735e-08.\n",
      "Iterataion 1468: Training Loss: 0.01314413463794431, Validation Loss: 0.12157177506156674\n",
      "Iteataion 1468: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.8347e-08.\n",
      "Iterataion 1469: Training Loss: 0.01238879886620349, Validation Loss: 0.12192556125867157\n",
      "Iteataion 1469: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 3.7964e-08.\n",
      "Iterataion 1470: Training Loss: 0.01332695782271738, Validation Loss: 0.11690627849127007\n",
      "Iteataion 1470: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.7584e-08.\n",
      "Iterataion 1471: Training Loss: 0.012234236093336985, Validation Loss: 0.1200198931505949\n",
      "Iteataion 1471: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.7208e-08.\n",
      "Iterataion 1472: Training Loss: 0.017121407978897524, Validation Loss: 0.12406908344511487\n",
      "Iteataion 1472: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.6836e-08.\n",
      "Iterataion 1473: Training Loss: 0.010432473926534486, Validation Loss: 0.1205055802157603\n",
      "Iteataion 1473: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.6468e-08.\n",
      "Iterataion 1474: Training Loss: 0.015577372588763783, Validation Loss: 0.12574446148795598\n",
      "Iteataion 1474: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.6103e-08.\n",
      "Iterataion 1475: Training Loss: 0.013507558947985344, Validation Loss: 0.12285814507688372\n",
      "Iteataion 1475: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.5742e-08.\n",
      "Iterataion 1476: Training Loss: 0.01381698756915807, Validation Loss: 0.11929133495247764\n",
      "Iteataion 1476: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.5385e-08.\n",
      "Iterataion 1477: Training Loss: 0.013144695466665919, Validation Loss: 0.12282728595040147\n",
      "Iteataion 1477: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.5031e-08.\n",
      "Iterataion 1478: Training Loss: 0.01510497385079688, Validation Loss: 0.12134551103851508\n",
      "Iteataion 1478: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.4681e-08.\n",
      "Iterataion 1479: Training Loss: 0.015388414000570885, Validation Loss: 0.12173933994235107\n",
      "Iteataion 1479: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.4334e-08.\n",
      "Iterataion 1480: Training Loss: 0.013999919208222553, Validation Loss: 0.12407519682537674\n",
      "Iteataion 1480: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 3.3991e-08.\n",
      "Iterataion 1481: Training Loss: 0.013978334053832212, Validation Loss: 0.1194936343235895\n",
      "Iteataion 1481: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.3651e-08.\n",
      "Iterataion 1482: Training Loss: 0.009977278307820586, Validation Loss: 0.1196060637040518\n",
      "Iteataion 1482: Training Accuracy: 0.9967447916666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.3314e-08.\n",
      "Iterataion 1483: Training Loss: 0.011791121121391397, Validation Loss: 0.12748844437684478\n",
      "Iteataion 1483: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.2981e-08.\n",
      "Iterataion 1484: Training Loss: 0.014650096403174159, Validation Loss: 0.1222839535699544\n",
      "Iteataion 1484: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.2651e-08.\n",
      "Iterataion 1485: Training Loss: 0.014317038769117127, Validation Loss: 0.1218190271373293\n",
      "Iteataion 1485: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.2325e-08.\n",
      "Iterataion 1486: Training Loss: 0.013908500055201117, Validation Loss: 0.12094754987842085\n",
      "Iteataion 1486: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.2001e-08.\n",
      "Iterataion 1487: Training Loss: 0.014645489800789722, Validation Loss: 0.1182985378318557\n",
      "Iteataion 1487: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.1681e-08.\n",
      "Iterataion 1488: Training Loss: 0.01565203620720387, Validation Loss: 0.11989538284819345\n",
      "Iteataion 1488: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.1365e-08.\n",
      "Iterataion 1489: Training Loss: 0.013435486602683379, Validation Loss: 0.1193816347988947\n",
      "Iteataion 1489: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.1051e-08.\n",
      "Iterataion 1490: Training Loss: 0.015964491625698452, Validation Loss: 0.11905002287907027\n",
      "Iteataion 1490: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 3.0740e-08.\n",
      "Iterataion 1491: Training Loss: 0.013399552161948934, Validation Loss: 0.11969719763288683\n",
      "Iteataion 1491: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.0433e-08.\n",
      "Iterataion 1492: Training Loss: 0.013438047291878277, Validation Loss: 0.11593075551620753\n",
      "Iteataion 1492: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.0129e-08.\n",
      "Iterataion 1493: Training Loss: 0.011538374274139555, Validation Loss: 0.12027327782792471\n",
      "Iteataion 1493: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.9827e-08.\n",
      "Iterataion 1494: Training Loss: 0.015490225446724171, Validation Loss: 0.11951879617366258\n",
      "Iteataion 1494: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.9529e-08.\n",
      "Iterataion 1495: Training Loss: 0.012554311141766285, Validation Loss: 0.12106696801492944\n",
      "Iteataion 1495: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.9234e-08.\n",
      "Iterataion 1496: Training Loss: 0.012660971115807539, Validation Loss: 0.11949618955046257\n",
      "Iteataion 1496: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.8942e-08.\n",
      "Iterataion 1497: Training Loss: 0.015252389436905567, Validation Loss: 0.12461727461777627\n",
      "Iteataion 1497: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.8652e-08.\n",
      "Iterataion 1498: Training Loss: 0.011490392283965907, Validation Loss: 0.11846343571286104\n",
      "Iteataion 1498: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.8366e-08.\n",
      "Iterataion 1499: Training Loss: 0.018115762077602363, Validation Loss: 0.1204673902744927\n",
      "Iteataion 1499: Training Accuracy: 0.9937686011904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.8082e-08.\n",
      "Iterataion 1500: Training Loss: 0.015577076411628985, Validation Loss: 0.11534269734870688\n",
      "Iteataion 1500: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.7801e-08.\n",
      "Iterataion 1501: Training Loss: 0.015644101661624398, Validation Loss: 0.1180304211753182\n",
      "Iteataion 1501: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.7523e-08.\n",
      "Iterataion 1502: Training Loss: 0.013385354114966858, Validation Loss: 0.12043763342790487\n",
      "Iteataion 1502: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.7248e-08.\n",
      "Iterataion 1503: Training Loss: 0.015165724863736015, Validation Loss: 0.12177057025482788\n",
      "Iteataion 1503: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.6975e-08.\n",
      "Iterataion 1504: Training Loss: 0.013239011996109206, Validation Loss: 0.11802821707196261\n",
      "Iteataion 1504: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.6706e-08.\n",
      "Iterataion 1505: Training Loss: 0.01582267730250051, Validation Loss: 0.11950005295334339\n",
      "Iteataion 1505: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.6439e-08.\n",
      "Iterataion 1506: Training Loss: 0.013310957717441558, Validation Loss: 0.12203556867941033\n",
      "Iteataion 1506: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.6174e-08.\n",
      "Iterataion 1507: Training Loss: 0.013119598394880227, Validation Loss: 0.11905665468799359\n",
      "Iteataion 1507: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 2.5912e-08.\n",
      "Iterataion 1508: Training Loss: 0.012680473215989545, Validation Loss: 0.1271790037124713\n",
      "Iteataion 1508: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.5653e-08.\n",
      "Iterataion 1509: Training Loss: 0.012506723751956708, Validation Loss: 0.12017088644092948\n",
      "Iteataion 1509: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.5397e-08.\n",
      "Iterataion 1510: Training Loss: 0.013422353022200652, Validation Loss: 0.12385778058115847\n",
      "Iteataion 1510: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.5143e-08.\n",
      "Iterataion 1511: Training Loss: 0.013787963189892918, Validation Loss: 0.11507962972547564\n",
      "Iteataion 1511: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.4891e-08.\n",
      "Iterataion 1512: Training Loss: 0.01287036720199042, Validation Loss: 0.12473079025257015\n",
      "Iteataion 1512: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.4642e-08.\n",
      "Iterataion 1513: Training Loss: 0.018041097709956485, Validation Loss: 0.12057771208900504\n",
      "Iteataion 1513: Training Accuracy: 0.9940476190476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.4396e-08.\n",
      "Iterataion 1514: Training Loss: 0.015836527762783992, Validation Loss: 0.1253171942108765\n",
      "Iteataion 1514: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 2.4152e-08.\n",
      "Iterataion 1515: Training Loss: 0.014605263258019618, Validation Loss: 0.11828565659433059\n",
      "Iteataion 1515: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.3911e-08.\n",
      "Iterataion 1516: Training Loss: 0.01423821781174988, Validation Loss: 0.12300640788133733\n",
      "Iteataion 1516: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.3671e-08.\n",
      "Iterataion 1517: Training Loss: 0.013275852602555187, Validation Loss: 0.1198883385166083\n",
      "Iteataion 1517: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.3435e-08.\n",
      "Iterataion 1518: Training Loss: 0.015933555673388205, Validation Loss: 0.12678578174843386\n",
      "Iteataion 1518: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.3200e-08.\n",
      "Iterataion 1519: Training Loss: 0.014042742038877613, Validation Loss: 0.11936932047275349\n",
      "Iteataion 1519: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.2968e-08.\n",
      "Iterataion 1520: Training Loss: 0.013602805824763515, Validation Loss: 0.11733049719463806\n",
      "Iteataion 1520: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.2739e-08.\n",
      "Iterataion 1521: Training Loss: 0.015601687571438152, Validation Loss: 0.11877226218774278\n",
      "Iteataion 1521: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.2511e-08.\n",
      "Iterataion 1522: Training Loss: 0.014821542487591282, Validation Loss: 0.11992043865810535\n",
      "Iteataion 1522: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.2286e-08.\n",
      "Iterataion 1523: Training Loss: 0.011206400723609247, Validation Loss: 0.12090441094365016\n",
      "Iteataion 1523: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.2063e-08.\n",
      "Iterataion 1524: Training Loss: 0.012040927551664457, Validation Loss: 0.1189741346667089\n",
      "Iteataion 1524: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.1843e-08.\n",
      "Iterataion 1525: Training Loss: 0.017683442934725745, Validation Loss: 0.11748324697496505\n",
      "Iteataion 1525: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.1624e-08.\n",
      "Iterataion 1526: Training Loss: 0.012979720198078092, Validation Loss: 0.11877389547199284\n",
      "Iteataion 1526: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.1408e-08.\n",
      "Iterataion 1527: Training Loss: 0.01426072183610944, Validation Loss: 0.12703009186704392\n",
      "Iteataion 1527: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.1194e-08.\n",
      "Iterataion 1528: Training Loss: 0.013958074916837301, Validation Loss: 0.1188193292416655\n",
      "Iteataion 1528: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.0982e-08.\n",
      "Iterataion 1529: Training Loss: 0.011379633241571475, Validation Loss: 0.12771553360635596\n",
      "Iteataion 1529: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.0772e-08.\n",
      "Iterataion 1530: Training Loss: 0.016802427757142423, Validation Loss: 0.11686640429855664\n",
      "Iteataion 1530: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.0564e-08.\n",
      "Iterataion 1531: Training Loss: 0.010698947624176528, Validation Loss: 0.12062136898038728\n",
      "Iteataion 1531: Training Accuracy: 0.9968377976190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.0359e-08.\n",
      "Iterataion 1532: Training Loss: 0.014332001758523252, Validation Loss: 0.12796738967526614\n",
      "Iteataion 1532: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.0155e-08.\n",
      "Iterataion 1533: Training Loss: 0.013286910876896634, Validation Loss: 0.11707748306301854\n",
      "Iteataion 1533: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.9954e-08.\n",
      "Iterataion 1534: Training Loss: 0.015139688758254832, Validation Loss: 0.12491666529293559\n",
      "Iteataion 1534: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.9754e-08.\n",
      "Iterataion 1535: Training Loss: 0.014073136247956601, Validation Loss: 0.12284830957225229\n",
      "Iteataion 1535: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.9557e-08.\n",
      "Iterataion 1536: Training Loss: 0.014942882919592036, Validation Loss: 0.12151085331229629\n",
      "Iteataion 1536: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.9361e-08.\n",
      "Iterataion 1537: Training Loss: 0.016115453782453742, Validation Loss: 0.12060259650858891\n",
      "Iteataion 1537: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.9167e-08.\n",
      "Iterataion 1538: Training Loss: 0.014993216569847733, Validation Loss: 0.12586237568970451\n",
      "Iteataion 1538: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.8976e-08.\n",
      "Iterataion 1539: Training Loss: 0.013407824877133693, Validation Loss: 0.12296826701551652\n",
      "Iteataion 1539: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.8786e-08.\n",
      "Iterataion 1540: Training Loss: 0.012978239820414073, Validation Loss: 0.12218364378687267\n",
      "Iteataion 1540: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.8598e-08.\n",
      "Iterataion 1541: Training Loss: 0.01370016919779396, Validation Loss: 0.1212330356115339\n",
      "Iteataion 1541: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.8412e-08.\n",
      "Iterataion 1542: Training Loss: 0.011983762244613071, Validation Loss: 0.12067109413683505\n",
      "Iteataion 1542: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.8228e-08.\n",
      "Iterataion 1543: Training Loss: 0.014229954906473004, Validation Loss: 0.11860944106237872\n",
      "Iteataion 1543: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.8046e-08.\n",
      "Iterataion 1544: Training Loss: 0.012899448027873333, Validation Loss: 0.12182738043782415\n",
      "Iteataion 1544: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.7865e-08.\n",
      "Iterataion 1545: Training Loss: 0.0169797860490978, Validation Loss: 0.12030010186306132\n",
      "Iteataion 1545: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.7687e-08.\n",
      "Iterataion 1546: Training Loss: 0.013934569871980239, Validation Loss: 0.1201350989278758\n",
      "Iteataion 1546: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.7510e-08.\n",
      "Iterataion 1547: Training Loss: 0.016148943788634088, Validation Loss: 0.12141927417435842\n",
      "Iteataion 1547: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.7335e-08.\n",
      "Iterataion 1548: Training Loss: 0.013600941592671289, Validation Loss: 0.12102855964586502\n",
      "Iteataion 1548: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.7161e-08.\n",
      "Iterataion 1549: Training Loss: 0.012865082301202225, Validation Loss: 0.12044768512146775\n",
      "Iteataion 1549: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.6990e-08.\n",
      "Iterataion 1550: Training Loss: 0.014012366004879335, Validation Loss: 0.1244724065394754\n",
      "Iteataion 1550: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6820e-08.\n",
      "Iterataion 1551: Training Loss: 0.011558419109174345, Validation Loss: 0.11940095484506612\n",
      "Iteataion 1551: Training Accuracy: 0.9972098214285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6652e-08.\n",
      "Iterataion 1552: Training Loss: 0.014828602221172615, Validation Loss: 0.11958499945893247\n",
      "Iteataion 1552: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.6485e-08.\n",
      "Iterataion 1553: Training Loss: 0.016582492503691686, Validation Loss: 0.12303955840137105\n",
      "Iteataion 1553: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6320e-08.\n",
      "Iterataion 1554: Training Loss: 0.012253333901056552, Validation Loss: 0.11898856641577057\n",
      "Iteataion 1554: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6157e-08.\n",
      "Iterataion 1555: Training Loss: 0.012912446835488192, Validation Loss: 0.12030308205199927\n",
      "Iteataion 1555: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.5996e-08.\n",
      "Iterataion 1556: Training Loss: 0.015015777690345868, Validation Loss: 0.12135595810690486\n",
      "Iteataion 1556: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.5836e-08.\n",
      "Iterataion 1557: Training Loss: 0.011894815503117702, Validation Loss: 0.1184865917879861\n",
      "Iteataion 1557: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.5677e-08.\n",
      "Iterataion 1558: Training Loss: 0.018737237084194083, Validation Loss: 0.11740537608615918\n",
      "Iteataion 1558: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.5520e-08.\n",
      "Iterataion 1559: Training Loss: 0.013024661129704414, Validation Loss: 0.12945102470381775\n",
      "Iteataion 1559: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.5365e-08.\n",
      "Iterataion 1560: Training Loss: 0.013077424119385573, Validation Loss: 0.11987105084060715\n",
      "Iteataion 1560: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.5212e-08.\n",
      "Iterataion 1561: Training Loss: 0.013493872786667142, Validation Loss: 0.12147240834055105\n",
      "Iteataion 1561: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.5059e-08.\n",
      "Iterataion 1562: Training Loss: 0.015393830085567807, Validation Loss: 0.11993936350478268\n",
      "Iteataion 1562: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4909e-08.\n",
      "Iterataion 1563: Training Loss: 0.014454905712603407, Validation Loss: 0.12052495432904035\n",
      "Iteataion 1563: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4760e-08.\n",
      "Iterataion 1564: Training Loss: 0.013979808376505302, Validation Loss: 0.12368595343162646\n",
      "Iteataion 1564: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4612e-08.\n",
      "Iterataion 1565: Training Loss: 0.018524594584230367, Validation Loss: 0.11830568781247498\n",
      "Iteataion 1565: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.4466e-08.\n",
      "Iterataion 1566: Training Loss: 0.011863213484551936, Validation Loss: 0.12325158184138695\n",
      "Iteataion 1566: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.4321e-08.\n",
      "Iterataion 1567: Training Loss: 0.014467267711851802, Validation Loss: 0.11941749067187718\n",
      "Iteataion 1567: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.4178e-08.\n",
      "Iterataion 1568: Training Loss: 0.015900007006956242, Validation Loss: 0.11848068519682828\n",
      "Iteataion 1568: Training Accuracy: 0.994140625, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.4036e-08.\n",
      "Iterataion 1569: Training Loss: 0.012417505037082738, Validation Loss: 0.11791333579600266\n",
      "Iteataion 1569: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.3896e-08.\n",
      "Iterataion 1570: Training Loss: 0.013947349132497342, Validation Loss: 0.11968825775107778\n",
      "Iteataion 1570: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.3757e-08.\n",
      "Iterataion 1571: Training Loss: 0.014550404432843144, Validation Loss: 0.11812852805610974\n",
      "Iteataion 1571: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.3619e-08.\n",
      "Iterataion 1572: Training Loss: 0.012734557227315214, Validation Loss: 0.12345023667326242\n",
      "Iteataion 1572: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.3483e-08.\n",
      "Iterataion 1573: Training Loss: 0.017692321537461267, Validation Loss: 0.11757058874851592\n",
      "Iteataion 1573: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.3348e-08.\n",
      "Iterataion 1574: Training Loss: 0.013364272493963871, Validation Loss: 0.11958091832390737\n",
      "Iteataion 1574: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.3215e-08.\n",
      "Iterataion 1575: Training Loss: 0.013350819039554474, Validation Loss: 0.12121752699093166\n",
      "Iteataion 1575: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.3083e-08.\n",
      "Iterataion 1576: Training Loss: 0.01488861454125148, Validation Loss: 0.11692221067411393\n",
      "Iteataion 1576: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.2952e-08.\n",
      "Iterataion 1577: Training Loss: 0.013736968189247878, Validation Loss: 0.11936741747336871\n",
      "Iteataion 1577: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2822e-08.\n",
      "Iterataion 1578: Training Loss: 0.012434219881546443, Validation Loss: 0.12847937152809008\n",
      "Iteataion 1578: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2694e-08.\n",
      "Iterataion 1579: Training Loss: 0.012980252072845257, Validation Loss: 0.119450202695855\n",
      "Iteataion 1579: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2567e-08.\n",
      "Iterataion 1580: Training Loss: 0.01653135560758267, Validation Loss: 0.11941378396685894\n",
      "Iteataion 1580: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2442e-08.\n",
      "Iterataion 1581: Training Loss: 0.012600266562515457, Validation Loss: 0.12274322187437153\n",
      "Iteataion 1581: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.2317e-08.\n",
      "Iterataion 1582: Training Loss: 0.016096227367172953, Validation Loss: 0.11933466236720361\n",
      "Iteataion 1582: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2194e-08.\n",
      "Iterataion 1583: Training Loss: 0.017855382871585425, Validation Loss: 0.12404119867331735\n",
      "Iteataion 1583: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2072e-08.\n",
      "Iterataion 1584: Training Loss: 0.013849060649950125, Validation Loss: 0.12063012879466774\n",
      "Iteataion 1584: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1951e-08.\n",
      "Iterataion 1585: Training Loss: 0.012880394926425738, Validation Loss: 0.12055672958447802\n",
      "Iteataion 1585: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.1832e-08.\n",
      "Iterataion 1586: Training Loss: 0.013908488212207689, Validation Loss: 0.11999101722087688\n",
      "Iteataion 1586: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.1714e-08.\n",
      "Iterataion 1587: Training Loss: 0.01141462893564042, Validation Loss: 0.1310177843040991\n",
      "Iteataion 1587: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1596e-08.\n",
      "Iterataion 1588: Training Loss: 0.012163970119621002, Validation Loss: 0.12026446376268457\n",
      "Iteataion 1588: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1480e-08.\n",
      "Iterataion 1589: Training Loss: 0.016097272167673815, Validation Loss: 0.1216164724219863\n",
      "Iteataion 1589: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.1366e-08.\n",
      "Iterataion 1590: Training Loss: 0.015979886549932067, Validation Loss: 0.12106945202472938\n",
      "Iteataion 1590: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.1252e-08.\n",
      "Iterataion 1591: Training Loss: 0.01079518754909395, Validation Loss: 0.1193392029537524\n",
      "Iteataion 1591: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1139e-08.\n",
      "Iterataion 1592: Training Loss: 0.0153074393641067, Validation Loss: 0.11982117095470951\n",
      "Iteataion 1592: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 1.1028e-08.\n",
      "Iterataion 1593: Training Loss: 0.014333891292126337, Validation Loss: 0.11918729576197021\n",
      "Iteataion 1593: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0918e-08.\n",
      "Iterataion 1594: Training Loss: 0.010825686188641947, Validation Loss: 0.11876353989042933\n",
      "Iteataion 1594: Training Accuracy: 0.9972098214285714, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0809e-08.\n",
      "Iterataion 1595: Training Loss: 0.014291296466804404, Validation Loss: 0.11893073226915808\n",
      "Iteataion 1595: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0701e-08.\n",
      "Iterataion 1596: Training Loss: 0.01449109794095181, Validation Loss: 0.11935562085326216\n",
      "Iteataion 1596: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0594e-08.\n",
      "Iterataion 1597: Training Loss: 0.014774677328853226, Validation Loss: 0.12575952198197385\n",
      "Iteataion 1597: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0488e-08.\n",
      "Iterataion 1598: Training Loss: 0.014010583876435572, Validation Loss: 0.12045013148723761\n",
      "Iteataion 1598: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0383e-08.\n",
      "Iterataion 1599: Training Loss: 0.012699169679795822, Validation Loss: 0.11998883756615858\n",
      "Iteataion 1599: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0279e-08.\n",
      "Iterataion 1600: Training Loss: 0.016535842630170106, Validation Loss: 0.11797677467452226\n",
      "Iteataion 1600: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0176e-08.\n",
      "Iterataion 1601: Training Loss: 0.013218722347669236, Validation Loss: 0.11890095703320851\n",
      "Iteataion 1601: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.0074e-08.\n",
      "Iterataion 1602: Training Loss: 0.012476287658457381, Validation Loss: 0.12803176162542956\n",
      "Iteataion 1602: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.9736e-09.\n",
      "Iterataion 1603: Training Loss: 0.012815265380916837, Validation Loss: 0.1227961784660271\n",
      "Iteataion 1603: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.8739e-09.\n",
      "Iterataion 1604: Training Loss: 0.013563176101348278, Validation Loss: 0.11800032457416286\n",
      "Iteataion 1604: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 9.7751e-09.\n",
      "Iterataion 1605: Training Loss: 0.014878896424584481, Validation Loss: 0.11959335983520737\n",
      "Iteataion 1605: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.6774e-09.\n",
      "Iterataion 1606: Training Loss: 0.01624146125364413, Validation Loss: 0.12144374728725268\n",
      "Iteataion 1606: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 9.5806e-09.\n",
      "Iterataion 1607: Training Loss: 0.013246124923650265, Validation Loss: 0.12172433232076511\n",
      "Iteataion 1607: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.4848e-09.\n",
      "Iterataion 1608: Training Loss: 0.012614294233931296, Validation Loss: 0.11980483355994405\n",
      "Iteataion 1608: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 9.3900e-09.\n",
      "Iterataion 1609: Training Loss: 0.01186109790446036, Validation Loss: 0.1191184983074824\n",
      "Iteataion 1609: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 9.2961e-09.\n",
      "Iterataion 1610: Training Loss: 0.017331235875475953, Validation Loss: 0.11730819792066496\n",
      "Iteataion 1610: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 9.2031e-09.\n",
      "Iterataion 1611: Training Loss: 0.013783433271570599, Validation Loss: 0.11896112569176205\n",
      "Iteataion 1611: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.1111e-09.\n",
      "Iterataion 1612: Training Loss: 0.014261385725328733, Validation Loss: 0.12001958200793214\n",
      "Iteataion 1612: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.0199e-09.\n",
      "Iterataion 1613: Training Loss: 0.01511155648232287, Validation Loss: 0.11928408697429227\n",
      "Iteataion 1613: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.9297e-09.\n",
      "Iterataion 1614: Training Loss: 0.015827638524951147, Validation Loss: 0.12070306990488727\n",
      "Iteataion 1614: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.8405e-09.\n",
      "Iterataion 1615: Training Loss: 0.015113954268142157, Validation Loss: 0.12567023460315996\n",
      "Iteataion 1615: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.7520e-09.\n",
      "Iterataion 1616: Training Loss: 0.013351791218504544, Validation Loss: 0.12082502331510868\n",
      "Iteataion 1616: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 8.6645e-09.\n",
      "Iterataion 1617: Training Loss: 0.01390362269465371, Validation Loss: 0.1182223870248602\n",
      "Iteataion 1617: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 8.5779e-09.\n",
      "Iterataion 1618: Training Loss: 0.014244244234918053, Validation Loss: 0.11936751292541442\n",
      "Iteataion 1618: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 8.4921e-09.\n",
      "Iterataion 1619: Training Loss: 0.017218008156779395, Validation Loss: 0.11945258342609855\n",
      "Iteataion 1619: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 8.4072e-09.\n",
      "Iterataion 1620: Training Loss: 0.01393740007345018, Validation Loss: 0.12116820846326513\n",
      "Iteataion 1620: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 8.3231e-09.\n",
      "Iterataion 1621: Training Loss: 0.0123644245007357, Validation Loss: 0.12330187468863342\n",
      "Iteataion 1621: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.2399e-09.\n",
      "Iterataion 1622: Training Loss: 0.013545669690555262, Validation Loss: 0.1220576221381723\n",
      "Iteataion 1622: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 8.1575e-09.\n",
      "Iterataion 1623: Training Loss: 0.011892014091087137, Validation Loss: 0.11927313127884323\n",
      "Iteataion 1623: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.0759e-09.\n",
      "Iterataion 1624: Training Loss: 0.014758898065882752, Validation Loss: 0.11989261900648339\n",
      "Iteataion 1624: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.9951e-09.\n",
      "Iterataion 1625: Training Loss: 0.014194095088308397, Validation Loss: 0.12149050439034997\n",
      "Iteataion 1625: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.9152e-09.\n",
      "Iterataion 1626: Training Loss: 0.01573135105273993, Validation Loss: 0.12406717977634199\n",
      "Iteataion 1626: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.8360e-09.\n",
      "Iterataion 1627: Training Loss: 0.015323864058542629, Validation Loss: 0.12462769014329263\n",
      "Iteataion 1627: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.7577e-09.\n",
      "Iterataion 1628: Training Loss: 0.014331741060874799, Validation Loss: 0.11910656255190033\n",
      "Iteataion 1628: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.6801e-09.\n",
      "Iterataion 1629: Training Loss: 0.009750511914820684, Validation Loss: 0.11681276139598794\n",
      "Iteataion 1629: Training Accuracy: 0.9970238095238095, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 7.6033e-09.\n",
      "Iterataion 1630: Training Loss: 0.013520888961721936, Validation Loss: 0.12149068380410714\n",
      "Iteataion 1630: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.5273e-09.\n",
      "Iterataion 1631: Training Loss: 0.020417932433691045, Validation Loss: 0.11660654398629715\n",
      "Iteataion 1631: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.4520e-09.\n",
      "Iterataion 1632: Training Loss: 0.015427802821124966, Validation Loss: 0.12382211282184892\n",
      "Iteataion 1632: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.3775e-09.\n",
      "Iterataion 1633: Training Loss: 0.013253221251551497, Validation Loss: 0.11980630118377143\n",
      "Iteataion 1633: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 7.3037e-09.\n",
      "Iterataion 1634: Training Loss: 0.014894997299520556, Validation Loss: 0.1182754640297101\n",
      "Iteataion 1634: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 7.2307e-09.\n",
      "Iterataion 1635: Training Loss: 0.013642731138705805, Validation Loss: 0.12184250423622249\n",
      "Iteataion 1635: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.1584e-09.\n",
      "Iterataion 1636: Training Loss: 0.015945839152419046, Validation Loss: 0.11543570332251853\n",
      "Iteataion 1636: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.0868e-09.\n",
      "Iterataion 1637: Training Loss: 0.01294171450447715, Validation Loss: 0.11726801873542504\n",
      "Iteataion 1637: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.0159e-09.\n",
      "Iterataion 1638: Training Loss: 0.011401842103596264, Validation Loss: 0.12276290035196126\n",
      "Iteataion 1638: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 6.9457e-09.\n",
      "Iterataion 1639: Training Loss: 0.014003795171142584, Validation Loss: 0.11872002944526286\n",
      "Iteataion 1639: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.8763e-09.\n",
      "Iterataion 1640: Training Loss: 0.01253531285938751, Validation Loss: 0.12291915448973091\n",
      "Iteataion 1640: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.8075e-09.\n",
      "Iterataion 1641: Training Loss: 0.015975039105159704, Validation Loss: 0.12345268080868509\n",
      "Iteataion 1641: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.7395e-09.\n",
      "Iterataion 1642: Training Loss: 0.015282184904034133, Validation Loss: 0.12592086489113594\n",
      "Iteataion 1642: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.6721e-09.\n",
      "Iterataion 1643: Training Loss: 0.016518777602318742, Validation Loss: 0.12388661064252984\n",
      "Iteataion 1643: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.6053e-09.\n",
      "Iterataion 1644: Training Loss: 0.010542029315016015, Validation Loss: 0.11778699954909204\n",
      "Iteataion 1644: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.5393e-09.\n",
      "Iterataion 1645: Training Loss: 0.0141730853356421, Validation Loss: 0.11932050198651623\n",
      "Iteataion 1645: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.4739e-09.\n",
      "Iterataion 1646: Training Loss: 0.011890861486338503, Validation Loss: 0.11898834219418193\n",
      "Iteataion 1646: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 6.4092e-09.\n",
      "Iterataion 1647: Training Loss: 0.013503325546110148, Validation Loss: 0.12401509524050464\n",
      "Iteataion 1647: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.3451e-09.\n",
      "Iterataion 1648: Training Loss: 0.011898944618997393, Validation Loss: 0.12104191098904532\n",
      "Iteataion 1648: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.2816e-09.\n",
      "Iterataion 1649: Training Loss: 0.010025637951389535, Validation Loss: 0.11965335827468462\n",
      "Iteataion 1649: Training Accuracy: 0.99609375, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.2188e-09.\n",
      "Iterataion 1650: Training Loss: 0.013279458508766842, Validation Loss: 0.12176322526718694\n",
      "Iteataion 1650: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.1566e-09.\n",
      "Iterataion 1651: Training Loss: 0.013350177564467219, Validation Loss: 0.12168902021594255\n",
      "Iteataion 1651: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.0950e-09.\n",
      "Iterataion 1652: Training Loss: 0.013168742258588276, Validation Loss: 0.12050935089809639\n",
      "Iteataion 1652: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.0341e-09.\n",
      "Iterataion 1653: Training Loss: 0.01455712194441578, Validation Loss: 0.11645877905326282\n",
      "Iteataion 1653: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.9738e-09.\n",
      "Iterataion 1654: Training Loss: 0.013741294077868033, Validation Loss: 0.12363794319496331\n",
      "Iteataion 1654: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.9140e-09.\n",
      "Iterataion 1655: Training Loss: 0.01797302073466558, Validation Loss: 0.1224345989445815\n",
      "Iteataion 1655: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.8549e-09.\n",
      "Iterataion 1656: Training Loss: 0.015969554428359727, Validation Loss: 0.12083438506758795\n",
      "Iteataion 1656: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.7963e-09.\n",
      "Iterataion 1657: Training Loss: 0.01588997216149328, Validation Loss: 0.1244323862483725\n",
      "Iteataion 1657: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.7384e-09.\n",
      "Iterataion 1658: Training Loss: 0.01530823252888112, Validation Loss: 0.12082430516531487\n",
      "Iteataion 1658: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.6810e-09.\n",
      "Iterataion 1659: Training Loss: 0.01460226411369356, Validation Loss: 0.11879442285223887\n",
      "Iteataion 1659: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.6242e-09.\n",
      "Iterataion 1660: Training Loss: 0.011714965779150273, Validation Loss: 0.12087474231077244\n",
      "Iteataion 1660: Training Accuracy: 0.9970238095238095, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.5679e-09.\n",
      "Iterataion 1661: Training Loss: 0.017815106192326263, Validation Loss: 0.11965952871974966\n",
      "Iteataion 1661: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.5122e-09.\n",
      "Iterataion 1662: Training Loss: 0.013900093499168162, Validation Loss: 0.12492618367655157\n",
      "Iteataion 1662: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 5.4571e-09.\n",
      "Iterataion 1663: Training Loss: 0.013719302716436323, Validation Loss: 0.1247168901240135\n",
      "Iteataion 1663: Training Accuracy: 0.99609375, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.4026e-09.\n",
      "Iterataion 1664: Training Loss: 0.01295675795743504, Validation Loss: 0.11887568232415971\n",
      "Iteataion 1664: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.3485e-09.\n",
      "Iterataion 1665: Training Loss: 0.01431916470442129, Validation Loss: 0.11873421234592636\n",
      "Iteataion 1665: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 5.2950e-09.\n",
      "Iterataion 1666: Training Loss: 0.013444421081984985, Validation Loss: 0.1222970460161067\n",
      "Iteataion 1666: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.2421e-09.\n",
      "Iterataion 1667: Training Loss: 0.015972065553557083, Validation Loss: 0.12319766113068908\n",
      "Iteataion 1667: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.1897e-09.\n",
      "Iterataion 1668: Training Loss: 0.015550315639765342, Validation Loss: 0.12253262170607497\n",
      "Iteataion 1668: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 5.1378e-09.\n",
      "Iterataion 1669: Training Loss: 0.011077113610603094, Validation Loss: 0.12083642851992897\n",
      "Iteataion 1669: Training Accuracy: 0.9969308035714286, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 5.0864e-09.\n",
      "Iterataion 1670: Training Loss: 0.01338770712288738, Validation Loss: 0.12047441877288426\n",
      "Iteataion 1670: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.0355e-09.\n",
      "Iterataion 1671: Training Loss: 0.010875949232482134, Validation Loss: 0.11680268971022309\n",
      "Iteataion 1671: Training Accuracy: 0.9967447916666666, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.9852e-09.\n",
      "Iterataion 1672: Training Loss: 0.014218110364616407, Validation Loss: 0.11611709514456778\n",
      "Iteataion 1672: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.9353e-09.\n",
      "Iterataion 1673: Training Loss: 0.014772089782399599, Validation Loss: 0.11869453661791163\n",
      "Iteataion 1673: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.8860e-09.\n",
      "Iterataion 1674: Training Loss: 0.013740233641813515, Validation Loss: 0.1214990109615539\n",
      "Iteataion 1674: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.8371e-09.\n",
      "Iterataion 1675: Training Loss: 0.01063914868188046, Validation Loss: 0.12009241047497021\n",
      "Iteataion 1675: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.7887e-09.\n",
      "Iterataion 1676: Training Loss: 0.01610400858314284, Validation Loss: 0.11806725598616162\n",
      "Iteataion 1676: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.7409e-09.\n",
      "Iterataion 1677: Training Loss: 0.013812047720246832, Validation Loss: 0.12301512289559469\n",
      "Iteataion 1677: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.6934e-09.\n",
      "Iterataion 1678: Training Loss: 0.011657548135963498, Validation Loss: 0.1273816491110909\n",
      "Iteataion 1678: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.6465e-09.\n",
      "Iterataion 1679: Training Loss: 0.01828977891817706, Validation Loss: 0.11869123415374083\n",
      "Iteataion 1679: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 4.6000e-09.\n",
      "Iterataion 1680: Training Loss: 0.01680059598540625, Validation Loss: 0.12022095685682782\n",
      "Iteataion 1680: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9799107142857143\n",
      "Adjusting learning rate of group 0 to 4.5540e-09.\n",
      "Iterataion 1681: Training Loss: 0.011721969518530276, Validation Loss: 0.12975664981271753\n",
      "Iteataion 1681: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.5085e-09.\n",
      "Iterataion 1682: Training Loss: 0.010726773622724601, Validation Loss: 0.12369400509718306\n",
      "Iteataion 1682: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.4634e-09.\n",
      "Iterataion 1683: Training Loss: 0.014736319113275996, Validation Loss: 0.12095293400258325\n",
      "Iteataion 1683: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.4188e-09.\n",
      "Iterataion 1684: Training Loss: 0.013415400985688317, Validation Loss: 0.12141770215012224\n",
      "Iteataion 1684: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.3746e-09.\n",
      "Iterataion 1685: Training Loss: 0.014635130775950201, Validation Loss: 0.1193140009993108\n",
      "Iteataion 1685: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.3309e-09.\n",
      "Iterataion 1686: Training Loss: 0.010923135132859266, Validation Loss: 0.12025045150061842\n",
      "Iteataion 1686: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.2875e-09.\n",
      "Iterataion 1687: Training Loss: 0.013652921533686092, Validation Loss: 0.12055417713737569\n",
      "Iteataion 1687: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.2447e-09.\n",
      "Iterataion 1688: Training Loss: 0.016791741510443277, Validation Loss: 0.11981002100538916\n",
      "Iteataion 1688: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 4.2022e-09.\n",
      "Iterataion 1689: Training Loss: 0.012256747200906633, Validation Loss: 0.1217421077421821\n",
      "Iteataion 1689: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 4.1602e-09.\n",
      "Iterataion 1690: Training Loss: 0.014725425221377281, Validation Loss: 0.12246102930001188\n",
      "Iteataion 1690: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 4.1186e-09.\n",
      "Iterataion 1691: Training Loss: 0.012313146701829876, Validation Loss: 0.12212852714867217\n",
      "Iteataion 1691: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 4.0774e-09.\n",
      "Iterataion 1692: Training Loss: 0.01420707976418369, Validation Loss: 0.11827163057538068\n",
      "Iteataion 1692: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 4.0366e-09.\n",
      "Iterataion 1693: Training Loss: 0.015208811520265616, Validation Loss: 0.12009660267873054\n",
      "Iteataion 1693: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.9963e-09.\n",
      "Iterataion 1694: Training Loss: 0.01263054220398336, Validation Loss: 0.12297192562042122\n",
      "Iteataion 1694: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.9563e-09.\n",
      "Iterataion 1695: Training Loss: 0.014520036540075044, Validation Loss: 0.12130359511413588\n",
      "Iteataion 1695: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.9167e-09.\n",
      "Iterataion 1696: Training Loss: 0.017447334399668522, Validation Loss: 0.11979696377984067\n",
      "Iteataion 1696: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.8776e-09.\n",
      "Iterataion 1697: Training Loss: 0.011613158322661602, Validation Loss: 0.12582949083156475\n",
      "Iteataion 1697: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.8388e-09.\n",
      "Iterataion 1698: Training Loss: 0.012761346140491615, Validation Loss: 0.11970709614944076\n",
      "Iteataion 1698: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.8004e-09.\n",
      "Iterataion 1699: Training Loss: 0.01213630573324926, Validation Loss: 0.11915166262344162\n",
      "Iteataion 1699: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.7624e-09.\n",
      "Iterataion 1700: Training Loss: 0.014615984043820265, Validation Loss: 0.12035704151409246\n",
      "Iteataion 1700: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.7248e-09.\n",
      "Iterataion 1701: Training Loss: 0.0140742311980171, Validation Loss: 0.11940576029492815\n",
      "Iteataion 1701: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.6875e-09.\n",
      "Iterataion 1702: Training Loss: 0.013513197081266696, Validation Loss: 0.11868203059903619\n",
      "Iteataion 1702: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.6507e-09.\n",
      "Iterataion 1703: Training Loss: 0.01629428002665455, Validation Loss: 0.11982496747627809\n",
      "Iteataion 1703: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.6142e-09.\n",
      "Iterataion 1704: Training Loss: 0.018261658490292484, Validation Loss: 0.123879690238604\n",
      "Iteataion 1704: Training Accuracy: 0.9943266369047619, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.5780e-09.\n",
      "Iterataion 1705: Training Loss: 0.011774370880395978, Validation Loss: 0.12439906895274251\n",
      "Iteataion 1705: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 3.5422e-09.\n",
      "Iterataion 1706: Training Loss: 0.01356571997044619, Validation Loss: 0.11674873749356399\n",
      "Iteataion 1706: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 3.5068e-09.\n",
      "Iterataion 1707: Training Loss: 0.013800974075248867, Validation Loss: 0.1220185580314137\n",
      "Iteataion 1707: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.4717e-09.\n",
      "Iterataion 1708: Training Loss: 0.018071736823411903, Validation Loss: 0.12096257523417746\n",
      "Iteataion 1708: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.4370e-09.\n",
      "Iterataion 1709: Training Loss: 0.012946959511407589, Validation Loss: 0.11751471398818511\n",
      "Iteataion 1709: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 3.4027e-09.\n",
      "Iterataion 1710: Training Loss: 0.015376110503681472, Validation Loss: 0.12024390278526059\n",
      "Iteataion 1710: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.3686e-09.\n",
      "Iterataion 1711: Training Loss: 0.010630152046904916, Validation Loss: 0.12010506915053488\n",
      "Iteataion 1711: Training Accuracy: 0.9968377976190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.3349e-09.\n",
      "Iterataion 1712: Training Loss: 0.017111667001955936, Validation Loss: 0.11769345675299807\n",
      "Iteataion 1712: Training Accuracy: 0.9939546130952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.3016e-09.\n",
      "Iterataion 1713: Training Loss: 0.017081701750748562, Validation Loss: 0.12269714907118369\n",
      "Iteataion 1713: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 3.2686e-09.\n",
      "Iterataion 1714: Training Loss: 0.015043695084680942, Validation Loss: 0.11862775693624848\n",
      "Iteataion 1714: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.2359e-09.\n",
      "Iterataion 1715: Training Loss: 0.012851457846627019, Validation Loss: 0.11801025208381073\n",
      "Iteataion 1715: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 3.2035e-09.\n",
      "Iterataion 1716: Training Loss: 0.013237615637718227, Validation Loss: 0.11840724279229506\n",
      "Iteataion 1716: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 3.1715e-09.\n",
      "Iterataion 1717: Training Loss: 0.012189529345595295, Validation Loss: 0.12205074035077038\n",
      "Iteataion 1717: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 3.1398e-09.\n",
      "Iterataion 1718: Training Loss: 0.010976519029933268, Validation Loss: 0.12388715602275802\n",
      "Iteataion 1718: Training Accuracy: 0.9968377976190477, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.1084e-09.\n",
      "Iterataion 1719: Training Loss: 0.01327991897040214, Validation Loss: 0.12044553425185746\n",
      "Iteataion 1719: Training Accuracy: 0.99609375, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 3.0773e-09.\n",
      "Iterataion 1720: Training Loss: 0.014322726080552423, Validation Loss: 0.11755276252032916\n",
      "Iteataion 1720: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.0465e-09.\n",
      "Iterataion 1721: Training Loss: 0.019393572748135385, Validation Loss: 0.12686769951918594\n",
      "Iteataion 1721: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 3.0161e-09.\n",
      "Iterataion 1722: Training Loss: 0.014413695062321059, Validation Loss: 0.1225938487630451\n",
      "Iteataion 1722: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.9859e-09.\n",
      "Iterataion 1723: Training Loss: 0.01599060375962133, Validation Loss: 0.11944769033253556\n",
      "Iteataion 1723: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.9560e-09.\n",
      "Iterataion 1724: Training Loss: 0.01282944675645802, Validation Loss: 0.11690887178311397\n",
      "Iteataion 1724: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.9265e-09.\n",
      "Iterataion 1725: Training Loss: 0.012498400338422117, Validation Loss: 0.11980490391455\n",
      "Iteataion 1725: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.8972e-09.\n",
      "Iterataion 1726: Training Loss: 0.015381665636498124, Validation Loss: 0.1183088661807521\n",
      "Iteataion 1726: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.8682e-09.\n",
      "Iterataion 1727: Training Loss: 0.015497419113693425, Validation Loss: 0.12033397700529681\n",
      "Iteataion 1727: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.8396e-09.\n",
      "Iterataion 1728: Training Loss: 0.015267299646079473, Validation Loss: 0.12123891777109082\n",
      "Iteataion 1728: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.8112e-09.\n",
      "Iterataion 1729: Training Loss: 0.011236792264546653, Validation Loss: 0.12317556834768323\n",
      "Iteataion 1729: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.7831e-09.\n",
      "Iterataion 1730: Training Loss: 0.015829469119289244, Validation Loss: 0.12123006997877028\n",
      "Iteataion 1730: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.7552e-09.\n",
      "Iterataion 1731: Training Loss: 0.012968302805124487, Validation Loss: 0.12130928296942219\n",
      "Iteataion 1731: Training Accuracy: 0.9969308035714286, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.7277e-09.\n",
      "Iterataion 1732: Training Loss: 0.016815418789154865, Validation Loss: 0.12229843116535737\n",
      "Iteataion 1732: Training Accuracy: 0.9942336309523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.7004e-09.\n",
      "Iterataion 1733: Training Loss: 0.01627811305186555, Validation Loss: 0.12239480071996407\n",
      "Iteataion 1733: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.6734e-09.\n",
      "Iterataion 1734: Training Loss: 0.01801750489090943, Validation Loss: 0.1211089903329749\n",
      "Iteataion 1734: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 2.6467e-09.\n",
      "Iterataion 1735: Training Loss: 0.014791799897242974, Validation Loss: 0.11999779799385224\n",
      "Iteataion 1735: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.6202e-09.\n",
      "Iterataion 1736: Training Loss: 0.013283537045500414, Validation Loss: 0.12109265144823528\n",
      "Iteataion 1736: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.5940e-09.\n",
      "Iterataion 1737: Training Loss: 0.012766605585013253, Validation Loss: 0.12224256873511277\n",
      "Iteataion 1737: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.5680e-09.\n",
      "Iterataion 1738: Training Loss: 0.013186965819481693, Validation Loss: 0.12396150320291338\n",
      "Iteataion 1738: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.5424e-09.\n",
      "Iterataion 1739: Training Loss: 0.01271273335877633, Validation Loss: 0.11871347206264235\n",
      "Iteataion 1739: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.5169e-09.\n",
      "Iterataion 1740: Training Loss: 0.017171818174667165, Validation Loss: 0.12018959933079824\n",
      "Iteataion 1740: Training Accuracy: 0.994140625, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.4918e-09.\n",
      "Iterataion 1741: Training Loss: 0.017529072355713226, Validation Loss: 0.11982685033368265\n",
      "Iteataion 1741: Training Accuracy: 0.9938616071428571, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.4669e-09.\n",
      "Iterataion 1742: Training Loss: 0.014869359806375188, Validation Loss: 0.11915798122120067\n",
      "Iteataion 1742: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.4422e-09.\n",
      "Iterataion 1743: Training Loss: 0.01311633125098121, Validation Loss: 0.12562023962155075\n",
      "Iteataion 1743: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.4178e-09.\n",
      "Iterataion 1744: Training Loss: 0.012193539153197557, Validation Loss: 0.1288801289969919\n",
      "Iteataion 1744: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.3936e-09.\n",
      "Iterataion 1745: Training Loss: 0.01256873005545213, Validation Loss: 0.1201179292813943\n",
      "Iteataion 1745: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.3697e-09.\n",
      "Iterataion 1746: Training Loss: 0.013648951990274757, Validation Loss: 0.11720949374834962\n",
      "Iteataion 1746: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.3460e-09.\n",
      "Iterataion 1747: Training Loss: 0.012630644239050274, Validation Loss: 0.12722844417241017\n",
      "Iteataion 1747: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.3225e-09.\n",
      "Iterataion 1748: Training Loss: 0.015329061161613783, Validation Loss: 0.1236023057476481\n",
      "Iteataion 1748: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.2993e-09.\n",
      "Iterataion 1749: Training Loss: 0.015833810070274443, Validation Loss: 0.11957409123467032\n",
      "Iteataion 1749: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.2763e-09.\n",
      "Iterataion 1750: Training Loss: 0.017991020252529397, Validation Loss: 0.11884694690418589\n",
      "Iteataion 1750: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.2535e-09.\n",
      "Iterataion 1751: Training Loss: 0.009950513904949115, Validation Loss: 0.12978997860081132\n",
      "Iteataion 1751: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.2310e-09.\n",
      "Iterataion 1752: Training Loss: 0.011107345595453939, Validation Loss: 0.12411493644481753\n",
      "Iteataion 1752: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.2087e-09.\n",
      "Iterataion 1753: Training Loss: 0.012014529298332905, Validation Loss: 0.11979263641292275\n",
      "Iteataion 1753: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.1866e-09.\n",
      "Iterataion 1754: Training Loss: 0.014848892063580029, Validation Loss: 0.12467692073480022\n",
      "Iteataion 1754: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.1647e-09.\n",
      "Iterataion 1755: Training Loss: 0.013413747086630253, Validation Loss: 0.11672640882614183\n",
      "Iteataion 1755: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 2.1431e-09.\n",
      "Iterataion 1756: Training Loss: 0.01146622984265786, Validation Loss: 0.11787295219113642\n",
      "Iteataion 1756: Training Accuracy: 0.9970238095238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.1216e-09.\n",
      "Iterataion 1757: Training Loss: 0.014311743664386554, Validation Loss: 0.12037169402067709\n",
      "Iteataion 1757: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 2.1004e-09.\n",
      "Iterataion 1758: Training Loss: 0.01359852484945336, Validation Loss: 0.13083735951534814\n",
      "Iteataion 1758: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 2.0794e-09.\n",
      "Iterataion 1759: Training Loss: 0.01667605291370269, Validation Loss: 0.12007680425147821\n",
      "Iteataion 1759: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.0586e-09.\n",
      "Iterataion 1760: Training Loss: 0.013078661073831573, Validation Loss: 0.12003938089658665\n",
      "Iteataion 1760: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 2.0380e-09.\n",
      "Iterataion 1761: Training Loss: 0.012406242496722997, Validation Loss: 0.12479741485127839\n",
      "Iteataion 1761: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 2.0177e-09.\n",
      "Iterataion 1762: Training Loss: 0.011346938613450857, Validation Loss: 0.12291428356902764\n",
      "Iteataion 1762: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.9975e-09.\n",
      "Iterataion 1763: Training Loss: 0.013742102106857465, Validation Loss: 0.12061487150196804\n",
      "Iteataion 1763: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.9775e-09.\n",
      "Iterataion 1764: Training Loss: 0.010855500307143247, Validation Loss: 0.11880903257193362\n",
      "Iteataion 1764: Training Accuracy: 0.9969308035714286, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.9577e-09.\n",
      "Iterataion 1765: Training Loss: 0.013425312387341534, Validation Loss: 0.1161831782083027\n",
      "Iteataion 1765: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.9382e-09.\n",
      "Iterataion 1766: Training Loss: 0.01345513061819665, Validation Loss: 0.11653637644556555\n",
      "Iteataion 1766: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.9188e-09.\n",
      "Iterataion 1767: Training Loss: 0.0128966452979795, Validation Loss: 0.11767443803794932\n",
      "Iteataion 1767: Training Accuracy: 0.99609375, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.8996e-09.\n",
      "Iterataion 1768: Training Loss: 0.013164610524235214, Validation Loss: 0.11805861162180763\n",
      "Iteataion 1768: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.8806e-09.\n",
      "Iterataion 1769: Training Loss: 0.01749715426013788, Validation Loss: 0.12207608231167286\n",
      "Iteataion 1769: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.8618e-09.\n",
      "Iterataion 1770: Training Loss: 0.01484969063173327, Validation Loss: 0.12036745025344738\n",
      "Iteataion 1770: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.8432e-09.\n",
      "Iterataion 1771: Training Loss: 0.013741114615807086, Validation Loss: 0.12068711767234362\n",
      "Iteataion 1771: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.8247e-09.\n",
      "Iterataion 1772: Training Loss: 0.012941395902753847, Validation Loss: 0.11778536185383706\n",
      "Iteataion 1772: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.8065e-09.\n",
      "Iterataion 1773: Training Loss: 0.013363108279401001, Validation Loss: 0.12242858305221378\n",
      "Iteataion 1773: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.7884e-09.\n",
      "Iterataion 1774: Training Loss: 0.015515636985223673, Validation Loss: 0.12231488712841826\n",
      "Iteataion 1774: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.7705e-09.\n",
      "Iterataion 1775: Training Loss: 0.01467596716090652, Validation Loss: 0.12135034782965327\n",
      "Iteataion 1775: Training Accuracy: 0.99609375, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.7528e-09.\n",
      "Iterataion 1776: Training Loss: 0.015933333375891336, Validation Loss: 0.11846943572163582\n",
      "Iteataion 1776: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.7353e-09.\n",
      "Iterataion 1777: Training Loss: 0.013340275043490606, Validation Loss: 0.11746197070915071\n",
      "Iteataion 1777: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.7180e-09.\n",
      "Iterataion 1778: Training Loss: 0.012652518558120746, Validation Loss: 0.11932491793058722\n",
      "Iteataion 1778: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.7008e-09.\n",
      "Iterataion 1779: Training Loss: 0.015283387073128858, Validation Loss: 0.11776386454230084\n",
      "Iteataion 1779: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.6838e-09.\n",
      "Iterataion 1780: Training Loss: 0.016675552960609304, Validation Loss: 0.1187217336193454\n",
      "Iteataion 1780: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6669e-09.\n",
      "Iterataion 1781: Training Loss: 0.014266993082267884, Validation Loss: 0.12583718132071492\n",
      "Iteataion 1781: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.6503e-09.\n",
      "Iterataion 1782: Training Loss: 0.012542896034247604, Validation Loss: 0.12020585330191819\n",
      "Iteataion 1782: Training Accuracy: 0.99609375, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.6338e-09.\n",
      "Iterataion 1783: Training Loss: 0.013158160643122287, Validation Loss: 0.12044228683722705\n",
      "Iteataion 1783: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.6174e-09.\n",
      "Iterataion 1784: Training Loss: 0.011445699659075789, Validation Loss: 0.1206173473520477\n",
      "Iteataion 1784: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.6012e-09.\n",
      "Iterataion 1785: Training Loss: 0.011956154018351919, Validation Loss: 0.12100987356559305\n",
      "Iteataion 1785: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.5852e-09.\n",
      "Iterataion 1786: Training Loss: 0.014600962639192376, Validation Loss: 0.1325504639535211\n",
      "Iteataion 1786: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.5694e-09.\n",
      "Iterataion 1787: Training Loss: 0.014592569328364944, Validation Loss: 0.11922234860987108\n",
      "Iteataion 1787: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.5537e-09.\n",
      "Iterataion 1788: Training Loss: 0.014262289396127474, Validation Loss: 0.11892483609859128\n",
      "Iteataion 1788: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.5381e-09.\n",
      "Iterataion 1789: Training Loss: 0.012983014814598865, Validation Loss: 0.1176869637906415\n",
      "Iteataion 1789: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.5228e-09.\n",
      "Iterataion 1790: Training Loss: 0.015831049779516472, Validation Loss: 0.11955017334122847\n",
      "Iteataion 1790: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.5075e-09.\n",
      "Iterataion 1791: Training Loss: 0.013551452848746603, Validation Loss: 0.1221292905556322\n",
      "Iteataion 1791: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.4925e-09.\n",
      "Iterataion 1792: Training Loss: 0.014413818623591772, Validation Loss: 0.12648480236757456\n",
      "Iteataion 1792: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4775e-09.\n",
      "Iterataion 1793: Training Loss: 0.01430579573843171, Validation Loss: 0.12241811495666143\n",
      "Iteataion 1793: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4628e-09.\n",
      "Iterataion 1794: Training Loss: 0.014089522069260133, Validation Loss: 0.12034980285197223\n",
      "Iteataion 1794: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.4481e-09.\n",
      "Iterataion 1795: Training Loss: 0.01233436961722432, Validation Loss: 0.12126683080483727\n",
      "Iteataion 1795: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.4337e-09.\n",
      "Iterataion 1796: Training Loss: 0.013386227037133035, Validation Loss: 0.11925774927410047\n",
      "Iteataion 1796: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.4193e-09.\n",
      "Iterataion 1797: Training Loss: 0.011675229105780538, Validation Loss: 0.12091062822742615\n",
      "Iteataion 1797: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.4051e-09.\n",
      "Iterataion 1798: Training Loss: 0.013210296057845036, Validation Loss: 0.11862101953933811\n",
      "Iteataion 1798: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.3911e-09.\n",
      "Iterataion 1799: Training Loss: 0.01483522200574234, Validation Loss: 0.12547972259429716\n",
      "Iteataion 1799: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9773065476190477\n",
      "Adjusting learning rate of group 0 to 1.3772e-09.\n",
      "Iterataion 1800: Training Loss: 0.01312974528590786, Validation Loss: 0.12050323288819594\n",
      "Iteataion 1800: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.3634e-09.\n",
      "Iterataion 1801: Training Loss: 0.01225562610445282, Validation Loss: 0.11680363856892033\n",
      "Iteataion 1801: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.3498e-09.\n",
      "Iterataion 1802: Training Loss: 0.012698868399034226, Validation Loss: 0.1184891348707535\n",
      "Iteataion 1802: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.3363e-09.\n",
      "Iterataion 1803: Training Loss: 0.016815048946913966, Validation Loss: 0.12016910462350608\n",
      "Iteataion 1803: Training Accuracy: 0.9948846726190477, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.3229e-09.\n",
      "Iterataion 1804: Training Loss: 0.013242859344038566, Validation Loss: 0.11624381138102674\n",
      "Iteataion 1804: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.3097e-09.\n",
      "Iterataion 1805: Training Loss: 0.012384774090170102, Validation Loss: 0.11890877048462266\n",
      "Iteataion 1805: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2966e-09.\n",
      "Iterataion 1806: Training Loss: 0.01351985203807694, Validation Loss: 0.1215693032022611\n",
      "Iteataion 1806: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.2836e-09.\n",
      "Iterataion 1807: Training Loss: 0.01425619361295454, Validation Loss: 0.12254494902388216\n",
      "Iteataion 1807: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.2708e-09.\n",
      "Iterataion 1808: Training Loss: 0.01347411780103673, Validation Loss: 0.1173081600459338\n",
      "Iteataion 1808: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2581e-09.\n",
      "Iterataion 1809: Training Loss: 0.016938179768838022, Validation Loss: 0.1218889733725341\n",
      "Iteataion 1809: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2455e-09.\n",
      "Iterataion 1810: Training Loss: 0.014027522879995652, Validation Loss: 0.12129007184469118\n",
      "Iteataion 1810: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2330e-09.\n",
      "Iterataion 1811: Training Loss: 0.014011306401682338, Validation Loss: 0.12270721326661636\n",
      "Iteataion 1811: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.2207e-09.\n",
      "Iterataion 1812: Training Loss: 0.013196532008751202, Validation Loss: 0.1195020030320781\n",
      "Iteataion 1812: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.2085e-09.\n",
      "Iterataion 1813: Training Loss: 0.01472442470679846, Validation Loss: 0.12382766287404726\n",
      "Iteataion 1813: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1964e-09.\n",
      "Iterataion 1814: Training Loss: 0.018057990536194096, Validation Loss: 0.12044565894402473\n",
      "Iteataion 1814: Training Accuracy: 0.9944196428571429, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1844e-09.\n",
      "Iterataion 1815: Training Loss: 0.01714787497565089, Validation Loss: 0.11666255147003274\n",
      "Iteataion 1815: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1726e-09.\n",
      "Iterataion 1816: Training Loss: 0.011971769608176608, Validation Loss: 0.11786294171569596\n",
      "Iteataion 1816: Training Accuracy: 0.9968377976190477, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.1609e-09.\n",
      "Iterataion 1817: Training Loss: 0.01243195590816862, Validation Loss: 0.12029286592676328\n",
      "Iteataion 1817: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1493e-09.\n",
      "Iterataion 1818: Training Loss: 0.015368128164732707, Validation Loss: 0.11811808675808673\n",
      "Iteataion 1818: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1378e-09.\n",
      "Iterataion 1819: Training Loss: 0.01458170510564295, Validation Loss: 0.11792635316846937\n",
      "Iteataion 1819: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.1264e-09.\n",
      "Iterataion 1820: Training Loss: 0.015246315281712702, Validation Loss: 0.12738191920031636\n",
      "Iteataion 1820: Training Accuracy: 0.9946056547619048, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 1.1151e-09.\n",
      "Iterataion 1821: Training Loss: 0.011685957373008355, Validation Loss: 0.12140020964349188\n",
      "Iteataion 1821: Training Accuracy: 0.99609375, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.1040e-09.\n",
      "Iterataion 1822: Training Loss: 0.013994249511052837, Validation Loss: 0.11787322422534954\n",
      "Iteataion 1822: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.0929e-09.\n",
      "Iterataion 1823: Training Loss: 0.012596966304556985, Validation Loss: 0.12320832121782233\n",
      "Iteataion 1823: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 1.0820e-09.\n",
      "Iterataion 1824: Training Loss: 0.011861942827695992, Validation Loss: 0.11933022698887237\n",
      "Iteataion 1824: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 1.0712e-09.\n",
      "Iterataion 1825: Training Loss: 0.011820578717272505, Validation Loss: 0.12354091512289171\n",
      "Iteataion 1825: Training Accuracy: 0.9964657738095238, Validation Accuracy  0.9769345238095238\n",
      "Adjusting learning rate of group 0 to 1.0605e-09.\n",
      "Iterataion 1826: Training Loss: 0.012399187730137304, Validation Loss: 0.12092877645755368\n",
      "Iteataion 1826: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0499e-09.\n",
      "Iterataion 1827: Training Loss: 0.01571690828175546, Validation Loss: 0.1152688447718236\n",
      "Iteataion 1827: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0394e-09.\n",
      "Iterataion 1828: Training Loss: 0.01497117382847888, Validation Loss: 0.11782273775244859\n",
      "Iteataion 1828: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 1.0290e-09.\n",
      "Iterataion 1829: Training Loss: 0.014846439004881296, Validation Loss: 0.11999719588245016\n",
      "Iteataion 1829: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 1.0187e-09.\n",
      "Iterataion 1830: Training Loss: 0.012837438892941186, Validation Loss: 0.12046087095400364\n",
      "Iteataion 1830: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 1.0085e-09.\n",
      "Iterataion 1831: Training Loss: 0.0112193000250535, Validation Loss: 0.12313117587047334\n",
      "Iteataion 1831: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.9842e-10.\n",
      "Iterataion 1832: Training Loss: 0.011480679544188015, Validation Loss: 0.12010497878811027\n",
      "Iteataion 1832: Training Accuracy: 0.9970238095238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.8843e-10.\n",
      "Iterataion 1833: Training Loss: 0.013974007422280147, Validation Loss: 0.11840905827504196\n",
      "Iteataion 1833: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 9.7855e-10.\n",
      "Iterataion 1834: Training Loss: 0.014443240607886513, Validation Loss: 0.1257836875809561\n",
      "Iteataion 1834: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 9.6876e-10.\n",
      "Iterataion 1835: Training Loss: 0.013776760075372381, Validation Loss: 0.11997759324163426\n",
      "Iteataion 1835: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 9.5907e-10.\n",
      "Iterataion 1836: Training Loss: 0.014238723975286992, Validation Loss: 0.12168755724588863\n",
      "Iteataion 1836: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 9.4948e-10.\n",
      "Iterataion 1837: Training Loss: 0.01629466864539723, Validation Loss: 0.12338023372108071\n",
      "Iteataion 1837: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.3999e-10.\n",
      "Iterataion 1838: Training Loss: 0.01518895825169685, Validation Loss: 0.12142137735343833\n",
      "Iteataion 1838: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.3059e-10.\n",
      "Iterataion 1839: Training Loss: 0.011198679554418377, Validation Loss: 0.12330057228512199\n",
      "Iteataion 1839: Training Accuracy: 0.9966517857142857, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.2128e-10.\n",
      "Iterataion 1840: Training Loss: 0.01657208426009228, Validation Loss: 0.12263225547106164\n",
      "Iteataion 1840: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 9.1207e-10.\n",
      "Iterataion 1841: Training Loss: 0.015411158385449562, Validation Loss: 0.12310911286707468\n",
      "Iteataion 1841: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 9.0295e-10.\n",
      "Iterataion 1842: Training Loss: 0.014294966498339648, Validation Loss: 0.12247878252585395\n",
      "Iteataion 1842: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 8.9392e-10.\n",
      "Iterataion 1843: Training Loss: 0.014251884997719174, Validation Loss: 0.119754338577367\n",
      "Iteataion 1843: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.8498e-10.\n",
      "Iterataion 1844: Training Loss: 0.014515554185428317, Validation Loss: 0.1204257649298553\n",
      "Iteataion 1844: Training Accuracy: 0.9958147321428571, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 8.7613e-10.\n",
      "Iterataion 1845: Training Loss: 0.011719502907031646, Validation Loss: 0.12666091575179386\n",
      "Iteataion 1845: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 8.6737e-10.\n",
      "Iterataion 1846: Training Loss: 0.01483479188807437, Validation Loss: 0.12723702901872103\n",
      "Iteataion 1846: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.5870e-10.\n",
      "Iterataion 1847: Training Loss: 0.017439878507883953, Validation Loss: 0.11914467344503486\n",
      "Iteataion 1847: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 8.5011e-10.\n",
      "Iterataion 1848: Training Loss: 0.014087848948777659, Validation Loss: 0.12226281911219902\n",
      "Iteataion 1848: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 8.4161e-10.\n",
      "Iterataion 1849: Training Loss: 0.01515790304670272, Validation Loss: 0.12421455430065668\n",
      "Iteataion 1849: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.3319e-10.\n",
      "Iterataion 1850: Training Loss: 0.013151508635035464, Validation Loss: 0.11934149850063344\n",
      "Iteataion 1850: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 8.2486e-10.\n",
      "Iterataion 1851: Training Loss: 0.0123696377282003, Validation Loss: 0.12138468180442365\n",
      "Iteataion 1851: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 8.1661e-10.\n",
      "Iterataion 1852: Training Loss: 0.012209333196557043, Validation Loss: 0.12053598452745597\n",
      "Iteataion 1852: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 8.0845e-10.\n",
      "Iterataion 1853: Training Loss: 0.012999442616173675, Validation Loss: 0.11884222737025106\n",
      "Iteataion 1853: Training Accuracy: 0.9946986607142857, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 8.0036e-10.\n",
      "Iterataion 1854: Training Loss: 0.014414609430084551, Validation Loss: 0.12194894191527898\n",
      "Iteataion 1854: Training Accuracy: 0.9952566964285714, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.9236e-10.\n",
      "Iterataion 1855: Training Loss: 0.013311884259494177, Validation Loss: 0.11965906964586594\n",
      "Iteataion 1855: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.8443e-10.\n",
      "Iterataion 1856: Training Loss: 0.010606257301235215, Validation Loss: 0.11938972230546357\n",
      "Iteataion 1856: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.7659e-10.\n",
      "Iterataion 1857: Training Loss: 0.0166312580176038, Validation Loss: 0.12029764031077077\n",
      "Iteataion 1857: Training Accuracy: 0.9939546130952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.6882e-10.\n",
      "Iterataion 1858: Training Loss: 0.014279894812226374, Validation Loss: 0.12097095187878372\n",
      "Iteataion 1858: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.6114e-10.\n",
      "Iterataion 1859: Training Loss: 0.014516352248359973, Validation Loss: 0.12303855398204178\n",
      "Iteataion 1859: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.5352e-10.\n",
      "Iterataion 1860: Training Loss: 0.013406499754463206, Validation Loss: 0.12017388501426024\n",
      "Iteataion 1860: Training Accuracy: 0.9960007440476191, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.4599e-10.\n",
      "Iterataion 1861: Training Loss: 0.012891326461427896, Validation Loss: 0.11854239176424992\n",
      "Iteataion 1861: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.3853e-10.\n",
      "Iterataion 1862: Training Loss: 0.01514832544977732, Validation Loss: 0.12475674279550908\n",
      "Iteataion 1862: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 7.3114e-10.\n",
      "Iterataion 1863: Training Loss: 0.013147235272555405, Validation Loss: 0.1208973017566633\n",
      "Iteataion 1863: Training Accuracy: 0.9957217261904762, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.2383e-10.\n",
      "Iterataion 1864: Training Loss: 0.015508479751893291, Validation Loss: 0.12173085244338415\n",
      "Iteataion 1864: Training Accuracy: 0.9953497023809523, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 7.1659e-10.\n",
      "Iterataion 1865: Training Loss: 0.01408635447004637, Validation Loss: 0.12014317417534341\n",
      "Iteataion 1865: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 7.0943e-10.\n",
      "Iterataion 1866: Training Loss: 0.012366919513041722, Validation Loss: 0.11658200975109982\n",
      "Iteataion 1866: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9795386904761905\n",
      "Adjusting learning rate of group 0 to 7.0233e-10.\n",
      "Iterataion 1867: Training Loss: 0.015068418634943887, Validation Loss: 0.12116571850918528\n",
      "Iteataion 1867: Training Accuracy: 0.9949776785714286, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.9531e-10.\n",
      "Iterataion 1868: Training Loss: 0.014885107611067604, Validation Loss: 0.12058504875578986\n",
      "Iteataion 1868: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.8836e-10.\n",
      "Iterataion 1869: Training Loss: 0.012147297412798389, Validation Loss: 0.12372104183588994\n",
      "Iteataion 1869: Training Accuracy: 0.9965587797619048, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.8147e-10.\n",
      "Iterataion 1870: Training Loss: 0.01092224864848237, Validation Loss: 0.12213705190764058\n",
      "Iteataion 1870: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.7466e-10.\n",
      "Iterataion 1871: Training Loss: 0.010078477303247933, Validation Loss: 0.11953198221347454\n",
      "Iteataion 1871: Training Accuracy: 0.9961867559523809, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.6791e-10.\n",
      "Iterataion 1872: Training Loss: 0.01269047204345816, Validation Loss: 0.12140124147224081\n",
      "Iteataion 1872: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.6123e-10.\n",
      "Iterataion 1873: Training Loss: 0.017096516964497033, Validation Loss: 0.12460885126223196\n",
      "Iteataion 1873: Training Accuracy: 0.9951636904761905, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.5462e-10.\n",
      "Iterataion 1874: Training Loss: 0.0122525094087099, Validation Loss: 0.11988171039819263\n",
      "Iteataion 1874: Training Accuracy: 0.9963727678571429, Validation Accuracy  0.9791666666666666\n",
      "Adjusting learning rate of group 0 to 6.4807e-10.\n",
      "Iterataion 1875: Training Loss: 0.015047761322344894, Validation Loss: 0.12478134825132878\n",
      "Iteataion 1875: Training Accuracy: 0.9945126488095238, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.4159e-10.\n",
      "Iterataion 1876: Training Loss: 0.01261592825245904, Validation Loss: 0.12066362517965366\n",
      "Iteataion 1876: Training Accuracy: 0.9955357142857143, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.3518e-10.\n",
      "Iterataion 1877: Training Loss: 0.015165084090626179, Validation Loss: 0.1283711174846536\n",
      "Iteataion 1877: Training Accuracy: 0.9959077380952381, Validation Accuracy  0.9784226190476191\n",
      "Adjusting learning rate of group 0 to 6.2883e-10.\n",
      "Iterataion 1878: Training Loss: 0.015282243618833648, Validation Loss: 0.12348734041130761\n",
      "Iteataion 1878: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 6.2254e-10.\n",
      "Iterataion 1879: Training Loss: 0.01507838266852178, Validation Loss: 0.12322941666082819\n",
      "Iteataion 1879: Training Accuracy: 0.9956287202380952, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.1631e-10.\n",
      "Iterataion 1880: Training Loss: 0.01216013704685907, Validation Loss: 0.12221091034504153\n",
      "Iteataion 1880: Training Accuracy: 0.9962797619047619, Validation Accuracy  0.9787946428571429\n",
      "Adjusting learning rate of group 0 to 6.1015e-10.\n",
      "Iterataion 1881: Training Loss: 0.014669670160820786, Validation Loss: 0.11982832931510241\n",
      "Iteataion 1881: Training Accuracy: 0.9954427083333334, Validation Accuracy  0.9776785714285714\n",
      "Adjusting learning rate of group 0 to 6.0405e-10.\n",
      "Iterataion 1882: Training Loss: 0.014603692632165743, Validation Loss: 0.12014574859867713\n",
      "Iteataion 1882: Training Accuracy: 0.9947916666666666, Validation Accuracy  0.9780505952380952\n",
      "Adjusting learning rate of group 0 to 5.9801e-10.\n",
      "Iterataion 1883: Training Loss: 0.014881626012892613, Validation Loss: 0.1217954212348204\n",
      "Iteataion 1883: Training Accuracy: 0.9950706845238095, Validation Accuracy  0.9784226190476191\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Windows Files\\Desktop\\Repo\\Python\\KAUST AI\\Final Project\\dl-dataloader.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Windows%20Files/Desktop/Repo/Python/KAUST%20AI/Final%20Project/dl-dataloader.ipynb#ch0000012?line=4'>5</a>\u001b[0m total_train\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Windows%20Files/Desktop/Repo/Python/KAUST%20AI/Final%20Project/dl-dataloader.ipynb#ch0000012?line=5'>6</a>\u001b[0m net\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Windows%20Files/Desktop/Repo/Python/KAUST%20AI/Final%20Project/dl-dataloader.ipynb#ch0000012?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m ii,batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Windows%20Files/Desktop/Repo/Python/KAUST%20AI/Final%20Project/dl-dataloader.ipynb#ch0000012?line=7'>8</a>\u001b[0m   data\u001b[39m=\u001b[39mbatch[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Windows%20Files/Desktop/Repo/Python/KAUST%20AI/Final%20Project/dl-dataloader.ipynb#ch0000012?line=8'>9</a>\u001b[0m   label\u001b[39m=\u001b[39mbatch[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\radwa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\radwa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\radwa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\radwa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32md:\\Windows Files\\Desktop\\Repo\\Python\\KAUST AI\\Final Project\\dl-dataloader.ipynb Cell 4'\u001b[0m in \u001b[0;36mDataSetWithTransforms.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Windows%20Files/Desktop/Repo/Python/KAUST%20AI/Final%20Project/dl-dataloader.ipynb#ch0000003?line=10'>11</a>\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_features[index]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Windows%20Files/Desktop/Repo/Python/KAUST%20AI/Final%20Project/dl-dataloader.ipynb#ch0000003?line=11'>12</a>\u001b[0m     \u001b[39m#feature = torch.rashape(feature, (32,32,3))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Windows%20Files/Desktop/Repo/Python/KAUST%20AI/Final%20Project/dl-dataloader.ipynb#ch0000003?line=12'>13</a>\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Windows%20Files/Desktop/Repo/Python/KAUST%20AI/Final%20Project/dl-dataloader.ipynb#ch0000003?line=13'>14</a>\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feature_transforms(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_features[index])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Windows%20Files/Desktop/Repo/Python/KAUST%20AI/Final%20Project/dl-dataloader.ipynb#ch0000003?line=14'>15</a>\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_target[index]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Windows%20Files/Desktop/Repo/Python/KAUST%20AI/Final%20Project/dl-dataloader.ipynb#ch0000003?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (features, target)\n",
      "File \u001b[1;32mc:\\Users\\radwa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 94\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\radwa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    127\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32mc:\\Users\\radwa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:168\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    167\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m img\n\u001b[1;32m--> 168\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mview(pic\u001b[39m.\u001b[39;49msize[\u001b[39m1\u001b[39;49m], pic\u001b[39m.\u001b[39;49msize[\u001b[39m0\u001b[39;49m], \u001b[39mlen\u001b[39;49m(pic\u001b[39m.\u001b[39;49mgetbands()))\n\u001b[0;32m    169\u001b[0m \u001b[39m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m    170\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(3000):\n",
    "  loss_total=0\n",
    "  loss_val=0\n",
    "  acc_train=0\n",
    "  total_train=0\n",
    "  net.train()\n",
    "  for ii,batch in enumerate(train_loader):\n",
    "    data=batch[0]\n",
    "    label=batch[1]\n",
    "    #optimizer-->buffer += grad\n",
    "    optimizer.zero_grad()\n",
    "    data, label = data.to(device), label.to(device)\n",
    "    logits = net(data)\n",
    "    #print(type(logits))\n",
    "    #this is the output of the network and it's shape is batch_size X no of classes\n",
    "    loss = F.cross_entropy(logits, label)\n",
    "    loss_total+=loss.item()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    out=torch.argmax(logits, dim=1)\n",
    "    acc_train+=torch.sum(out==label)\n",
    "    total_train+=logits.shape[0]\n",
    "\n",
    "  acc_val=0\n",
    "  total_val=0 \n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "    for jj,batch in enumerate(valid_loader):\n",
    "          data=batch[0]\n",
    "          label=batch[1]\n",
    "          #optimizer-->buffer += grad\n",
    "          data, label = data.to(device), label.to(device)\n",
    "          logits = net(data)\n",
    "          loss = F.cross_entropy(logits, label)\n",
    "          loss_val+=loss.item()\n",
    "          out=torch.argmax(logits, dim=1)\n",
    "          acc_val+=torch.sum(out==label)\n",
    "          total_val+=logits.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "  ls.append(loss_total)\n",
    "  lr_scheduler.step()\n",
    "  print(f\"Iterataion {i}: Training Loss: {loss_total/ii}, Validation Loss: {loss_val/jj}\")\n",
    "  print(f\"Iteataion {i}: Training Accuracy: {acc_train.item()/total_train}, Validation Accuracy  {acc_val.item()/total_val}\")\n",
    "  if ((acc_val.item()/total_val) > highest):\n",
    "    highest = acc_val.item()/total_val\n",
    "    break\n",
    "    \n",
    "plt.plot(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "303fa597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.9840029761904762\n"
     ]
    }
   ],
   "source": [
    "acc_val=0\n",
    "total_val=0 \n",
    "with torch.no_grad():\n",
    "      for jj,batch in enumerate(valid_loader):\n",
    "            data=batch[0]\n",
    "            label=batch[1]\n",
    "            #optimizer-->buffer += grad\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            logits = net(data)\n",
    "            loss = F.cross_entropy(logits, label)\n",
    "            loss_val+=loss.item()\n",
    "            out=torch.argmax(logits, dim=1)\n",
    "            acc_val+=torch.sum(out==label)\n",
    "            total_val+=logits.shape[0]\n",
    "\n",
    "print(f\"Testing Accuracy: {acc_val.item()/total_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "8458cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = list()\n",
    "for images in test_loader:\n",
    "    prediction_list.append(net(images.cuda()).argmax(1))\n",
    "    \n",
    "prediction_list = torch.cat(prediction_list)\n",
    "test_features = pd.read_csv(DATA_DIR / \"test.csv\")\n",
    "\n",
    "_ = (pd.DataFrame\n",
    "       .from_dict({\"Id\": test_features.index, \"Category\": prediction_list.cpu()})\n",
    "       .to_csv(\"submission.csv\", index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6277d6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34.93097,
   "end_time": "2022-06-29T05:42:18.383685",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-29T05:41:43.452715",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0d9c7fd3642b660ffedf3a77d11c31e11ccbd2a913cb9ccb12c86252838bb24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
