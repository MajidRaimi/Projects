{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nbbIa6w7Ifbr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from time import time\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taGn5jj_gYD8"
      },
      "source": [
        "An open source machine learning framework that accelerates the path from research prototyping to production deployment [PyTorch](https://pytorch.org/). To check the installation instructions check [PyTorch](https://pytorch.org/). We will import PyTorch and use it in todya's lab to implement simple and convoutional neural networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqR7Z027gheU"
      },
      "source": [
        "Let's start by checking the version of PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuhtOOmPXVbz",
        "outputId": "ef4f599d-6222-4e0f-f1b4-a65f9c087b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using torch 1.12.0+cpu\n"
          ]
        }
      ],
      "source": [
        "print(\"Using torch\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jun 29 10:29:09 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 516.40       Driver Version: 516.40       CUDA Version: 11.7     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
            "| N/A   49C    P0    30W /  N/A |    382MiB /  8192MiB |      7%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1988    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
            "|    0   N/A  N/A      2016    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
            "|    0   N/A  N/A      3856    C+G   ...batNotificationClient.exe    N/A      |\n",
            "|    0   N/A  N/A      4368    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A      4372    C+G   ...ightStudio-background.exe    N/A      |\n",
            "|    0   N/A  N/A      4836    C+G   ...8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
            "|    0   N/A  N/A      6008    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A      6724    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A      9728    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A      9740    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
            "|    0   N/A  N/A     11652    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
            "|    0   N/A  N/A     15336    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     18204    C+G   ...jag6ke6\\HP.JumpStarts.exe    N/A      |\n",
            "|    0   N/A  N/A     19392    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
            "|    0   N/A  N/A     22260    C+G   ...4__8j3eq9eme6ctt\\IGCC.exe    N/A      |\n",
            "|    0   N/A  N/A     22696    C+G   ...mmandCenterBackground.exe    N/A      |\n",
            "|    0   N/A  N/A     22768    C+G   ...pcg\\ModernFlyoutsHost.exe    N/A      |\n",
            "|    0   N/A  N/A     22924    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
            "|    0   N/A  N/A     25288    C+G   ...ystemEventUtilityHost.exe    N/A      |\n",
            "|    0   N/A  N/A     25332    C+G   ...txyewy\\MiniSearchHost.exe    N/A      |\n",
            "|    0   N/A  N/A     26188    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDWOeBIcg-I4"
      },
      "source": [
        "In several codes you will see the manaul_seed setup of PyTorch. This is done to ensure reproducibility of the code. Run the below code multiple times with and without the manual seed setup and you will that the random number geneator produces same random numbers every time when the seed is set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7bTTNPfXn6d",
        "outputId": "71fa4271-ddc2-43aa-c9e4-6b8c239fbb06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-1.6053,  0.2325])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(4) # Setting the seed\n",
        "torch.randn(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrfQdvFiheUI"
      },
      "source": [
        "The basic data structure for PyTorch (and for that matter most other deep learning libraries) is Tensor. The simplest definition of a Tensor is \"Tensor is a multi-dimensional matrix\".\n",
        "\n",
        "There are multiple ways of defining tensors in PyTorch below we will show two such methods. Run the code and see what tensors are produced. For ease of notation I have used {variable name}_t to represent tensor variables in the code "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xKN-0kncJFnJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 0.],\n",
            "        [0., 1.]])\n",
            "tensor([[0.6687, 0.2111, 0.4950],\n",
            "        [0.6774, 0.8025, 0.3760],\n",
            "        [0.4381, 0.1807, 0.9200]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "x=[[1,0],[0,1]]\n",
        "x_t=torch.Tensor(x)\n",
        "print(x_t)\n",
        "\n",
        "\n",
        "x=np.random.rand(3,3)\n",
        "x_t=torch.from_numpy(x)\n",
        "print(x_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgX3E361iTnK"
      },
      "source": [
        "Tensors in PyTorch have several useful attributes (properties). Some of these attributes are shape, requires_grad, dtype, and device. shape attributes shows the shape of the Tensor, similar to the shape of a matrix. requries_grad is a flag that shows weather the gradients w.r.t the tensor are calculated or not. If requires_grad is True it will mean that PyTorch will keep of the gradient of the [output] w.r.t. the Tensor varaiable. dtype shows the data type of the tensor. device shows the device on which the tensor resides cpu or cuda (GPU). We will discuss why this is an important feature of the Tensor and how it helps us to speed up our codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOAwhSpDJbTm"
      },
      "outputs": [],
      "source": [
        "print(x_t.shape)\n",
        "print(x_t.requires_grad)\n",
        "print(x_t.dtype)\n",
        "print(x_t.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBlbMTekjafO"
      },
      "source": [
        "GPU (Graphics Processing Unit) is a specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device. GPUs are used in embedded systems, mobile phones, personal computers, workstations, and game consoles. [GPUs](https://en.wikipedia.org/wiki/Graphics_processing_unit#:~:text=A%20graphics%20processing%20unit%20(GPU,%2C%20workstations%2C%20and%20game%20consoles.)\n",
        "\n",
        "\n",
        "GPUs are extremely beneficial in running matrix operations and as we will most of deep learning is composed of matrix opearations, we can significantly speed up our codes by using GPUs.\n",
        "\n",
        "There are several methods and attributes in PyTorch to manage the device on which Tensors can reside. Below we look at a few."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr1xhDQFmYpY"
      },
      "source": [
        "GPUs are specialized expensive piece of equipment and might not be available on all machines. To check if a GPU is available on a machine we can use torch.cuda.is_available() method which returns a True value if a GPUs is available.\n",
        "\n",
        "Note: To use a GPU on Google Colab you can select the option under Edit->NoteBook Settings.\n",
        "\n",
        "\n",
        "To move Tensor between CPU and GPU we can use Tensor.to(...) method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpcy8y1VLLg9"
      },
      "outputs": [],
      "source": [
        "#managing device\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "print(torch.cuda.device_count())\n",
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda:0\")\n",
        "else:\n",
        "  device=torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "print(device)\n",
        "device=torch.device(\"cpu\")\n",
        "x_t_cpu=x_t.to(device)\n",
        "print(x_t_cpu.device)\n",
        "device=torch.device(\"cuda\")\n",
        "x_t_gpu=x_t.to(device)\n",
        "print(x_t_gpu.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN_deHP3SUXB",
        "outputId": "5e07865d-aedf-4b42-991b-a85bd336e906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May 26 10:25:35 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcnYsKVTQ_To"
      },
      "outputs": [],
      "source": [
        "use_gpu=True\n",
        "if use_gpu:\n",
        "  device=torch.device(\"cuda:0\")\n",
        "else:\n",
        "  device=torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16qjvhZ_owQ7"
      },
      "source": [
        "We have dedicated functions in PyTorch to create tensors of particular types. Some of these are provided below. torch.zeros, creates a tensor of zeors, torch.ones, crates a tensor of ones, torch.eye creats an indentity matrix, torch.rand creats a tensor or random values sampled fron uniform distribution, torch.randn creates a tensor of random values samples from unit normal (gaussian distribution), torch.arange(N) ceates whole numbers till N-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB8ebKmroQ7C"
      },
      "outputs": [],
      "source": [
        "x=torch.zeros(3,3)\n",
        "print(x)\n",
        "x=torch.ones(2,2)\n",
        "print(x)\n",
        "x=torch.eye(2)\n",
        "print(x)\n",
        "x=torch.rand(2,1)\n",
        "print(x)\n",
        "x=torch.randn((3,2))\n",
        "print(x)\n",
        "x=torch.arange(5)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xzdy_333nEH3"
      },
      "source": [
        "Tensor opeartions:\n",
        "Most numpy operations are also available in PyTorch. opeartaions like addition (+), subtraction (-), mulitplication (*), divistion (/), matrix multiplication (@), and power(***)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaOiJ9ffLkUV"
      },
      "outputs": [],
      "source": [
        "#tensor operations\n",
        "\n",
        "x=torch.randn((3,3))\n",
        "y=torch.eye(3)\n",
        "print(x,y)\n",
        "\n",
        "zsum=x+y\n",
        "zdiff=x-y\n",
        "zprod=x*y\n",
        "zdiv=y/x\n",
        "# @ is read as at\n",
        "zmatmul=x@y\n",
        "zpow=x**y\n",
        "\n",
        "print(f\"element wise of the sum of the two tensors is{zsum}\")\n",
        "print(f\"element wise of the diff of the two tensors is{zdiff}\")\n",
        "print(f\"element wise of the prod of the two tensors is{zprod}\")\n",
        "print(f\"element wise of the div of the two tensors is{zdiv}\")\n",
        "print(f\"element wise of the pow of the two tensors is{zpow}\")\n",
        "print(f\"matrix multiplicaiton of the two tensors is{zmatmul}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3Ids2kfrh8_"
      },
      "source": [
        "We can use Tensor1 [operation]= Tensor2 for in place operations on Tensor1.\n",
        "\n",
        "Several PyTorch functions also have an inplace version with the function name appended with and underscore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oODYh0ExOWfB"
      },
      "outputs": [],
      "source": [
        "#pytorch also has inplace operations\n",
        "\n",
        "x+=y #x=x+y\n",
        "x-=y\n",
        "y*=x\n",
        "y/=x\n",
        "#x**=y.  x=x**y\n",
        "x@=y\n",
        "\n",
        "\n",
        "x.clamp(-0.5,0.5)\n",
        "print(x)\n",
        "x.clamp_(-0.5,0.5)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1g-q8Njr8My"
      },
      "source": [
        "PyTorch uses same indexing and slicing conventians as numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L8bo5hiQoCJ"
      },
      "outputs": [],
      "source": [
        "#indexing and slicing\n",
        "x=torch.Tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
        "print(x)\n",
        "#an element can be access by specifying the row and column\n",
        "print(x[1,1])\n",
        "# acessing rows and columns\n",
        "print(x[1,:], x[:,1])\n",
        "print(x[1,:].shape, x[:,1].shape)\n",
        "# acessing rows and columns and keeping the shape\n",
        "print(x[1:2,:], x[:,1:2])\n",
        "print(x[1:2,:].shape, x[:,1:2].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KkUSKvi8Bc3",
        "outputId": "6e87c9b2-56c9-47ae-e5bb-7ea589569ee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.],\n",
            "        [7., 8., 9.]])\n",
            "tensor([[5., 6.],\n",
            "        [8., 9.]])\n"
          ]
        }
      ],
      "source": [
        "#indexing and slicing\n",
        "x=torch.Tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
        "print(x)\n",
        "\n",
        "\n",
        "print(x[1:,1:])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuEk5nq3sBcN"
      },
      "source": [
        "Some Tensor operations in PyTorch are:\n",
        "concateation, and reshaping. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgqHOJ9sUivV"
      },
      "outputs": [],
      "source": [
        "#tensor operations\n",
        "\n",
        "z=torch.cat((x,y), dim=1)\n",
        "print(z)\n",
        "\n",
        "z2=z.reshape(9,2)\n",
        "print(z2)\n",
        "z2=torch.reshape(z,(9,2))\n",
        "print(z2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCLS-tPmsXud"
      },
      "source": [
        "removing a unit dimension through squeeze, adding a unit dimension through unsqueeze."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9eUDOf1iLli",
        "outputId": "a05a46f4-1ebc-4bb8-8c6f-ec0c4ba5f127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2, 3, 1, 5]) torch.Size([1, 1, 2, 3, 1, 5])\n",
            "torch.Size([1, 1, 2, 3, 1, 5])\n",
            "torch.Size([1, 1, 2, 3, 1, 5])\n",
            "torch.Size([2, 3, 5])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x=torch.rand((1,2,3,1,5))\n",
        "x_u=x.unsqueeze(dim=0)\n",
        "print(x.shape, x_u.shape)\n",
        "x.unsqueeze_(dim=1)\n",
        "print(x.shape)\n",
        "\n",
        "\n",
        "\n",
        "print(x.shape)\n",
        "x_s=x.squeeze()\n",
        "print(x_s.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6twOFl_Vsju2"
      },
      "source": [
        "Why use GPU?\n",
        "Example of matrix multiplication on CPU and GPU.\n",
        "\n",
        "Important points to consdier:\n",
        "Always use vector opeartions\n",
        "Always use PyTorch functions\n",
        "When possible always use GPUs for matrix operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tSEtyTaiSZf",
        "outputId": "3c6547ca-cec4-4268-aa6a-0ce72174aa87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time taken by the nested loop multiplciation is 15.097606658935547 seconds\n",
            "time taken by the single loop multiplciation is 0.15124773979187012 seconds\n",
            "time taken by  multiplciation on cpu is 0.065185546875 seconds\n",
            "time taken by multiplciation on GPU is 0.06881403923034668 seconds\n"
          ]
        }
      ],
      "source": [
        "# use vectorized operations and broadcasting\n",
        "# use GPU for vector/matrix operations\n",
        "siz=1000\n",
        "\n",
        "x=torch.randn((siz,siz))\n",
        "y=torch.randn((siz,siz))\n",
        "z=torch.zeros((siz,siz))\n",
        "st=time()\n",
        "for i in range(siz):\n",
        "  for j in range(siz):\n",
        "    z[i,j]=torch.dot(x[i,:],y[:,j])\n",
        "\n",
        "ed=time()\n",
        "print(f\"time taken by the nested loop multiplciation is {ed-st} seconds\")\n",
        "st=time()\n",
        "for i in range(siz):\n",
        "  z[i,:]=torch.mm(x[i,:].unsqueeze(dim=0),y)\n",
        "\n",
        "ed=time()\n",
        "print(f\"time taken by the single loop multiplciation is {ed-st} seconds\")\n",
        "st=time()\n",
        "z=torch.mm(x,y)\n",
        "\n",
        "ed=time()\n",
        "print(f\"time taken by  multiplciation on cpu is {ed-st} seconds\")\n",
        "\n",
        "device=torch.device(\"cuda:0\")\n",
        "x=x.to(device)\n",
        "y=y.to(device)\n",
        "z=z.to(device)\n",
        "st=time()\n",
        "z=torch.mm(x,y)\n",
        "ed=time()\n",
        "print(f\"time taken by multiplciation on GPU is {ed-st} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjOc-p0KtSw8"
      },
      "source": [
        "Autograd example with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7EVtohYrymk",
        "outputId": "10238d91-39c5-4329-9ad3-2f49fb5da40d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n",
            "tensor([[0.0106]])\n",
            "After backpass\n",
            "dz/dx\n",
            "tensor([[2.]])\n",
            "<AddBackward0 object at 0x7f0404c33c10>\n",
            "tensor([[0.0106]])\n",
            "dz/dy\n",
            "tensor([10.])\n",
            "tensor([[25.0212]], grad_fn=<AddBackward0>)\n",
            "tensor([5.])\n",
            "True\n",
            "False\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "x=torch.randn((1,1), requires_grad=True)\n",
        "y=torch.Tensor([5.0])\n",
        "y.requires_grad=True\n",
        "\n",
        "z=2*x+y*y\n",
        "\n",
        "print(x.grad)\n",
        "print(x.grad_fn)\n",
        "print(x.data)\n",
        "z.backward()\n",
        "print(\"After backpass\")\n",
        "print(\"dz/dx\")\n",
        "print(x.grad)\n",
        "print(z.grad_fn)\n",
        "print(x.data)\n",
        "\n",
        "print(\"dz/dy\")\n",
        "print(y.grad)\n",
        "print(z)\n",
        "print(y.data)\n",
        "print(z.requires_grad)\n",
        "with torch.no_grad():\n",
        "  z=2*x+y*y\n",
        "  print(z.requires_grad)\n",
        "\n",
        "\n",
        "#detaching variable and coverting back to numpy\n",
        "x=x.detach().cpu().numpy()\n",
        "print(type(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFM0OLQEc5xj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x=torch.rand((1,32,32))\n",
        "plt.imshow(x[0,:,:].numpy())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PyTorch_Tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0d9c7fd3642b660ffedf3a77d11c31e11ccbd2a913cb9ccb12c86252838bb24"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
